<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>Introduction to Probabilistic Programming in R: All in One View</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<script src="../assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="../assets/styles.css">
<script src="../assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="../favicons/incubator/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicons/incubator/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../favicons/incubator/favicon-16x16.png">
<link rel="manifest" href="../favicons/incubator/site.webmanifest">
<link rel="mask-icon" href="../favicons/incubator/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="white">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="black">
</head>
<body>
    <header id="top" class="navbar navbar-expand-md top-nav incubator"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="incubator-logo" alt="Carpentries Incubator" src="../assets/images/incubator-logo.svg"><span class="badge text-bg-danger">
          <abbr title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.">
            <a href="https://docs.carpentries.org/resources/curriculum/lesson-life-cycle.html" class="external-link alert-link">
              <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
              Pre-Alpha
            </a>
            <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
          </abbr>
        </span>

      </div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text">
<li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul>
</li>
      </div>

      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
<li><button class="dropdown-item" type="button" onclick="window.location.href='../aio.html';">Learner View</button></li>
        </ul>
</div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Carpentries Incubator" src="../assets/images/incubator-logo-sm.svg">
</div>
    <div class="lesson-title-md">
      Introduction to Probabilistic Programming in R
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
<li class="nav-item">
          <span class="lesson-title">
            Introduction to Probabilistic Programming in R
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/instructor-notes.html">Instructor Notes</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/images.html">Extract All Images</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
<hr>
<li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul>
</li>
      </ul>
</div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="../instructor/aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div>
<!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Introduction to Probabilistic Programming in R
</div>

<aside class="col-md-12 lesson-progress"><div style="width: %" class="percentage">
    %
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: %" aria-valuenow="" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text">
<li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul>
</li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="../aio.html">Learner View</a>
                      </div>
                    </div>
                  </div>
<!--/div.accordion-item-->
                </div>
<!--/div.accordion-flush-->
              </div>
<!--div.sidenav-view-selector -->
            </div>
<!--/div.col -->

            <hr>
</div>
<!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Schedule</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="bayesian-statistics.html">1. Short introduction to Bayesian statistics</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="stan.html">2. Stan</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="mcmc.html">3. Markov chain Monte Carlo</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="hierarchical-models.html">4. Hierarchical models</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="model-comparison.html">5. Model comparison</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="gaussian-processes.html">6. Gaussian processes</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="stan-extensions.html">7. Stan extensions</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush9">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading9">
        <a href="exercises.html">8. Exercises</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width">
<div class="accordion accordion-flush lesson-resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="lesson-resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul>
<li>
                        <a href="../instructor/key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="../instructor/instructor-notes.html">Instructor Notes</a>
                      </li>
                      <li>
                        <a href="../instructor/images.html">Extract All Images</a>
                      </li>
                      <hr>
<li><a class="dropdown-item" href="reference.html">Reference</a></li>
                    </ul>
</div>
                </div>
              </div>
            </div>
            <hr class="half-width lesson-resources">
<a href="../instructor/aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none">
<div class="d-grid gap-1">

            </div>
          </div>
<!-- /div.accordion -->
        </div>
<!-- /div.sidebar-inner -->
      </nav>
</div>
<!-- /div.sidebar -->
  </div>
<!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-extra.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <main id="main-content" class="main-content"><div class="container lesson-content">
        
        
<section id="aio-bayesian-statistics"><p>Content from <a href="bayesian-statistics.html">Short introduction to Bayesian statistics</a></p>
<hr>
<p>Last updated on 2025-08-22 |

        <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/edit/main/episodes/bayesian-statistics.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 68 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How are statistical models formulated and fitted within the Bayesian
framework?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<p>Learn to</p>
<ul>
<li>formulate prior, likelihood, posterior distributions.</li>
<li>fit a Bayesian model with the grid approximation.</li>
<li>communicate posterior information.</li>
<li>work with with posterior samples.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="bayes-formula">Bayes’ formula<a class="anchor" aria-label="anchor" href="#bayes-formula"></a>
</h2>
<hr class="half-width">
<p>The starting point of Bayesian statistics is Bayes’ theorem,
expressed as:</p>
<p><span class="math display">\[
  p(\theta | X) = \frac{p(X | \theta) p(\theta)  }{p(X)} \\
\]</span></p>
<p>When dealing with a statistical model, this theorem is used to infer
the probability distribution of the model parameters <span class="math inline">\(\theta\)</span>, conditional on the available data
<span class="math inline">\(X\)</span>. These probabilities are
quantified by the <em>posterior distribution</em> <span class="math inline">\(p(\theta | X)\)</span>, which is primary the
target of probabilistic modeling.</p>
<p>On the right-hand side of the formula, the <em>likelihood
function</em> <span class="math inline">\(p(X | \theta)\)</span> gives
plausibility of the data given <span class="math inline">\(\theta\)</span>, and determines the impact of the
data on the posterior.</p>
<p>A defining feature of Bayesian modeling is the second term in the
numerator, the <em>prior distribution</em> <span class="math inline">\(p(\theta)\)</span>. The prior is used to
incorporate beliefs about <span class="math inline">\(\theta\)</span>
before considering the data.</p>
<p>The denominator on the right-hand side <span class="math inline">\(p(X)\)</span> is called the marginal probability,
and is often practically impossible to compute. For this reason the
proportional version of Bayes’ formula is typically employed:</p>
<p><span class="math display">\[
p(\theta | X) \propto p(\theta)  p(X | \theta).
\]</span></p>
<p>The proportional Bayes’ formula yields an unnormalized posterior
distribution, which can subsequently be normalized to obtain the
posterior.</p>
</section><section><h2 class="section-heading" id="example-1-handedness">Example 1: handedness<a class="anchor" aria-label="anchor" href="#example-1-handedness"></a>
</h2>
<hr class="half-width">
<p>Let’s illustrate the use of the Bayes’ theorem with an example.</p>
<p>Assume we are trying to estimate the prevalence of left-handedness in
humans, based on a sample of <span class="math inline">\(N=50\)</span>
students, out of which <span class="math inline">\(x=7\)</span> are
left-handed and 43 right-handed.</p>
<p>The outcome is binary and the students are assumed to be independent
(e.g. no twins), so the binomial distribution is the appropriate choice
for likelihood:</p>
<p><span class="math display">\[
p(X|\theta) = Bin(7 | 50, \theta).
\]</span></p>
<p>Without further justification, we’ll choose <span class="math inline">\(p(\theta) = Beta(\theta |1, 10)\)</span> as the
prior distribution, so the unnormalized posterior distribution is</p>
<p><span class="math display">\[
p(\theta | X) = \text{Bin}(7 | 50, \theta) \cdot \text{Beta}(\theta | 1,
10).
\]</span></p>
<p>Below, we’ll plot these functions. Likelihood (which is not a
distribution!) has been normalized for better illustration.</p>
<figure><img src="../fig/bayesian-statistics-rendered-unnamed-chunk-2-1.png" width="100%" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>The figure shows that the majority of the mass in the posterior
distribution is concentrated between 0 and 0.25. This implies that,
given the available data and prior distribution, the model is fairly
confident that the value of <span class="math inline">\(\theta\)</span>
is between these values. The peak of the posterior is at approximately
0.1 representing the most likely value. This aligns well with intuitive
expectations about left-handedness in humans.</p>
<div id="accordionInstructor1" class="accordion instructor-note accordion-flush">
<div class="accordion-item">
<button class="accordion-button instructor-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseInstructor1" aria-expanded="false" aria-controls="collapseInstructor1">
  <h3 class="accordion-header" id="headingInstructor1">  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="edit-2"></i></div> Instructor Note </h3>
</button>
<div id="collapseInstructor1" class="accordion-collapse collapse" data-bs-parent="#accordionInstructor1" aria-labelledby="headingInstructor1">
<div class="accordion-body">
<p>Actual value from a study from 1975 with 7,688 children in US grades
1-6 was 9.6%</p>
<p>Hardyck, C. et al. (1976), Left-handedness and cognitive deficit <a href="https://en.wikipedia.org/wiki/Handedness" class="external-link uri">https://en.wikipedia.org/wiki/Handedness</a></p>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="communicating-posterior-information">Communicating posterior information<a class="anchor" aria-label="anchor" href="#communicating-posterior-information"></a>
</h2>
<hr class="half-width">
<p>The posterior distribution <span class="math inline">\(p(\theta |
X)\)</span> contains all the information about <span class="math inline">\(\theta\)</span> given the data, chosen model, and
the prior distribution. However, understanding a distribution in itself
can be challenging, especially if it is multidimensional. To effectively
communicate posterior information, methods to quantify the information
contained in the posterior are needed. Two commonly used types of
estimates are point estimates, such as the posterior mean, mode, and
variance, and posterior intervals, which provide probabilities for
ranges of values.</p>
<p>Two specific types of posterior intervals are often of interest:</p>
<ol style="list-style-type: decimal">
<li><p><em>Credible intervals</em> (CIs): These intervals leave equal
posterior mass below and above them, computed as posterior quantiles.
For instance, a 90% CI would span the range between the 5% and 95%
quantiles.</p></li>
<li><p><em>Defined boundary intervals</em>: Computed as the posterior
mass for specific parts of the parameter space, these intervals quantify
the probability for given parameter conditions. For example, we might be
interested in the posterior probability that <span class="math inline">\(\theta &gt; 0\)</span>, <span class="math inline">\(0&lt;\theta&lt;0.5\)</span>, or <span class="math inline">\(\theta&lt;0\)</span> or <span class="math inline">\(\theta &gt; 0.5\)</span>. These probabilities can
be computed by integrating the posterior over the corresponding
sets.</p></li>
</ol>
<p>The following figures illustrate selected posterior intervals for the
previous example along with the posterior mode, or <em>maximum a
posteriori</em> (MAP) estimate.</p>
<figure><img src="../fig/bayesian-statistics-rendered-unnamed-chunk-3-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure></section><section><h2 class="section-heading" id="grid-approximation">Grid approximation<a class="anchor" aria-label="anchor" href="#grid-approximation"></a>
</h2>
<hr class="half-width">
<p>Specifying a probabilistic model can be simple, but a common
bottleneck in Bayesian data analysis is model fitting. Later in the
course, we will begin using Stan, a state-of-the-art method for
approximating the posterior. However, we’ll begin fitting probabilistic
model using the grid approximation. This approach involves computing the
unnormalized posterior distribution at a grid of evenly spaced values in
the parameter space and can be specified as follows:</p>
<ol style="list-style-type: decimal">
<li>Define a grid of parameter values.</li>
<li>Compute the prior and likelihood on the grid.</li>
<li>Multiply to get the unnormalized posterior.</li>
<li>Normalize.</li>
</ol>
<p>Now, we’ll implement the grid approximation for the handedness
example in R.</p>
</section><section><h2 class="section-heading" id="example-2-handedness-with-grid-approximation">Example 2: handedness with grid approximation<a class="anchor" aria-label="anchor" href="#example-2-handedness-with-grid-approximation"></a>
</h2>
<hr class="half-width">
<p>First, we’ll load the required packages, define the data variables,
and the grid of parameter values</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Sample size</span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">50</span></span>
<span></span>
<span><span class="co"># 7/50 are left-handed</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fl">7</span></span>
<span></span>
<span><span class="co"># Define a grid of points in the interval [0, 1], with 0.01 interval</span></span>
<span><span class="va">delta</span> <span class="op">&lt;-</span> <span class="fl">0.01</span></span>
<span><span class="va">theta_grid</span> <span class="op">&lt;-</span> <span class="fu">seq</span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, by <span class="op">=</span> <span class="va">delta</span><span class="op">)</span></span></code></pre>
</div>
<p>Computing the values of the likelihood, prior, and unnormalized
posterior is straightforward. While you can compute these using
for-loops, vectorization as used below, is a more efficient
approach:</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu">dbinom</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, size <span class="op">=</span> <span class="va">N</span>, prob <span class="op">=</span> <span class="va">theta_grid</span><span class="op">)</span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu">dbeta</span><span class="op">(</span><span class="va">theta_grid</span>, <span class="fl">1</span>, <span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">likelihood</span><span class="op">*</span><span class="va">prior</span></span></code></pre>
</div>
<p>Next, the posterior needs to be normalized.</p>
<p>In practice, this means dividing the values by the area under the
unnormalized posterior. The area is computed with the integral <span class="math display">\[\int_0^1 p(\theta | X)_{\text{unnormalized}}
d\theta,\]</span> which is for a grid approximated function is the sum
<span class="math display">\[\sum_{\text{grid}} p(\theta |
X)_{\text{unnormalized}} \cdot \delta,\]</span> where <span class="math inline">\(\delta\)</span> is the grid interval.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Normalize </span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">posterior</span><span class="op">/</span><span class="op">(</span><span class="fu">sum</span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span><span class="op">*</span><span class="va">delta</span><span class="op">)</span></span>
<span><span class="co"># Likelihood also normalized for better visualization</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="va">likelihood</span><span class="op">/</span><span class="op">(</span><span class="fu">sum</span><span class="op">(</span><span class="va">likelihood</span><span class="op">)</span><span class="op">*</span><span class="va">delta</span><span class="op">)</span></span></code></pre>
</div>
<p>Finally, we can plot these functions</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Make data frame</span></span>
<span><span class="va">df1</span> <span class="op">&lt;-</span> <span class="fu">data.frame</span><span class="op">(</span>theta <span class="op">=</span> <span class="va">theta_grid</span>, <span class="va">likelihood</span>, <span class="va">prior</span>, <span class="va">posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Wide to long format</span></span>
<span><span class="va">df1_l</span> <span class="op">&lt;-</span> <span class="va">df1</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">gather</span><span class="op">(</span>key <span class="op">=</span> <span class="st">"Function"</span>, value <span class="op">=</span> <span class="st">"value"</span>, <span class="op">-</span><span class="va">theta</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot</span></span>
<span><span class="va">p1</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">df1_l</span>, </span>
<span>       <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">theta</span>, y <span class="op">=</span> <span class="va">value</span>, color <span class="op">=</span> <span class="va">Function</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>size <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>linewidth <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_color_grafify</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="fu">expression</span><span class="op">(</span><span class="va">theta</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">p1</span></span></code></pre>
</div>
<figure><img src="../fig/bayesian-statistics-rendered-unnamed-chunk-7-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>The points in the figure represent the values of the functions
computed at the grid locations. The lines depict linear interpolations
between these points.</p>
<div id="discussion1" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<span class="callout-header">Discussion</span>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>Experiment with different priors and examine their effects on the
posterior. You could try, for example, different Beta distributions, the
normal distribution, or the uniform distribution.</p>
<p>How does the shape of the prior impact the posterior?</p>
<p>What is the relationship between the posterior, data (likelihood) and
the prior?</p>
</div>
</div>
</div>
<div class="section level3">
<h3 id="grid-approximation-and-posterior-summaries">Grid approximation and posterior summaries<a class="anchor" aria-label="anchor" href="#grid-approximation-and-posterior-summaries"></a>
</h3>
<p>Next, we’ll learn how to compute point estimates and posterior
intervals based on the approximate posterior obtained with the grid
approximation.</p>
<p>Computing the posterior mean and variance is based on the definition
of these statistics for continuous variables. The mean is defined as
<span class="math display">\[\int \theta \cdot p(\theta | X)
d\theta,\]</span> and can be computed using discrete integration: <span class="math display">\[\sum_{\text{grid}} \theta \cdot p(\theta | X)
\cdot \delta.\]</span> Similarly, variance can be computed based on the
definition <span class="math display">\[\text{var}(\theta) = \int
(\theta - \text{mean}(\theta))^2p(\theta | X)d\theta.\]</span> Posterior
mode is simply the grid value where the posterior is maximized.</p>
<p>In R, these statistics can be computed as follows:</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">data.frame</span><span class="op">(</span>Estimate <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="st">"Mode"</span>, <span class="st">"Mean"</span>, <span class="st">"Variance"</span><span class="op">)</span>, </span>
<span>           Value <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="va">df1</span><span class="op">[</span><span class="fu">which.max</span><span class="op">(</span><span class="va">df1</span><span class="op">$</span><span class="va">posterior</span><span class="op">)</span>, <span class="st">"theta"</span><span class="op">]</span>,</span>
<span>                     <span class="fu">sum</span><span class="op">(</span><span class="va">df1</span><span class="op">$</span><span class="va">theta</span><span class="op">*</span><span class="va">df1</span><span class="op">$</span><span class="va">posterior</span><span class="op">*</span><span class="va">delta</span><span class="op">)</span>, </span>
<span>                     <span class="fu">sum</span><span class="op">(</span><span class="va">df1</span><span class="op">$</span><span class="va">theta</span><span class="op">^</span><span class="fl">2</span><span class="op">*</span><span class="va">df1</span><span class="op">$</span><span class="va">posterior</span><span class="op">*</span><span class="va">delta</span><span class="op">)</span> <span class="op">-</span></span>
<span>                       <span class="fu">sum</span><span class="op">(</span><span class="va">df1</span><span class="op">$</span><span class="va">theta</span><span class="op">*</span><span class="va">df1</span><span class="op">$</span><span class="va">posterior</span><span class="op">*</span><span class="va">delta</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>  Estimate       Value
1     Mode 0.120000000
2     Mean 0.131147540
3 Variance 0.001837869</code></pre>
</div>
<p>Posterior intervals are also relatively easy to compute.</p>
<p>Finding the quantiles used to determine CIs is based on the
cumulative distribution function of the posterior <span class="math inline">\(F(\theta) = \int_{\infty}^{\theta}p(y | X)
dy\)</span>. The locations where the <span class="math inline">\(F(\theta) = 0.05\)</span> and <span class="math inline">\(F(\theta) = 0.95\)</span> define the 90% CIs.</p>
<p>Probabilities for certain parameter ranges are computed simply by
integrating over the appropriate set, for example, <span class="math inline">\(Pr(\theta &lt; 0.1) = \int_0^{0.1} p(\theta | X)
d\theta.\)</span></p>
<div id="challenge1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>Compute the 90% CIs and the probability <span class="math inline">\(Pr(\theta &lt; 0.1)\)</span> for the handedness
example.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Quantiles</span></span>
<span><span class="va">q5</span> <span class="op">&lt;-</span> <span class="va">theta_grid</span><span class="op">[</span><span class="fu">which.max</span><span class="op">(</span><span class="fu">cumsum</span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span><span class="op">*</span><span class="va">delta</span> <span class="op">&gt;</span> <span class="fl">0.05</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">q95</span> <span class="op">&lt;-</span> <span class="va">theta_grid</span><span class="op">[</span><span class="fu">which.min</span><span class="op">(</span><span class="fu">cumsum</span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span><span class="op">*</span><span class="va">delta</span> <span class="op">&lt;</span> <span class="fl">0.95</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Pr(theta &lt; 0.1)</span></span>
<span><span class="va">Pr_theta_under_0.1</span> <span class="op">&lt;-</span> <span class="fu">sum</span><span class="op">(</span><span class="va">posterior</span><span class="op">[</span><span class="va">theta_grid</span> <span class="op">&lt;</span> <span class="fl">0.1</span><span class="op">]</span><span class="op">)</span><span class="op">*</span><span class="va">delta</span></span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="fu">paste0</span><span class="op">(</span><span class="st">"90% CI = ("</span>, <span class="va">q5</span>,<span class="st">","</span>, <span class="va">q95</span>,<span class="st">")"</span><span class="op">)</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[1] "90% CI = (0.07,0.21)"</code></pre>
</div>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">print</span><span class="op">(</span><span class="fu">paste0</span><span class="op">(</span><span class="st">"Pr(theta &lt; 0.1) = "</span>,</span>
<span>             <span class="fu">round</span><span class="op">(</span><span class="va">Pr_theta_under_0.1</span>, <span class="fl">5</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[1] "Pr(theta &lt; 0.1) = 0.20659"</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="example-3-gamma-model-with-grid-approximation">Example 3: Gamma model with grid approximation<a class="anchor" aria-label="anchor" href="#example-3-gamma-model-with-grid-approximation"></a>
</h2>
<hr class="half-width">
<p>Let’s investigate another model and implement a grid approximation to
fit it.</p>
<p>The gamma distribution arises, for example, in applications that
model the waiting time between consecutive events. Let’s model the
following data points as independent realizations from a <span class="math inline">\(\Gamma(\alpha, \beta)\)</span> distribution with
unknown shape <span class="math inline">\(\alpha\)</span> and rate <span class="math inline">\(\beta\)</span> parameters:</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu">c</span><span class="op">(</span><span class="fl">0.34</span>, <span class="fl">0.2</span>, <span class="fl">0.22</span>, <span class="fl">0.77</span>, <span class="fl">0.46</span>, <span class="fl">0.73</span>, <span class="fl">0.24</span>, <span class="fl">0.66</span>, <span class="fl">0.64</span><span class="op">)</span></span></code></pre>
</div>
<p>We’ll estimate <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> using the grid approximation.
Similarly as before, we’ll first need to define a grid. Since there are
two parameters the parameter space is 2-dimensional and the grid needs
to be defined at all pairwise combinations of the points of the
individual grids.</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">delta</span> <span class="op">&lt;-</span> <span class="fl">0.1</span></span>
<span><span class="va">alpha_grid</span> <span class="op">&lt;-</span> <span class="fu">seq</span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0.01</span>, to <span class="op">=</span> <span class="fl">15</span>, by <span class="op">=</span> <span class="va">delta</span><span class="op">)</span></span>
<span><span class="va">beta_grid</span> <span class="op">&lt;-</span> <span class="fu">seq</span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0.01</span>, to <span class="op">=</span> <span class="fl">25</span>, by <span class="op">=</span> <span class="va">delta</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Get pairwise combinations</span></span>
<span><span class="va">df2</span> <span class="op">&lt;-</span> <span class="fu">expand.grid</span><span class="op">(</span>alpha <span class="op">=</span> <span class="va">alpha_grid</span>, beta <span class="op">=</span> <span class="va">beta_grid</span><span class="op">)</span></span></code></pre>
</div>
<p>Next, we’ll compute the likelihood. As we assumed the data points to
be independently generated from the gamma distribution, the likelihood
is the product of the likelihoods of individual observations.</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Loop over all alpha, beta combinations</span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fu">nrow</span><span class="op">(</span><span class="va">df2</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">df2</span><span class="op">[</span><span class="va">i</span>, <span class="st">"likelihood"</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">prod</span><span class="op">(</span></span>
<span>    <span class="fu">dgamma</span><span class="op">(</span>x <span class="op">=</span> <span class="va">X</span>,</span>
<span>           shape <span class="op">=</span> <span class="va">df2</span><span class="op">[</span><span class="va">i</span>, <span class="st">"alpha"</span><span class="op">]</span>,</span>
<span>           rate <span class="op">=</span> <span class="va">df2</span><span class="op">[</span><span class="va">i</span>, <span class="st">"beta"</span><span class="op">]</span><span class="op">)</span></span>
<span>    <span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre>
</div>
<p>Next, we’ll define priors for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. Only positive values are allowed,
which should be reflected in the prior. We’ll use <span class="math inline">\(\Gamma\)</span> priors with large variances.</p>
<p>Notice, that normalizing the posterior now requires integrating over
both dimensions, hence the <span class="math inline">\(\delta^2\)</span>
below.</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Priors: alpha, beta ~ Gamma(2, .1)</span></span>
<span><span class="va">df2</span> <span class="op">&lt;-</span> <span class="va">df2</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>prior <span class="op">=</span> <span class="fu">dgamma</span><span class="op">(</span>x <span class="op">=</span> <span class="va">alpha</span>, <span class="fl">2</span>, <span class="fl">0.1</span><span class="op">)</span><span class="op">*</span><span class="fu">dgamma</span><span class="op">(</span>x <span class="op">=</span> <span class="va">beta</span>, <span class="fl">2</span>, <span class="fl">0.1</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Posterior</span></span>
<span><span class="va">df2</span> <span class="op">&lt;-</span> <span class="va">df2</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>posterior <span class="op">=</span> <span class="va">prior</span><span class="op">*</span><span class="va">likelihood</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>posterior <span class="op">=</span> <span class="va">posterior</span><span class="op">/</span><span class="op">(</span><span class="fu">sum</span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span><span class="op">*</span><span class="va">delta</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="co"># Normalize</span></span>
<span></span>
<span></span>
<span><span class="co"># Plot</span></span>
<span><span class="va">p_joint_posterior</span> <span class="op">&lt;-</span> <span class="va">df2</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_tile</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">alpha</span>, y <span class="op">=</span> <span class="va">beta</span>, fill <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">scale_fill_gradientn</span><span class="op">(</span>colours <span class="op">=</span> <span class="fu">rainbow</span><span class="op">(</span><span class="fl">5</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="fu">expression</span><span class="op">(</span><span class="va">alpha</span><span class="op">)</span>, y <span class="op">=</span> <span class="fu">expression</span><span class="op">(</span><span class="va">beta</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">p_joint_posterior</span></span></code></pre>
</div>
<figure><img src="../fig/bayesian-statistics-rendered-unnamed-chunk-13-1.png" width="100%" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>Next, we’ll compute the posterior mode, which is a point in the
2-dimensional parameter space.</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">df2</span><span class="op">[</span><span class="fu">which.max</span><span class="op">(</span><span class="va">df2</span><span class="op">$</span><span class="va">posterior</span><span class="op">)</span>, <span class="fu">c</span><span class="op">(</span><span class="st">"alpha"</span>, <span class="st">"beta"</span><span class="op">)</span><span class="op">]</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>      alpha beta
14898  4.71 9.91</code></pre>
</div>
<p>Often, in addition to the parameters of interest, the model contains
parameters we are not interested in. For instance, we might only be
interested in <span class="math inline">\(\alpha\)</span>, in which case
<span class="math inline">\(\beta\)</span> would be a ‘nuisance’
parameter. Nuisance parameters are part of the full (‘joint’) posterior,
but they can be discarded by integrating the joint posterior over these
parameters. A posterior integrated over some parameters is called a
marginal posterior.</p>
<p>Let’s now compute the marginal posterior for <span class="math inline">\(\alpha\)</span> by integrating over <span class="math inline">\(\beta\)</span>. Intuitively, it can be helpful to
think of marginalization as a process where all of the joint posterior
mass is drawn towards the <span class="math inline">\(\alpha\)</span>
axis, as if drawn by a gravitational force.</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Get marginal posterior for alpha</span></span>
<span><span class="va">alpha_posterior</span> <span class="op">&lt;-</span> <span class="va">df2</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">group_by</span><span class="op">(</span><span class="va">alpha</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">summarize</span><span class="op">(</span>posterior <span class="op">=</span> <span class="fu">sum</span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>posterior <span class="op">=</span> <span class="va">posterior</span><span class="op">/</span><span class="op">(</span><span class="fu">sum</span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span><span class="op">*</span><span class="va">delta</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">p_alpha_posterior</span> <span class="op">&lt;-</span> <span class="va">alpha_posterior</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_line</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">alpha</span>, y <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span>, </span>
<span>            color <span class="op">=</span> <span class="va">posterior_color</span>, </span>
<span>            linewidth <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="fu">expression</span><span class="op">(</span><span class="va">alpha</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">p_alpha_posterior</span></span></code></pre>
</div>
<figure><img src="../fig/bayesian-statistics-rendered-unnamed-chunk-15-1.png" width="100%" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><div id="discussion2" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<span class="callout-header">Discussion</span>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>Does the MAP of the joint posterior of <span class="math inline">\(\theta = (\alpha, \beta)\)</span> correspond to
the MAPs of the marginal posteriors of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>?</p>
</div>
</div>
</div>
<div id="callout1" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div class="callout-inner">
<div class="callout-content">
<p>The conjugate prior for the Gamma likelihood <a href="https://en.wikipedia.org/wiki/Gamma_distribution#Bayesian_inference" class="external-link">exists</a>,
which means there is a prior that causes the posterior to be of the same
shape.</p>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="working-with-samples">Working with samples<a class="anchor" aria-label="anchor" href="#working-with-samples"></a>
</h2>
<hr class="half-width">
<p>The main limitation of the grid approximation is that it becomes
impractical for models with even a moderate number of parameters. The
reason is that the number of computations grows as <span class="math inline">\(O \{ \Delta^p \}\)</span> where <span class="math inline">\(\Delta\)</span> is the number of grid points per
model parameter and <span class="math inline">\(p\)</span> the number of
parameters. This quickly becomes prohibitive, and the grid approximation
is seldom used in practice. The standard approach to fitting Bayesian
models is to draw samples from the posterior with Markov chain Monte
Carlo (MCMC) methods. These methods are the topic of a later episode but
we’ll anticipate this now by studying how posterior summaries can be
computed based on samples.</p>
</section><section><h2 class="section-heading" id="example-4-handedness-with-samples">Example 4: handedness with samples<a class="anchor" aria-label="anchor" href="#example-4-handedness-with-samples"></a>
</h2>
<hr class="half-width">
<p>Let’s take the beta-binomial model (beta prior, binomial likelihood)
of the handedness analysis as our example. It is an instance of a model
for which the posterior can be computed analytically. Given a prior
<span class="math inline">\(\text{Beta}(\alpha, \beta)\)</span> and
likelihood <span class="math inline">\(\text{Bin}(x | N,
\theta)\)</span>, the posterior is <span class="math display">\[p(\theta
| X) = \text{Beta}(\alpha + x, \beta + N - x).\]</span> Let’s generate
<span class="math inline">\(n = 1000\)</span> samples from this
posterior using the handedness data:</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">1000</span></span>
<span><span class="va">theta_samples</span> <span class="op">&lt;-</span> <span class="fu">rbeta</span><span class="op">(</span><span class="va">n</span>, <span class="fl">1</span> <span class="op">+</span> <span class="fl">7</span>, <span class="fl">10</span> <span class="op">+</span> <span class="fl">50</span> <span class="op">-</span> <span class="fl">7</span><span class="op">)</span></span></code></pre>
</div>
<p>Plotting a histogram of these samples against the grid approximation
posterior displays that both are indeed approximating the same
distribution</p>
<div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>data <span class="op">=</span> <span class="va">theta_samples</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">data.frame</span><span class="op">(</span>theta <span class="op">=</span> <span class="va">.</span><span class="op">)</span>, </span>
<span>  <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">theta</span>, y <span class="op">=</span> <span class="fu">after_stat</span><span class="op">(</span><span class="va">density</span><span class="op">)</span><span class="op">)</span>, bins <span class="op">=</span> <span class="fl">50</span>, </span>
<span>  fill <span class="op">=</span> <span class="va">posterior_color</span>, color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">geom_line</span><span class="op">(</span>data <span class="op">=</span> <span class="va">df1</span>,</span>
<span>            <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">theta</span>, y <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span>,</span>
<span>            linewidth <span class="op">=</span> <span class="fl">1.5</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>data <span class="op">=</span> <span class="va">df1</span>, </span>
<span>            <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">theta</span>, y <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span>, </span>
<span>            color <span class="op">=</span> <span class="va">posterior_color</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="fu">expression</span><span class="op">(</span><span class="va">theta</span><span class="op">)</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/bayesian-statistics-rendered-unnamed-chunk-17-1.png" width="100%" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>Computing posterior summaries from samples is easy. The posterior
mean and variance are computed simply by taking the mean and variance of
the samples, respectively. Posterior intervals are equally easy to
compute: 90% CI is recovered from the appropriate quantiles and the
probability of a certain parameter interval is the proportion of total
samples within the interval.</p>
<div id="discussion3" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<span class="callout-header">Discussion</span>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>Compute the posterior mean, variance, 90% CI and <span class="math inline">\(Pr(\theta &gt; 0.1)\)</span> using the generated
samples.</p>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="posterior-predictive-distribution">Posterior predictive distribution<a class="anchor" aria-label="anchor" href="#posterior-predictive-distribution"></a>
</h2>
<hr class="half-width">
<p>Now we have learned how to fit a probabilistic model using the grid
approximation and how to compute posterior summaries of the model
parameters based on the fit or with posterior samples. A potentially
interesting question that the posterior doesn’t directly answer is what
do possible unobserved data values <span class="math inline">\(\tilde{X}\)</span> look like, conditional on the
observed values <span class="math inline">\(X\)</span>.</p>
<p>The unknown value can be predicted using the <em>posterior predictive
distribution</em> <span class="math inline">\(p(\tilde{X} | X) = \int
p(\tilde{X} | \theta) p(\theta | X) d\theta\)</span>. Using samples,
this distribution can be sampled from by first drawing a value <span class="math inline">\(\theta^s\)</span> from the posterior and then
generating a random value from the likelihood function <span class="math inline">\(p(\tilde{X} | \theta^s)\)</span>.</p>
<p>A posterior predictive distribution for the beta-binomial model,
using the posterior samples of the previous example can be generated
as</p>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ppd</span> <span class="op">&lt;-</span> <span class="fu">rbinom</span><span class="op">(</span><span class="fu">length</span><span class="op">(</span><span class="va">theta_samples</span><span class="op">)</span>, <span class="fl">50</span>, prob <span class="op">=</span> <span class="va">theta_samples</span><span class="op">)</span></span></code></pre>
</div>
<p>In other words, this is the distribution of the number of left-handed
people in a yet unseen sample of 50 people. Let’s plot the histogram of
these samples and compare it to the observed data (red vertical
line):</p>
<div class="codewrapper sourceCode" id="cb21">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>data <span class="op">=</span> <span class="fu">data.frame</span><span class="op">(</span><span class="va">ppd</span><span class="op">)</span>, </span>
<span>                 <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">ppd</span>, y <span class="op">=</span> <span class="fu">after_stat</span><span class="op">(</span><span class="va">density</span><span class="op">)</span><span class="op">)</span>, binwidth <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">7</span>, color <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/bayesian-statistics-rendered-unnamed-chunk-19-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Likelihood determines the probability of data conditional on the
model parameters.</li>
<li>Prior encodes beliefs about the model parameters without considering
data.</li>
<li>Posterior quantifies the probability of parameter values conditional
on the data.</li>
<li>The posterior is a compromise between the data and prior. The less
data available, the greater the impact of the prior.</li>
<li>The grid approximation is a method for inferring the (approximate)
posterior distribution.</li>
<li>Posterior information can be summarized with point estimates and
posterior intervals.</li>
<li>The marginal posterior is accessed by integrating over nuisance
parameters.</li>
<li>Usually, Bayesian models are fitted using methods that generate
samples from the posterior.</li>
</ul>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="reading">Reading<a class="anchor" aria-label="anchor" href="#reading"></a>
</h2>
<hr class="half-width">
<ul>
<li>Bayesian Data Analysis (3rd ed.): Ch. 1-3</li>
<li>Statistical Rethinking (2nd ed.): Ch. 1-3</li>
<li>Bayes Rules!: Ch. 1-6</li>
</ul>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 --></section></section><section id="aio-stan"><p>Content from <a href="stan.html">Stan</a></p>
<hr>
<p>Last updated on 2025-08-22 |

        <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/edit/main/episodes/stan.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 64 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can posterior samples be generated using Stan?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<p>Learn how to</p>
<ul>
<li>implement statistical models in Stan.</li>
<li>generate posterior samples with Stan.</li>
<li>extract and process samples generated with Stan.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>Stan is a probabilistic programming language that can be used to
specify probabilistic models and to generate samples from posterior
distributions.</p>
<p>The standard steps is using Stan is to first write the statistical
model in a separate text file, then to call Stan from R (or other
supported interface) which performs the sampling. Instead of having to
write formulas the model can be written using built-in functions and
sampling statements similar to written text. The sampling process is
performed with a Markov Chain Monte Carlo (MCMC) algorithm, which we
will study in a later episode. For now, however, our focus is on
understanding how to execute it using Stan.</p>
<p>Several R packages have been built that simplify Stan usage. For
example, brms allows specifying models via R’s customary formula syntax,
while bayesplot provides a library of plotting functions. In this
lesson, however, we will first learn using Stan from the bottom-up, by
writing Stan programs, extracting the posterior samples and generating
the plots ourselves. Later, in episode 7, we’ll introduce the usage of
some of these additional packages.</p>
<p>To get started, follow the instructions provided at <a href="https://mc-stan.org/users/interfaces/" class="external-link uri">https://mc-stan.org/users/interfaces/</a> to install Stan on
your local computer.</p>
<div id="callout1" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div class="callout-inner">
<div class="callout-content">
<p>With Stan, you can fit model that have continuous parameters. Models
with discrete parameters such as most classification models are
typically impossible to fit, although some workarounds have been
implemented.</p>
</div>
</div>
</div>
<section><h2 class="section-heading" id="basic-program-structure">Basic program structure<a class="anchor" aria-label="anchor" href="#basic-program-structure"></a>
</h2>
<hr class="half-width">
<p>A Stan program is organized into several blocks that collectively
define the model. Typically, a Stan program includes at least the
following blocks:</p>
<ol style="list-style-type: decimal">
<li><p>Data: This block is used to declare the input data provided to
the model. It specifies the types and dimensions of the data variables
incorporated into the model.</p></li>
<li><p>Parameters: In this block, the model parameters are
declared.</p></li>
<li><p>Model: The likelihood and prior distributions are included here
through sampling statements.</p></li>
</ol>
<p>For best practices, it is recommended to specify Stan programs in
separate text files with a .stan extension, which can then be called
from R.</p>
</section><section><h2 class="section-heading" id="example-1-beta-binomial-model">Example 1: Beta-binomial model<a class="anchor" aria-label="anchor" href="#example-1-beta-binomial-model"></a>
</h2>
<hr class="half-width">
<p>The following Stan program specifies the Beta-binomial model, and
consists of data, parameters, and model blocks.</p>
<p>The data variables are the total sample size <span class="math inline">\(N\)</span> and <span class="math inline">\(x\)</span>, the outcome of a binary variable (coin
flip, handedness etc.). The declared data type is <code>int</code> for
integer, and the variables have a lower bound 1 and 0 for <span class="math inline">\(N\)</span> and <span class="math inline">\(x\)</span>, respectively. Notice that each line
ends with a semicolon.</p>
<p>In the parameters block we declare <span class="math inline">\(\theta\)</span>, the probability for a success.
Since this parameter is a probability, it is a real number restricted
between 0 and 1.</p>
<p>In the model block, the likelihood is specified with the sampling
statement <code>x ~ binomial(N, theta)</code>. This line includes the
binomial distribution <span class="math inline">\(\text{Bin}(x | N,
theta)\)</span> in the target distribution. The prior is set similarly,
and omitting the prior implies a uniform prior. Comments can be included
after two forward slashes.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">STAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode stan" tabindex="0"><code class="sourceCode stan"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a>  <span class="kw">data</span>{</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a>    <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N; </span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>    <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; x; </span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>  }</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>  </span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>  <span class="kw">parameters</span>{</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>    <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>, <span class="kw">upper</span>=<span class="dv">1</span>&gt; theta;</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>  }</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>  </span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a>  <span class="kw">model</span>{</span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a>    </span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a>    <span class="co">// Likelihood</span></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>    x ~ binomial(N, theta);</span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>    </span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a>    <span class="co">// Uniform prior</span></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a>  }</span></code></pre>
</div>
<p>When the Stan program has been saved we need to compile it. In R,
this is done by running the following line, where
<code>"binomial_model.stan"</code> is the path of the program file.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">binomial_model</span> <span class="op">&lt;-</span> <span class="fu">stan_model</span><span class="op">(</span><span class="st">"binomial_model.stan"</span><span class="op">)</span></span></code></pre>
</div>
<p>Once the program has been compiled, it can be used to generate the
posterior samples by calling the function <code>sampling()</code>. The
data needs to be input as a list.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">set.seed</span><span class="op">(</span><span class="fl">135</span><span class="op">)</span></span>
<span></span>
<span><span class="va">binom_data</span> <span class="op">&lt;-</span> <span class="fu">list</span><span class="op">(</span>N <span class="op">=</span> <span class="fl">50</span>, x <span class="op">=</span> <span class="fl">7</span><span class="op">)</span></span>
<span></span>
<span><span class="va">binom_samples</span> <span class="op">&lt;-</span> <span class="fu">sampling</span><span class="op">(</span>object <span class="op">=</span> <span class="va">binomial_model</span>,</span>
<span>                          data <span class="op">=</span> <span class="va">binom_data</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>
SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1:
Chain 1: Gradient evaluation took 3e-06 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1:
Chain 1:
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1:
Chain 1:  Elapsed Time: 0.004 seconds (Warm-up)
Chain 1:                0.003 seconds (Sampling)
Chain 1:                0.007 seconds (Total)
Chain 1:

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2:
Chain 2: Gradient evaluation took 1e-06 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.01 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2:
Chain 2:
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2:
Chain 2:  Elapsed Time: 0.004 seconds (Warm-up)
Chain 2:                0.003 seconds (Sampling)
Chain 2:                0.007 seconds (Total)
Chain 2:

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3:
Chain 3: Gradient evaluation took 1e-06 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.01 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3:
Chain 3:
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3:
Chain 3:  Elapsed Time: 0.004 seconds (Warm-up)
Chain 3:                0.003 seconds (Sampling)
Chain 3:                0.007 seconds (Total)
Chain 3:

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4:
Chain 4: Gradient evaluation took 1e-06 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.01 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4:
Chain 4:
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4:
Chain 4:  Elapsed Time: 0.004 seconds (Warm-up)
Chain 4:                0.003 seconds (Sampling)
Chain 4:                0.007 seconds (Total)
Chain 4: </code></pre>
</div>
<p>With the default settings, Stan executes 4 MCMC chains, each with
2000 iterations (more about this in the next episode). During the run,
Stan provides progress information, aiding in estimating the running
time, particularly for complex models or extensive datasets. In this
case the sampling took only a fraction of a second.</p>
<p>Running <code>binom_samples</code>, a summary for the model parameter
<span class="math inline">\(p\)</span> is printed, facilitating a quick
review of the results.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">binom_samples</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Inference for Stan model: anon_model.
4 chains, each with iter=2000; warmup=1000; thin=1;
post-warmup draws per chain=1000, total post-warmup draws=4000.

        mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
theta   0.16    0.00 0.05   0.07   0.12   0.15   0.18   0.26  1545    1
lp__  -22.80    0.02 0.69 -24.75 -22.93 -22.53 -22.37 -22.33  1987    1

Samples were drawn using NUTS(diag_e) at Fri Aug 22 10:21:35 2025.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at
convergence, Rhat=1).</code></pre>
</div>
<p>This summary can also be accessed as a matrix with
<code>summary(binom_samples)$summary</code>.</p>
<p>Often, however, it is necessary process the individual samples. These
can be extracted as follows:</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">theta_samples</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">extract</span><span class="op">(</span><span class="va">binom_samples</span>, <span class="st">"theta"</span><span class="op">)</span><span class="op">[[</span><span class="st">"theta"</span><span class="op">]</span><span class="op">]</span></span></code></pre>
</div>
<p>Now we can use the methods presented in the previous Episode to
compute posterior summaries, credible intervals and to generate
figures.</p>
<div id="challenge1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>Compute the 95% credible intervals for the samples drawn with Stan.
What is the probability that <span class="math inline">\(\theta \in
(0.05, 0.15)\)</span>? Plot a histogram of the posterior samples.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">CI95</span> <span class="op">&lt;-</span> <span class="fu">quantile</span><span class="op">(</span><span class="va">theta_samples</span>, probs <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="fl">0.025</span>, <span class="fl">0.975</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">theta_between_0.05_0.15</span> <span class="op">&lt;-</span> <span class="fu">mean</span><span class="op">(</span><span class="va">theta_samples</span><span class="op">&gt;</span><span class="fl">0.05</span> <span class="op">&amp;</span> <span class="va">theta_samples</span><span class="op">&lt;</span><span class="fl">0.15</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span>data <span class="op">=</span> <span class="fu">data.frame</span><span class="op">(</span>theta <span class="op">=</span> <span class="va">theta_samples</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">theta</span><span class="op">)</span>, bins <span class="op">=</span> <span class="fl">30</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">coord_cartesian</span><span class="op">(</span>xlim <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="va">p</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/stan-rendered-unnamed-chunk-7-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure>
</div>
</div>
</div>
</div>
<div id="challenge2" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>Try modifying the Stan program so that you add a <span class="math inline">\(Beta(\alpha, \beta)\)</span> prior for <span class="math inline">\(\theta\)</span>.</p>
<p>Can you modify the Stan program further so that you can set the
hyperparameters <span class="math inline">\(\alpha, \beta\)</span> as
part of the data? What is the benefit of using this approach?</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" data-bs-parent="#accordionSolution2" aria-labelledby="headingSolution2">
<div class="accordion-body">
<p>Modifying the data block so that it declares the hyperparameters as
data (e.g. <code>real&lt;lower=0&gt; alpha;</code>) enables setting the
hyperparameter values as part of data. This makes it possible to change
the hyperparameters without modifying the Stan file.</p>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="additional-stan-blocks">Additional Stan blocks<a class="anchor" aria-label="anchor" href="#additional-stan-blocks"></a>
</h2>
<hr class="half-width">
<p>In addition to the data, parameters, and model blocks there are
additional blocks that can be included in the program.</p>
<ol style="list-style-type: decimal">
<li><p>Functions: For user-defined functions. This block must be the
first in the Stan program. It allows users to define custom
functions.</p></li>
<li><p>Transformed data: This block is used for transformations of the
data variables. It is often employed to preprocess or modify the input
data before it is used in the main model. Common tasks include
standardization, scaling, or other data adjustments.</p></li>
<li><p>Transformed parameters: In this block, transformations of the
parameters are defined. If transformed parameters are used on the
left-hand side of sampling statements in the model block, the Jacobian
adjustment for the posterior density needs to be included in the model
block as well.</p></li>
<li><p>Generated quantities: This block is used to define quantities
based on both data and model parameters. These quantities are not part
of the model but are useful for post-processing.</p></li>
</ol>
<p>We will make use of these additional structures in subsequent
illustrations.</p>
</section><section><h2 class="section-heading" id="example-2-normal-model">Example 2: Normal model<a class="anchor" aria-label="anchor" href="#example-2-normal-model"></a>
</h2>
<hr class="half-width">
<p>Next, let’s implement the normal model in Stan. First we’ll generate
some data <span class="math inline">\(X\)</span> from a normal model
with unknown mean and standard deviation parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span></p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Sample size</span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">99</span></span>
<span></span>
<span><span class="co"># Generate data with unknown parameters</span></span>
<span><span class="va">unknown_sigma</span> <span class="op">&lt;-</span> <span class="fu">runif</span><span class="op">(</span><span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">unknown_mu</span> <span class="op">&lt;-</span> <span class="fu">runif</span><span class="op">(</span><span class="fl">1</span>, <span class="op">-</span><span class="fl">5</span>, <span class="fl">5</span><span class="op">)</span></span>
<span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu">rnorm</span><span class="op">(</span>n <span class="op">=</span> <span class="va">N</span>,</span>
<span>           mean <span class="op">=</span> <span class="va">unknown_mu</span>,</span>
<span>           sd <span class="op">=</span> <span class="va">unknown_sigma</span><span class="op">)</span> </span>
<span></span>
<span><span class="va">normal_data</span> <span class="op">&lt;-</span> <span class="fu">list</span><span class="op">(</span>N <span class="op">=</span> <span class="va">N</span>, X <span class="op">=</span> <span class="va">X</span><span class="op">)</span></span></code></pre>
</div>
<p>The Stan program for the normal model is specified in the next code
chunk. It introduces a new data type (vector) and leverages
vectorization in the likelihood statement. In the end of the program, a
generated quantities block is included which generates new data
(X_tilde) to estimate what unseen data points might look like. This
resulting distribution is referred to as the <em>posterior predictive
distribution</em>, which is generated by drawing a random realization
from the normal distribution for each posterior sample <span class="math inline">\((\mu, \sigma)\)</span>.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">STAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode stan" tabindex="0"><code class="sourceCode stan"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N;</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>  <span class="dt">vector</span>[N] X;</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>}</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>  <span class="dt">real</span> mu;</span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; sigma;</span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>}</span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a>  <span class="co">// Vectorized likelihood</span></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a>  X ~ normal(mu, sigma);</span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a>  </span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a>  <span class="co">// Priors</span></span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a>  mu ~ normal(<span class="dv">0</span>, <span class="dv">1</span>);</span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a>  sigma ~ gamma(<span class="dv">2</span>, <span class="dv">1</span>);</span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a>}</span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a><span class="kw">generated quantities</span> {</span>
<span id="cb10-18"><a href="#cb10-18" tabindex="-1"></a>  <span class="dt">real</span> X_tilde;</span>
<span id="cb10-19"><a href="#cb10-19" tabindex="-1"></a>  X_tilde = normal_rng(mu, sigma);</span>
<span id="cb10-20"><a href="#cb10-20" tabindex="-1"></a>}</span></code></pre>
</div>
<p>Let’s fit the model to the data</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">normal_samples</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">sampling</span><span class="op">(</span><span class="va">normal_model</span>, </span>
<span>                                  <span class="va">normal_data</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>
SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1:
Chain 1: Gradient evaluation took 5e-06 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1:
Chain 1:
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1:
Chain 1:  Elapsed Time: 0.008 seconds (Warm-up)
Chain 1:                0.008 seconds (Sampling)
Chain 1:                0.016 seconds (Total)
Chain 1:

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2:
Chain 2: Gradient evaluation took 2e-06 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2:
Chain 2:
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2:
Chain 2:  Elapsed Time: 0.009 seconds (Warm-up)
Chain 2:                0.008 seconds (Sampling)
Chain 2:                0.017 seconds (Total)
Chain 2:

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3:
Chain 3: Gradient evaluation took 2e-06 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3:
Chain 3:
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3:
Chain 3:  Elapsed Time: 0.009 seconds (Warm-up)
Chain 3:                0.007 seconds (Sampling)
Chain 3:                0.016 seconds (Total)
Chain 3:

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4:
Chain 4: Gradient evaluation took 2e-06 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4:
Chain 4:
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4:
Chain 4:  Elapsed Time: 0.008 seconds (Warm-up)
Chain 4:                0.008 seconds (Sampling)
Chain 4:                0.016 seconds (Total)
Chain 4: </code></pre>
</div>
<p>Next, we’ll extract posterior samples and generate a plot for the
joint, and marginal posteriors. The true unknown parameter values are
included in the plots in red.</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Extract parameter samples</span></span>
<span><span class="va">par_samples</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">extract</span><span class="op">(</span><span class="va">normal_samples</span>, <span class="fu">c</span><span class="op">(</span><span class="st">"mu"</span>, <span class="st">"sigma"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">do.call</span><span class="op">(</span><span class="va">cbind</span>, <span class="va">.</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="va">data.frame</span></span>
<span></span>
<span></span>
<span><span class="co"># Full posterior</span></span>
<span><span class="va">p_posterior</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span>data <span class="op">=</span> <span class="va">par_samples</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_point</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">mu</span>, y <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">annotate</span><span class="op">(</span><span class="st">"point"</span>, x <span class="op">=</span> <span class="va">unknown_mu</span>, y <span class="op">=</span> <span class="va">unknown_sigma</span>, </span>
<span>           color <span class="op">=</span> <span class="st">"red"</span>, size <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Marginal posteriors</span></span>
<span><span class="va">p_marginals</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span>data <span class="op">=</span> <span class="va">par_samples</span> <span class="op">%&gt;%</span> <span class="va">gather</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">value</span><span class="op">)</span>, bins <span class="op">=</span> <span class="fl">40</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>data <span class="op">=</span> <span class="fu">data.frame</span><span class="op">(</span>key <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="st">"mu"</span>, <span class="st">"sigma"</span><span class="op">)</span>, </span>
<span>                               value <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="va">unknown_mu</span>, <span class="va">unknown_sigma</span><span class="op">)</span><span class="op">)</span>, </span>
<span>             <span class="fu">aes</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">value</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"red"</span>, linewidth <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">facet_wrap</span><span class="op">(</span><span class="op">~</span><span class="va">key</span>, scales <span class="op">=</span> <span class="st">"free"</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fu">cowplot</span><span class="fu">::</span><span class="fu">plot_grid</span><span class="op">(</span><span class="va">p_posterior</span>, <span class="va">p_marginals</span>,</span>
<span>                        ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="va">p</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/stan-rendered-unnamed-chunk-11-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>Let’s also plot the posterior predictive distribution samples
histogram and compare it to that of the data.</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">PPD</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">extract</span><span class="op">(</span><span class="va">normal_samples</span>, <span class="fu">c</span><span class="op">(</span><span class="st">"X_tilde"</span><span class="op">)</span><span class="op">)</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">data.frame</span><span class="op">(</span>X_tilde <span class="op">=</span> <span class="va">.</span> <span class="op">)</span></span>
<span></span>
<span><span class="va">p_PPD</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>data <span class="op">=</span> <span class="va">PPD</span>, </span>
<span>                 <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">X_tilde</span>, y <span class="op">=</span> <span class="fu">after_stat</span><span class="op">(</span><span class="va">density</span><span class="op">)</span><span class="op">)</span>, </span>
<span>                 bins <span class="op">=</span> <span class="fl">30</span>, fill <span class="op">=</span> <span class="va">posterior_color</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>data <span class="op">=</span> <span class="fu">data.frame</span><span class="op">(</span><span class="va">X</span><span class="op">)</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">X</span>, y <span class="op">=</span> <span class="fu">after_stat</span><span class="op">(</span><span class="va">density</span><span class="op">)</span><span class="op">)</span>, </span>
<span>                 bins <span class="op">=</span> <span class="fl">30</span>, alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="va">p_PPD</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/stan-rendered-unnamed-chunk-12-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure></section><section><h2 class="section-heading" id="example-3-linear-regression">Example 3: Linear regression<a class="anchor" aria-label="anchor" href="#example-3-linear-regression"></a>
</h2>
<hr class="half-width">
<div id="challenge3" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>Write a Stan program for linear regression with one dependent
variable.</p>
<p>Generate data from the linear model and use the Stan program to
estimate the intercept <span class="math inline">\(\alpha\)</span>,
slope <span class="math inline">\(\beta\)</span>, and noise term <span class="math inline">\(\sigma\)</span>.</p>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3"> Show me the solution </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" data-bs-parent="#accordionSolution3" aria-labelledby="headingSolution3">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">STAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode stan" tabindex="0"><code class="sourceCode stan"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N; <span class="co">// Sample size</span></span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a>  <span class="dt">vector</span>[N] x; <span class="co">// x-values</span></span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>  <span class="dt">vector</span>[N] y; <span class="co">// y-values</span></span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>}</span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a>  <span class="dt">real</span> alpha; <span class="co">// intercept</span></span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a>  <span class="dt">real</span> beta;  <span class="co">// slope</span></span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; sigma; <span class="co">// noise</span></span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a>}</span>
<span id="cb15-11"><a href="#cb15-11" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb15-13"><a href="#cb15-13" tabindex="-1"></a>  </span>
<span id="cb15-14"><a href="#cb15-14" tabindex="-1"></a>  <span class="co">// Likelihood</span></span>
<span id="cb15-15"><a href="#cb15-15" tabindex="-1"></a>  y ~ normal(alpha + beta * x, sigma);</span>
<span id="cb15-16"><a href="#cb15-16" tabindex="-1"></a>  </span>
<span id="cb15-17"><a href="#cb15-17" tabindex="-1"></a>  <span class="co">// Priors</span></span>
<span id="cb15-18"><a href="#cb15-18" tabindex="-1"></a>  alpha ~ normal(<span class="dv">0</span>, <span class="dv">1</span>);</span>
<span id="cb15-19"><a href="#cb15-19" tabindex="-1"></a>  beta ~ normal(<span class="dv">0</span>, <span class="dv">1</span>);</span>
<span id="cb15-20"><a href="#cb15-20" tabindex="-1"></a>  sigma ~ inv_gamma(<span class="dv">1</span>, <span class="dv">1</span>);</span>
<span id="cb15-21"><a href="#cb15-21" tabindex="-1"></a>}</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<div id="challenge4" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>Modify the program for linear regression so it facilitates <span class="math inline">\(M\)</span> dependent variables.</p>
</div>
</div>
</div>
<div id="accordionSolution4" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution4" aria-expanded="false" aria-controls="collapseSolution4">
  <h4 class="accordion-header" id="headingSolution4"> Show me the solution </h4>
</button>
<div id="collapseSolution4" class="accordion-collapse collapse" data-bs-parent="#accordionSolution4" aria-labelledby="headingSolution4">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">STAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode stan" tabindex="0"><code class="sourceCode stan"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a></span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N; <span class="co">// Sample size</span></span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; M; <span class="co">// Number of features</span></span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a>  <span class="dt">matrix</span>[N, M] x; <span class="co">// x-values</span></span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a>  <span class="dt">vector</span>[N] y; <span class="co">// y-values</span></span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a>}</span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a>  <span class="dt">real</span> alpha; <span class="co">// intercept</span></span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a>  <span class="dt">vector</span>[M] beta;  <span class="co">// slopes</span></span>
<span id="cb16-11"><a href="#cb16-11" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; sigma; <span class="co">// noise</span></span>
<span id="cb16-12"><a href="#cb16-12" tabindex="-1"></a>}</span>
<span id="cb16-13"><a href="#cb16-13" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb16-15"><a href="#cb16-15" tabindex="-1"></a>  </span>
<span id="cb16-16"><a href="#cb16-16" tabindex="-1"></a>  <span class="co">// Likelihood</span></span>
<span id="cb16-17"><a href="#cb16-17" tabindex="-1"></a>  y ~ normal(alpha + x * beta, sigma);</span>
<span id="cb16-18"><a href="#cb16-18" tabindex="-1"></a>  </span>
<span id="cb16-19"><a href="#cb16-19" tabindex="-1"></a>  <span class="co">// Priors</span></span>
<span id="cb16-20"><a href="#cb16-20" tabindex="-1"></a>  alpha ~ normal(<span class="dv">0</span>, <span class="dv">1</span>);</span>
<span id="cb16-21"><a href="#cb16-21" tabindex="-1"></a>  beta ~ normal(<span class="dv">0</span>, <span class="dv">1</span>);</span>
<span id="cb16-22"><a href="#cb16-22" tabindex="-1"></a>  sigma ~ inv_gamma(<span class="dv">1</span>, <span class="dv">1</span>);</span>
<span id="cb16-23"><a href="#cb16-23" tabindex="-1"></a>}</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Stan is a tool for efficient posterior distribution sample
generation.</li>
<li>A Stan program is specified in a separate text file that consists of
code blocks, with the data, parameters, and model blocks being the most
crucial ones.</li>
</ul>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="resources">Resources<a class="anchor" aria-label="anchor" href="#resources"></a>
</h2>
<hr class="half-width">
<ul>
<li>Official release paper <a href="https://www.jstatsoft.org/article/view/v076i01" class="external-link uri">https://www.jstatsoft.org/article/view/v076i01</a>
</li>
<li>User’s guide <a href="https://mc-stan.org/docs/2_18/stan-users-guide/" class="external-link uri">https://mc-stan.org/docs/2_18/stan-users-guide/</a>
</li>
<li>Function’s reference <a href="https://mc-stan.org/docs/functions-reference/" class="external-link uri">https://mc-stan.org/docs/functions-reference/</a>
</li>
<li>Reference manual <a href="https://mc-stan.org/docs/reference-manual/" class="external-link uri">https://mc-stan.org/docs/reference-manual/</a>
</li>
<li>Stan forum <a href="https://discourse.mc-stan.org" class="external-link uri">https://discourse.mc-stan.org</a>
</li>
<li>Case studies <a href="https://mc-stan.org/users/documentation/case-studies" class="external-link uri">https://mc-stan.org/users/documentation/case-studies</a>
</li>
</ul></section><section><h2 class="section-heading" id="reading">Reading<a class="anchor" aria-label="anchor" href="#reading"></a>
</h2>
<hr class="half-width">
<ul>
<li>BDA3: Ch. 12.6, Appendix C</li>
<li>Bayes Rules!: Ch. 6.2</li>
</ul>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 --></section></section><section id="aio-mcmc"><p>Content from <a href="mcmc.html">Markov chain Monte Carlo</a></p>
<hr>
<p>Last updated on 2025-08-22 |

        <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/edit/main/episodes/mcmc.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 63 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How does Stan generate the posterior samples?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<p>Learn</p>
<ul>
<li>the basic idea of the Metropolis-Hasting algorithm.</li>
<li>how to assess Markov chain Monte Carlo convergence.</li>
<li>how to implement a random walk Metropolis-Hasting algorithm.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>The standard solution to fitting probabilistic models is to generate
random samples from the posterior distribution. In the previous episode,
we learned how to generate posterior samples using Stan without knowing
how the samples are generated. In this episode, we’ll study Markov chain
Monte Carlo (MCMC) methods, which are the class of algorithms Stan uses
under the hood.</p>
<section><h2 class="section-heading" id="metropolis-hastings-algorithm">Metropolis-Hastings algorithm<a class="anchor" aria-label="anchor" href="#metropolis-hastings-algorithm"></a>
</h2>
<hr class="half-width">
<p>MCMC methods draw samples from the posterior distribution by
constructing sequences (chains) of values in the parameter space that
ultimately converge to the posterior. While there are other variants of
MCMC, on this course we will mainly focus on the Metropolis-Hasting (MH)
algorithm outlined below. As this algorithm is ran long enough,
convergence to posterior (or to other specified target density) is
guaranteed. This means that that if the chain is run long enough, the
samples will eventually start approximating the posterior
distribution.</p>
<p>A chain starts is initialized at value <span class="math inline">\(\theta^{0}\)</span>, which can be manually set or
random. The only precondition is that the target distribution has
positive mass at the location, <span class="math inline">\(p(\theta^{0}
| X) &gt; 0\)</span>. Then, a proposal <span class="math inline">\(\theta^*\)</span> for the next value is generated
from a proposal distribution <span class="math inline">\(T_i\)</span>.
An often-used solution is the normal distribution centered at the
current value, <span class="math inline">\(\theta^* \sim N(\theta^{i},
\sigma^2)\)</span>. This is where the term “Markov chain” comes from,
the value of each element depends only on the previous one.</p>
<p>Next, the proposal <span class="math inline">\(\theta^*\)</span> is
either accepted or rejected. If each proposal was accepted, the sequence
would simply be a random walk in the parameter space and would not
approximate the posterior to any degree. The rule that determines the
acceptance should reflect this; proposals towards higher posterior
densities should be favored over proposals toward low density areas. The
solution is to compute the ratio</p>
<p><span class="math display">\[r = \frac{p(\theta^* | X) / T_i(\theta^*
| \theta^{i})}{p(\theta^i | X) / T_i(\theta^{i} | \theta^{*})},\]</span>
and use is as the probability to move to the proposed value. In other
words, the next element in the chain is <span class="math inline">\(\theta^{i+1} = \theta^*\)</span> with probability
<span class="math inline">\(\min(r, 1)\)</span>. If the proposal is not
accepted the chain stays at the current value, <span class="math inline">\(\theta^{i+1} = \theta^{i}.\)</span> This approach
induces directional randomness in the chain; proposals towards higher
density areas are generally accepted but transitions away from it are
also possible. In situations where the transition density is symmetric,
such as with the normal distribution, <span class="math inline">\(r\)</span> reduces simply to the ratio of the
posterior values, and all proposals toward higher posterior density
areas are accepted.</p>
</section><section><h2 class="section-heading" id="example-banana-distribution">Example: Banana distribution<a class="anchor" aria-label="anchor" href="#example-banana-distribution"></a>
</h2>
<hr class="half-width">
<p>Let’s implement the MH algorithm and use it to generate posterior
samples from the following statistical model:</p>
<p><span class="math display">\[X \sim N(\theta_1 + \theta_2^2, 1) \\
\theta_1, \theta_2 \sim N(0, 1),\]</span></p>
<p>where <span class="math inline">\(X\)</span> is univariate data and
<span class="math inline">\(\theta_1, \theta_2\)</span> the
parameters.</p>
<div class="section level4">
<h4 id="helper-functions">Helper functions<a class="anchor" aria-label="anchor" href="#helper-functions"></a>
</h4>
<p>We begin by writing some helper functions that carry out the
incremental steps of the MH algorithm.</p>
<p>First, we need to be able to generate the proposals. Let’s use the
two-dimensional normal with identity covariance scaled by a scalar
<code>jump_scale</code>.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">set.seed</span><span class="op">(</span><span class="fl">12</span><span class="op">)</span></span>
<span></span>
<span><span class="va">generate_proposal</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">pars_now</span>, <span class="va">jump_scale</span> <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span> <span class="op">{</span></span>
<span></span>
<span>  <span class="va">n_pars</span> <span class="op">&lt;-</span> <span class="fu">length</span><span class="op">(</span><span class="va">pars_now</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Random draw from multivariate normal</span></span>
<span>  <span class="va">theta_star</span> <span class="op">&lt;-</span> <span class="fu">mvtnorm</span><span class="fu">::</span><span class="fu">rmvnorm</span><span class="op">(</span><span class="fl">1</span>,</span>
<span>                                 mean <span class="op">=</span> <span class="va">pars_now</span>,</span>
<span>                                 sigma <span class="op">=</span> <span class="va">jump_scale</span><span class="op">*</span><span class="fu">diag</span><span class="op">(</span><span class="va">n_pars</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="kw">return</span><span class="op">(</span><span class="va">theta_star</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre>
</div>
<p>Running MH also requires computing the (unnormalized) posterior
density at the proposed parameter values. This function returns the log
posterior value at the location <code>pars</code>. The density is
computed on log scale to avoid issues with numerical precision.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">get_log_target_value</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">X</span>, <span class="va">pars</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="co"># log(likelihood)</span></span>
<span>  <span class="fu">sum</span><span class="op">(</span></span>
<span>    <span class="fu">dnorm</span><span class="op">(</span><span class="va">X</span>,</span>
<span>          mean <span class="op">=</span> <span class="va">pars</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">pars</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">^</span><span class="fl">2</span>, </span>
<span>          sd <span class="op">=</span> <span class="fl">1</span>,</span>
<span>          log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span>      <span class="op">)</span> <span class="op">+</span></span>
<span>    </span>
<span>    <span class="co"># log(prior)</span></span>
<span>    <span class="fu">dnorm</span><span class="op">(</span><span class="va">pars</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="fl">0</span>, <span class="fl">1</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">dnorm</span><span class="op">(</span><span class="va">pars</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, <span class="fl">0</span>, <span class="fl">1</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span>  </span>
<span><span class="op">}</span></span></code></pre>
</div>
<p>Then, we’ll write a function that computes the acceptance ratio <span class="math inline">\(r\)</span>. Since the proposal is symmetric, the
expression reduces to the ratio of the posterior densities of the
proposed and current parameter values. Notice that a ratio on a log
scale is equal to the difference of logarithms.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Compute ratio</span></span>
<span><span class="va">get_ratio</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">X</span>, <span class="va">pars_now</span>, <span class="va">pars_proposal</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">r</span> <span class="op">&lt;-</span> <span class="fu">exp</span><span class="op">(</span></span>
<span>    <span class="fu">get_log_target_value</span><span class="op">(</span><span class="va">X</span>, <span class="va">pars_proposal</span><span class="op">)</span> <span class="op">-</span> </span>
<span>      <span class="fu">get_log_target_value</span><span class="op">(</span><span class="va">X</span>, <span class="va">pars_now</span><span class="op">)</span></span>
<span>    <span class="op">)</span></span>
<span>  </span>
<span>  <span class="kw">return</span><span class="op">(</span><span class="va">r</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre>
</div>
<p>Finally, we can wrap the helpers in a function that loops over the
algorithm steps.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Sampler</span></span>
<span><span class="va">MH_sampler</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">X</span>, <span class="co"># Data</span></span>
<span>                       <span class="va">inits</span>, <span class="co"># Initial values</span></span>
<span>                       <span class="va">n_samples</span> <span class="op">=</span> <span class="fl">1000</span>, <span class="co"># Number of iterations</span></span>
<span>                       <span class="va">jump_scale</span> <span class="op">=</span> <span class="fl">0.1</span> <span class="co"># Proposal jump variance</span></span>
<span>                       <span class="op">)</span> <span class="op">{</span></span>
<span></span>
<span>  </span>
<span>  <span class="co"># Matrix for samples</span></span>
<span>  <span class="va">pars</span> <span class="op">&lt;-</span> <span class="fu">matrix</span><span class="op">(</span>nrow <span class="op">=</span> <span class="va">n_samples</span>, ncol <span class="op">=</span> <span class="fu">length</span><span class="op">(</span><span class="va">inits</span><span class="op">)</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Set initial values</span></span>
<span>  <span class="va">pars</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span> <span class="op">&lt;-</span> <span class="va">inits</span></span>
<span></span>
<span>  <span class="co"># Generate samples </span></span>
<span>  <span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">2</span><span class="op">:</span><span class="va">n_samples</span><span class="op">)</span> <span class="op">{</span></span>
<span>    </span>
<span>    <span class="co"># Current parameters</span></span>
<span>    <span class="va">pars_now</span> <span class="op">&lt;-</span> <span class="va">pars</span><span class="op">[</span><span class="va">i</span><span class="op">-</span><span class="fl">1</span>, <span class="op">]</span></span>
<span>    </span>
<span>    <span class="co"># Proposal</span></span>
<span>    <span class="va">pars_proposal</span> <span class="op">&lt;-</span> <span class="fu">generate_proposal</span><span class="op">(</span><span class="va">pars_now</span>, <span class="va">jump_scale</span><span class="op">)</span></span>
<span>    </span>
<span>    <span class="co"># Ratio</span></span>
<span>    <span class="va">r</span> <span class="op">&lt;-</span> <span class="fu">get_ratio</span><span class="op">(</span><span class="va">X</span>, <span class="va">pars_now</span>, <span class="va">pars_proposal</span><span class="op">)</span></span>
<span>    </span>
<span>    <span class="va">r</span> <span class="op">&lt;-</span> <span class="fu">min</span><span class="op">(</span><span class="fl">1</span>, <span class="va">r</span><span class="op">)</span></span>
<span>    </span>
<span>    <span class="co"># Does the sampler move?</span></span>
<span>    <span class="va">move</span> <span class="op">&lt;-</span> <span class="fu">sample</span><span class="op">(</span>x <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="cn">TRUE</span>, <span class="cn">FALSE</span><span class="op">)</span>,</span>
<span>                   size <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                   prob <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="va">r</span>, <span class="fl">1</span><span class="op">-</span><span class="va">r</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="co"># OR: </span></span>
<span>    <span class="co"># move &lt;- runif(n = 1, min = 0, max = 1) &lt;= r</span></span>
<span>    </span>
<span>    <span class="kw">if</span><span class="op">(</span><span class="va">move</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="va">pars</span><span class="op">[</span><span class="va">i</span>, <span class="op">]</span> <span class="op">&lt;-</span> <span class="va">pars_proposal</span></span>
<span>    <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>      <span class="va">pars</span><span class="op">[</span><span class="va">i</span>, <span class="op">]</span> <span class="op">&lt;-</span> <span class="va">pars_now</span></span>
<span>    <span class="op">}</span></span>
<span>  <span class="op">}</span></span>
<span>  </span>
<span>  <span class="va">pars</span> <span class="op">&lt;-</span> <span class="fu">data.frame</span><span class="op">(</span><span class="va">pars</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="kw">return</span><span class="op">(</span><span class="va">pars</span><span class="op">)</span> </span>
<span><span class="op">}</span></span></code></pre>
</div>
</div>
<div class="section level4">
<h4 id="run-mh">Run MH<a class="anchor" aria-label="anchor" href="#run-mh"></a>
</h4>
<p>Now we can try out our MH implementation. Let’s use the simulated
data points stored in vector <code>X</code>:</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu">c</span><span class="op">(</span><span class="fl">3.78</span>, <span class="fl">2.76</span>, <span class="fl">2.84</span>, <span class="fl">2.92</span>, <span class="fl">1.3</span>, <span class="fl">3.93</span>, <span class="fl">3.69</span>, <span class="fl">2.28</span>, <span class="fl">2.81</span>, <span class="fl">0.71</span><span class="op">)</span></span></code></pre>
</div>
<p>We’ll generate 1000 samples with initial value (0, 5) and jump scale
0.01. The trajectory of samples is plotted over the posterior density
computed with the grid approximation.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Draw samples</span></span>
<span><span class="va">samples1</span> <span class="op">&lt;-</span> <span class="fu">MH_sampler</span><span class="op">(</span><span class="va">X</span>,</span>
<span>                      inits <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">5</span><span class="op">)</span>,</span>
<span>                      n_samples <span class="op">=</span> <span class="fl">1000</span>, </span>
<span>                      jump_scale <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">colnames</span><span class="op">(</span><span class="va">samples1</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu">c</span><span class="op">(</span><span class="st">"theta1"</span>, <span class="st">"theta2"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Add column for sample index</span></span>
<span><span class="va">samples1</span><span class="op">$</span><span class="va">sample</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="fu">nrow</span><span class="op">(</span><span class="va">samples1</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="co"># Grid approximation</span></span>
<span><span class="va">delta</span> <span class="op">&lt;-</span> <span class="fl">0.05</span></span>
<span><span class="va">df_grid</span> <span class="op">&lt;-</span> <span class="fu">expand.grid</span><span class="op">(</span><span class="fu">seq</span><span class="op">(</span><span class="op">-</span><span class="fl">4</span>, <span class="fl">4</span>, by <span class="op">=</span> <span class="va">delta</span><span class="op">)</span>,</span>
<span>                       <span class="fu">seq</span><span class="op">(</span><span class="op">-</span><span class="fl">4</span>, <span class="fl">5</span>, by <span class="op">=</span> <span class="va">delta</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">set_colnames</span><span class="op">(</span><span class="fu">c</span><span class="op">(</span><span class="st">"theta1"</span>, <span class="st">"theta2"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fu">nrow</span><span class="op">(</span><span class="va">df_grid</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">df_grid</span><span class="op">[</span><span class="va">i</span>, <span class="st">"likelihood"</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">prod</span><span class="op">(</span></span>
<span>    <span class="fu">dnorm</span><span class="op">(</span><span class="va">X</span>,</span>
<span>          <span class="va">df_grid</span><span class="op">[</span><span class="va">i</span>, <span class="st">"theta1"</span><span class="op">]</span> <span class="op">+</span> <span class="va">df_grid</span><span class="op">[</span><span class="va">i</span>, <span class="st">"theta2"</span><span class="op">]</span><span class="op">^</span><span class="fl">2</span>,</span>
<span>          <span class="fl">1</span><span class="op">)</span></span>
<span>    <span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">df_grid</span> <span class="op">&lt;-</span> <span class="va">df_grid</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>prior <span class="op">=</span> <span class="fu">dnorm</span><span class="op">(</span><span class="va">theta1</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span><span class="op">*</span><span class="fu">dnorm</span><span class="op">(</span><span class="va">theta2</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>posterior <span class="op">=</span> <span class="va">prior</span><span class="op">*</span><span class="va">likelihood</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>posterior <span class="op">=</span> <span class="va">posterior</span> <span class="op">/</span> <span class="op">(</span><span class="fu">sum</span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span><span class="op">*</span><span class="va">delta</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="co"># Plot</span></span>
<span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_tile</span><span class="op">(</span>data <span class="op">=</span> <span class="va">df_grid</span>, </span>
<span>             <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">theta1</span>, y <span class="op">=</span> <span class="va">theta2</span>, fill <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_fill_gradientn</span><span class="op">(</span>colours <span class="op">=</span> <span class="fu">rainbow</span><span class="op">(</span><span class="fl">5</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span></span>
<span></span>
<span><span class="co"># Plot joint posterior samples</span></span>
<span><span class="va">p_MH1</span> <span class="op">&lt;-</span> <span class="va">p_grid</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_path</span><span class="op">(</span>data <span class="op">=</span> <span class="va">samples1</span>,</span>
<span>            <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">theta1</span>, y <span class="op">=</span> <span class="va">theta2</span><span class="op">)</span><span class="op">)</span></span>
<span>  </span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="va">p_MH1</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/mcmc-rendered-unnamed-chunk-6-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>Looking at the figure, a few observations become evident. Firstly,
despite the chosen initial value being moderately far from the
high-density areas of the posterior, the algorithm quickly converges to
the target region. This rapid convergence is due to the fact that
proposals toward higher density areas are favored, in fact they are
always accepted when using normal density proposals. However, it’s
important to note that such swift convergence is not guaranteed in all
scenarios. In cases with a high number of model parameters, there’s an
increased likelihood of the sampler taking ‘wrong’ directions. The
samples before convergence introduce bias to the posterior
approximation.</p>
<p>Secondly, the posterior is not fully explored; no samples are
generated from the lower mode in the figure. This highlights a crucial
point: even if the sampler has converged, it doesn’t guarantee that the
drawn samples provide a representative picture of the target.</p>
<div id="discussion1" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<span class="callout-header">Discussion</span>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>Consider how you could address the two issues raised above:</p>
<ol style="list-style-type: decimal">
<li>Initial unconverged samples introduce a bias.</li>
<li>The sampler may not have explored the target distribution
properly.</li>
</ol>
<p>Try different proposal distributions variances in the MCMC example
above by changing <code>jump_scale</code>. How does this affect the
inference and convergence? Why?</p>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="assessing-convergence">Assessing convergence<a class="anchor" aria-label="anchor" href="#assessing-convergence"></a>
</h2>
<hr class="half-width">
<p>Although convergence of MCMC is theoretically guaranteed, in
practice, this is not always the case. Monitoring convergence is crucial
whenever MCMC is utilized to ensure the reliability of recovered
results.</p>
<p>Depending on the model used, initial values, amount of data, among
other factors, can cause convergence issues. Earlier, we mentioned two
common complications, and here we will list a few more, along with
actions that can alleviate the issues.</p>
<ol style="list-style-type: decimal">
<li><p>Slow convergence can occur when initial values of the chain are
far from most of the target mass, resulting in early iterations biasing
the approximation. Another cause for slow convergence is that the
proposals are not far enough from the current value, and the sampler
moves too slowly.</p></li>
<li><p>Incomplete exploration: This means that the sampler doesn’t spend
enough time in all significant posterior areas.</p></li>
<li><p>A large proportion of the proposals is rejected. When the
proposal distribution generates proposals too far from the current
value, the proposals are rejected and the sampler stands still for many
iterations. This leads to inefficiency.</p></li>
<li><p>Sample autocorrelation: Consecutive samples are close to each
other. Ideally, we’d like to generate independent samples from the
target. High sample autocorrelation can be caused by several factors,
including the ones mentioned in the previous points.</p></li>
</ol>
<p>These issues can be remedied with:</p>
<ol style="list-style-type: decimal">
<li><p>Running multiple long chains with distinct or random initial
values.</p></li>
<li><p>Discarding the early proportion of the chain as warm-up.</p></li>
<li><p>Setting an appropriate proposal distribution.</p></li>
</ol>
<p>It also important to be able to monitor whether the sampler has
converged. This can be done with statistics, such as <em>effective
sample size</em> and <span class="math inline">\(\hat{R}\)</span>.
Effective sample size estimates how many independent samples have been
generated. Ideally, this number should be close to the total number of
iterations the sampler has been ran for. <span class="math inline">\(\hat{R}\)</span> on the other hand measures chain
mixing, that is, how well the chains agree with each other. It is
computed by comparing the variance within each chain to the total
variance of all samples. Usually, values of <span class="math inline">\(\hat{R} &gt; 1.1\)</span> are considered as
signaling convergence issues. However, the Stan development team <a href="https://mc-stan.org/rstan/reference/Rhat.html" class="external-link">recommends</a>
using 1.05 as the limit.</p>
<p>Besides statistics, visually evaluating the samples can be useful.
<em>Trace plots</em> refer to graphs where the marginal posterior
samples are plotted against sample index. Trace plots can be used to
investigate convergence and mixing properties, and can reveal, for
example, multimodality.</p>
<p>In Stan, many of the above-mentioned points have been automatized. By
default, Stan runs 4 chains with 2000 iterations each, and discards the
initial 50% as warm-up. Moreover, it computes <span class="math inline">\(\hat{R}\)</span>, effective sample size, and other
statistics and throws warnings in case of issues.</p>
<div class="section level3">
<h3 id="example-continued">Example continued<a class="anchor" aria-label="anchor" href="#example-continued"></a>
</h3>
<p>In light of the above information, let’s re-fit the model of the
previous example. Now, we’ll run 4 chains with random initial values,
10000 samples each, and discard the first 50% of each chain as warm-up.
We’ll use 0.1 as the proposal variance.</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Number of chains</span></span>
<span><span class="va">n_chains</span> <span class="op">&lt;-</span> <span class="fl">4</span></span>
<span></span>
<span><span class="co"># Number of samples</span></span>
<span><span class="va">n_samples</span> <span class="op">&lt;-</span> <span class="fl">10000</span></span>
<span></span>
<span><span class="co"># Initial warmup proportion</span></span>
<span><span class="va">warmup</span> <span class="op">&lt;-</span> <span class="fl">0.5</span></span>
<span></span>
<span><span class="va">samples2</span> <span class="op">&lt;-</span> <span class="fu">lapply</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">n_chains</span>, <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="co"># Use random initial values</span></span>
<span>  <span class="va">inits</span> <span class="op">&lt;-</span> <span class="fu">rnorm</span><span class="op">(</span><span class="fl">2</span>, <span class="fl">0</span>, <span class="fl">5</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="va">chain</span> <span class="op">&lt;-</span> <span class="fu">MH_sampler</span><span class="op">(</span><span class="va">X</span>, inits <span class="op">=</span> <span class="va">inits</span>,</span>
<span>                        n_samples <span class="op">=</span> <span class="va">n_samples</span>, </span>
<span>                        jump_scale <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Wrangle</span></span>
<span>  <span class="fu">colnames</span><span class="op">(</span><span class="va">chain</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu">c</span><span class="op">(</span><span class="st">"theta1"</span>, <span class="st">"theta2"</span><span class="op">)</span></span>
<span>  <span class="va">chain</span><span class="op">$</span><span class="va">sample</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="fu">nrow</span><span class="op">(</span><span class="va">chain</span><span class="op">)</span></span>
<span>  <span class="va">chain</span><span class="op">$</span><span class="va">chain</span> <span class="op">&lt;-</span> <span class="fu">as.factor</span><span class="op">(</span><span class="va">i</span><span class="op">)</span></span>
<span>  <span class="va">chain</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fu">round</span><span class="op">(</span><span class="va">warmup</span><span class="op">*</span><span class="va">n_samples</span><span class="op">)</span>, <span class="st">"warmup"</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="cn">TRUE</span></span>
<span>  <span class="va">chain</span><span class="op">[</span><span class="op">(</span><span class="fu">round</span><span class="op">(</span><span class="va">warmup</span><span class="op">*</span><span class="va">n_samples</span><span class="op">)</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">:</span><span class="va">n_samples</span>, <span class="st">"warmup"</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="cn">FALSE</span></span>
<span>  </span>
<span>  <span class="kw">return</span><span class="op">(</span><span class="va">chain</span><span class="op">)</span></span>
<span>  </span>
<span><span class="op">}</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">do.call</span><span class="op">(</span><span class="va">rbind</span>, <span class="va">.</span><span class="op">)</span></span></code></pre>
</div>
<p>Now it’s evident that the sample trajectories explore the entire
posterior distribution:</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Plot</span></span>
<span><span class="va">p_joint_2</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="co"># Warm-up samples</span></span>
<span>  <span class="fu">geom_path</span><span class="op">(</span>data <span class="op">=</span> <span class="va">samples2</span> <span class="op">%&gt;%</span></span>
<span>              <span class="fu">filter</span><span class="op">(</span><span class="va">warmup</span> <span class="op">==</span> <span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>            <span class="fu">aes</span><span class="op">(</span><span class="va">theta1</span>, <span class="va">theta2</span>, color <span class="op">=</span> <span class="va">chain</span><span class="op">)</span>,</span>
<span>            alpha <span class="op">=</span> <span class="fl">0.25</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="co"># Post-warm-up samples</span></span>
<span>  <span class="fu">geom_path</span><span class="op">(</span>data <span class="op">=</span> <span class="va">samples2</span> <span class="op">%&gt;%</span></span>
<span>              <span class="fu">filter</span><span class="op">(</span><span class="va">warmup</span> <span class="op">==</span> <span class="cn">FALSE</span><span class="op">)</span>,</span>
<span>            <span class="fu">aes</span><span class="op">(</span><span class="va">theta1</span>, <span class="va">theta2</span>, color <span class="op">=</span> <span class="va">chain</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="va">p_joint_2</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/mcmc-rendered-unnamed-chunk-8-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>Let’s see what the trace plots look like. Generally, we’d want to see
the samples randomly scattered around a mean value. For <span class="math inline">\(\theta_1\)</span> this is more or less the case,
although there some autocorrelation is apparent. With <span class="math inline">\(\theta_2\)</span> we can see that the chains have
mixed as they explore the same parameter ranges. However, the bimodality
of the posterior is quite apparent. The <span class="math inline">\(\hat{R}\)</span> statistics are 1.0082279 and
1.1065365 for <span class="math inline">\(\theta_1\)</span> and <span class="math inline">\(\theta_2\)</span>, respectively.</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Trace plots</span></span>
<span><span class="va">p_trace_2</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>data <span class="op">=</span> <span class="va">samples2</span> <span class="op">%&gt;%</span> </span>
<span>              <span class="fu">filter</span><span class="op">(</span><span class="va">warmup</span> <span class="op">==</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>              <span class="fu">gather</span><span class="op">(</span>key <span class="op">=</span> <span class="st">"parameter"</span>,</span>
<span>                     value <span class="op">=</span> <span class="st">"value"</span>,</span>
<span>                     <span class="op">-</span><span class="fu">c</span><span class="op">(</span><span class="st">"sample"</span>, <span class="st">"chain"</span>, <span class="st">"warmup"</span><span class="op">)</span><span class="op">)</span>, </span>
<span>            <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">sample</span>, y <span class="op">=</span> <span class="va">value</span>, color <span class="op">=</span> <span class="va">chain</span><span class="op">)</span>, </span>
<span>            alpha <span class="op">=</span> <span class="fl">0.25</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>data <span class="op">=</span> <span class="va">samples2</span> <span class="op">%&gt;%</span> </span>
<span>              <span class="fu">filter</span><span class="op">(</span><span class="va">warmup</span> <span class="op">==</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>              <span class="fu">gather</span><span class="op">(</span>key <span class="op">=</span> <span class="st">"parameter"</span>,</span>
<span>                     value <span class="op">=</span> <span class="st">"value"</span>,</span>
<span>                     <span class="op">-</span><span class="fu">c</span><span class="op">(</span><span class="st">"sample"</span>, <span class="st">"chain"</span>, <span class="st">"warmup"</span><span class="op">)</span><span class="op">)</span>, </span>
<span>            <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">sample</span>, y <span class="op">=</span> <span class="va">value</span>, color <span class="op">=</span> <span class="va">chain</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">facet_wrap</span><span class="op">(</span><span class="op">~</span><span class="va">parameter</span>,</span>
<span>             ncol <span class="op">=</span> <span class="fl">1</span>,</span>
<span>             scales <span class="op">=</span> <span class="st">"free"</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="va">p_trace_2</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/mcmc-rendered-unnamed-chunk-10-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure>
</div>
</section><section><h2 class="section-heading" id="hamiltonian-monte-carlo">Hamiltonian Monte Carlo<a class="anchor" aria-label="anchor" href="#hamiltonian-monte-carlo"></a>
</h2>
<hr class="half-width">
<p>Stan uses a variant of the Metropolis-Hastings algorithm called
Hamiltonian Monte Carlo (HMC; or actually a variant HMC). The defining
feature is the elaborate scheme it uses to generate proposals. Briefly,
the idea is to simulate the dynamics of a particle moving in a potential
landscape defined by the posterior. At each iteration, the particle is
given a random momentum vector and then its dynamics are simulated
forward for some time. The end of the trajectory is then taken as the
proposal value.</p>
<p>Compared to the random walk Metropolis-Hastings we implemented in
this episode, HMC is very efficient. The main advantages of HMC is its
ability to explore high-dimensional spaces more effectively, making it
especially useful in complex models with many parameters.</p>
<p>A type of convergence criterion exclusive to HMC is the divergent
transition. In a region of the parameter space where the posterior has
high curvature, the simulated particle dynamics can produce spurious
transitions which do not represent the posterior accurately. Such
transitions are called divergent and signal that the particular area of
parameter space is not explored accurately. Stan provides information
about divergent transitions automatically.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Markov chain Monte Carlo methods can be used to generate samples
from a posterior distribution.</li>
<li>Values of the chain are generated from a proposal distribution.</li>
<li>Proposals towards higher areas of the target distribution are
accepted with higher probability.</li>
<li>MCMC convergence should always be monitored.</li>
</ul>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="reading">Reading<a class="anchor" aria-label="anchor" href="#reading"></a>
</h2>
<hr class="half-width">
<ul>
<li><p>See interactive visualization of different MCMC algorithms: <a href="https://chi-feng.github.io/mcmc-demo/app.html" class="external-link uri">https://chi-feng.github.io/mcmc-demo/app.html</a></p></li>
<li><p>Bayesian Data Analysis (3rd ed.): Ch. 11-12</p></li>
<li><p>Statistical Rethinking (2nd ed.): Ch. 9</p></li>
<li><p>Bayes Rules!: Ch. 6-7</p></li>
</ul>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 --></section></section><section id="aio-hierarchical-models"><p>Content from <a href="hierarchical-models.html">Hierarchical models</a></p>
<hr>
<p>Last updated on 2025-08-22 |

        <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/edit/main/episodes/hierarchical-models.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 14 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How does Bayesian modeling accommodate group structure?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Learn to construct and fit hierarchical models.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p><em>Hierarchical</em> (or multi-level) models are a class of models
suited for situations where the study population comprises distinct but
interconnected groups. For example, analyzing student performance across
different schools, income disparities among various regions, or studying
animal behavior within different populations are scenarios where such
models would be appropriate.</p>
<p>Incorporating group-wise parameters allows us to model each group
separately, and a model becomes hierarchical when we treat the
parameters of the prior distribution as unknown. These parameters, known
as hyperparameters, are assigned their own prior distribution, referred
to as a hyperprior, and are learned during the model fitting process.
Similarly as priors, the hyperpriors should be set so they reflect
ranges of possible hyperparameter values. Conceptually, these
hyperparameters and hyperpriors operate at a higher level of hierarchy,
hence the name.</p>
<p>For example, let’s consider the beta-binomial model discussed in
Episode 1. We used it to estimate the prevalence of left-handedness
based on a sample of 50 students. If we were to include additional
information, such as the students’ majors, we could extend the model as
follows:</p>
<p><span class="math display">\[X_g \sim \text{Bin}(N_g, \theta_g) \\
\theta_g \sim \text{Beta}(\alpha, \beta) \\
\alpha, \beta \sim \Gamma(2, 0.1).\]</span></p>
<p>Here, the subscript <span class="math inline">\(g\)</span> indexes
the groups based on majors. The group-specific prevalences for
left-handedness <span class="math inline">\(\theta_g\)</span> are
assigned a beta prior with hyperparameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> which are treated as random
variables. The final line indicates the hyperprior <span class="math inline">\(\Gamma(2, 0.1)\)</span> governing the prior
beliefs about the hyperparameters.</p>
<p>In this hierarchical beta-binomial model, students are considered
exchangeable within their majors but no longer across the entire
population. However, an underlying assumption of similarity exists
between the groups since they share a common prior, that is learned.
This way the groups are not entirely independent but are not treated as
equal either.</p>
<p>One of the key advantages of Bayesian hierarchical models is their
capacity to leverage information across groups. By pooling information
from various groups, these models can yield more robust estimates,
particularly when data availability is limited.</p>
<p>Another distinction from non-hierarchical models is that the prior,
or the <em>population distribution</em>, of the parameters is learned in
the process. This population distribution can provide information into
parameter variability on a broader scale, even for groups where data is
scarce or completely missing. For instance, if we had data on the
handedness of students majoring in natural sciences, the population
distribution can give insights into students in humanities and social
sciences as well.</p>
<p>In the following example, we will perform a hierarchical analysis of
human heights across different countries.</p>
<section><h2 class="section-heading" id="example-human-height">Example: human height<a class="anchor" aria-label="anchor" href="#example-human-height"></a>
</h2>
<hr class="half-width">
<p>Let’s examine the heights of adults in various countries. In [1],
averages and standard errors of adult heights in centimeters across
different countries and age groups were provided. We’ll utilize this
dataset to generate a sample of hypothetical individual heights and then
assess our ability to reproduce these measured height statistics.</p>
<p>This approach is commonly employed when building and testing models:
we generate simulated data with known parameters and then compare the
inferred results to these known parameters. In our case, the true
parameters are derived from real-world data.</p>
<p>We’ll employ a normal model with unknown mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span> as our generative model, and treat
these parameters hierarchically.</p>
<p>First, let’s load the data and examine its structure.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">set.seed</span><span class="op">(</span><span class="fl">4985</span><span class="op">)</span></span>
<span></span>
<span><span class="va">height</span> <span class="op">&lt;-</span> <span class="fu">read.csv</span><span class="op">(</span><span class="st">"data/height_data.csv"</span><span class="op">)</span></span>
<span><span class="fu">str</span><span class="op">(</span><span class="va">height</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>'data.frame':	210000 obs. of  8 variables:
 $ Country                                   : chr  "Afghanistan" "Afghanistan" "Afghanistan" "Afghanistan" ...
 $ Sex                                       : chr  "Boys" "Boys" "Boys" "Boys" ...
 $ Year                                      : int  1985 1985 1985 1985 1985 1985 1985 1985 1985 1985 ...
 $ Age.group                                 : int  5 6 7 8 9 10 11 12 13 14 ...
 $ Mean.height                               : num  103 109 115 120 125 ...
 $ Mean.height.lower.95..uncertainty.interval: num  92.9 99.9 106.3 112.2 117.9 ...
 $ Mean.height.upper.95..uncertainty.interval: num  114 118 123 128 132 ...
 $ Mean.height.standard.error                : num  5.3 4.72 4.27 3.92 3.66 ...</code></pre>
</div>
<p>Let’s subset this data to simplify the analysis and focus on the
height of adult women measured in 2019.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">height_women</span> <span class="op">&lt;-</span> <span class="va">height</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">filter</span><span class="op">(</span></span>
<span>    <span class="va">Age.group</span> <span class="op">==</span> <span class="fl">19</span>, </span>
<span>    <span class="va">Sex</span> <span class="op">==</span> <span class="st">"Girls"</span>,</span>
<span>    <span class="va">Year</span> <span class="op">==</span> <span class="fl">2019</span></span>
<span>    <span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="co"># Select variables of interest</span></span>
<span>  <span class="fu">select</span><span class="op">(</span><span class="va">Country</span>, <span class="va">Sex</span>, <span class="va">Mean.height</span>, <span class="va">Mean.height.standard.error</span><span class="op">)</span></span></code></pre>
</div>
<p>Let’s select 10 countries randomly</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">set.seed</span><span class="op">(</span><span class="fl">5431</span><span class="op">)</span></span>
<span><span class="co"># Select countries</span></span>
<span><span class="va">N_countries</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span><span class="va">Countries</span> <span class="op">&lt;-</span> <span class="fu">sample</span><span class="op">(</span><span class="fu">unique</span><span class="op">(</span><span class="va">height_women</span><span class="op">$</span><span class="va">Country</span><span class="op">)</span>,</span>
<span>                    size <span class="op">=</span> <span class="va">N_countries</span>,</span>
<span>                    replace <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">sort</span></span>
<span></span>
<span><span class="va">height_women10</span> <span class="op">&lt;-</span> <span class="va">height_women</span> <span class="op">%&gt;%</span> <span class="fu">filter</span><span class="op">(</span><span class="va">Country</span> <span class="op">%in%</span> <span class="va">Countries</span><span class="op">)</span></span>
<span></span>
<span><span class="va">height_women10</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>         Country   Sex Mean.height Mean.height.standard.error
1     Bangladesh Girls    152.3776                  0.4966124
2         Belize Girls    158.1201                  1.4026324
3       Cameroon Girls    160.4112                  0.6146315
4           Chad Girls    162.1242                  0.8894219
5  Cote d'Ivoire Girls    158.6524                  0.9254438
6          Ghana Girls    158.8551                  0.8002225
7          Kenya Girls    159.4338                  0.6680202
8     Luxembourg Girls    165.0690                  1.3778094
9         Taiwan Girls    160.6953                  0.7307839
10     Venezuela Girls    160.0370                  1.0813162</code></pre>
</div>
<div class="section level3">
<h3 id="simulate-data">Simulate data<a class="anchor" aria-label="anchor" href="#simulate-data"></a>
</h3>
<p>Now, we can treat the values in the table above as ground truth and
simulate some data based on them. Let’s generate <span class="math inline">\(N=10\)</span> samples for each country from the
normal model with <span class="math inline">\(\mu =
\text{Mean.height}\)</span> and <span class="math inline">\(\sigma =
\text{Mean.height.standard.error}\)</span>.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Sample size per group </span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span></span>
<span><span class="co"># For each country, generate heights</span></span>
<span><span class="va">height_sim</span> <span class="op">&lt;-</span> <span class="fu">lapply</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">N_countries</span>, <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="va">my_df</span> <span class="op">&lt;-</span> <span class="va">height_women10</span><span class="op">[</span><span class="va">i</span>, <span class="op">]</span></span>
<span>  </span>
<span>  <span class="fu">data.frame</span><span class="op">(</span>Country <span class="op">=</span> <span class="va">my_df</span><span class="op">$</span><span class="va">Country</span>, </span>
<span>             <span class="co"># Random values from normal</span></span>
<span>             Height <span class="op">=</span> <span class="fu">rnorm</span><span class="op">(</span><span class="va">N</span>,</span>
<span>                            mean <span class="op">=</span> <span class="va">my_df</span><span class="op">$</span><span class="va">Mean.height</span>,</span>
<span>                            sd <span class="op">=</span> <span class="va">my_df</span><span class="op">$</span><span class="va">Mean.height.standard.error</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="op">}</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">do.call</span><span class="op">(</span><span class="va">rbind</span>, <span class="va">.</span><span class="op">)</span></span></code></pre>
</div>
<p>Let’s plot the data</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Plot</span></span>
<span><span class="va">height_sim</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">geom_point</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">Height</span>, y <span class="op">=</span> <span class="va">Country</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>    <span class="fu">labs</span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Simulated data"</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/hierarchical-models-rendered-unnamed-chunk-6-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure>
</div>
<div class="section level3">
<h3 id="modeling">Modeling<a class="anchor" aria-label="anchor" href="#modeling"></a>
</h3>
<p>Let’s build a normal model that uses partial pooling for the country
means and standard deviations. The model can be stated as follows:</p>
<p><span class="math display">\[\begin{align}
X_{gi} &amp;\sim \text{N}(\mu_g, \sigma_g) \\
\mu_g &amp;\sim \text{N}(\mu_\mu, \sigma_\mu) \\
\sigma_g &amp;\sim \Gamma(\alpha_\sigma, \beta_\sigma) \\
\mu_\mu &amp;\sim \text{N}(0, 100)\\
\sigma_\mu &amp;\sim \Gamma(2, 0.1) \\
\alpha_\sigma, \beta_\sigma  &amp;\sim \Gamma(2, 0.01).
\end{align}\]</span></p>
<p>Above, <span class="math inline">\(X_{gi}\)</span> denotes the height
for individual <span class="math inline">\(i\)</span> in country <span class="math inline">\(g\)</span>. The country specific parameters <span class="math inline">\(\mu_g\)</span> and <span class="math inline">\(\sigma_g\)</span> are given normal and gamma
priors, respectively, with unknown hyperparameters that, in turn, are
given hyperpriors on the last two lines. The hyperpriors are quite
uninformative as they allow large hyperparameter ranges.</p>
<p>Below is the Stan program for this model. The data points are input
as a concatenated vector <code>X</code>. The country-specific start and
end indices are computed in the transformed data block. This approach
accommodates uneven sample sizes between groups, although in our data
these are equal.</p>
<p>The parameters block contains the declarations of mean and standard
deviation vectors, along with the hyperparameters. The hyperparameter
subscripts denote the parameter they are assigned to so, for instance,
<span class="math inline">\(\sigma_{\mu}\)</span> is the standard
deviation of the mean parameter <span class="math inline">\(\mu\)</span>. The generated quantities block
generates samples from the population distributions of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> and a country-agnostic posterior
predictive distribution <span class="math inline">\(\tilde{X}\)</span>.</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">STAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode stan" tabindex="0"><code class="sourceCode stan"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; G; <span class="co">// number of groups</span></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N[G]; <span class="co">// sample size within each group</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>  <span class="dt">vector</span>[sum(N)] X; <span class="co">// concatenated observations</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>}</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a><span class="kw">transformed data</span> {</span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>  <span class="co">// get first and last index for each group in X</span></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>  <span class="dt">int</span> start_i[G];</span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>  <span class="dt">int</span> end_i[G];</span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>  </span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>  <span class="cf">for</span>(g <span class="cf">in</span> <span class="dv">1</span>:G) {</span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a></span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a>    <span class="cf">if</span>(g == <span class="dv">1</span>) {</span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a>      start_i[<span class="dv">1</span>] = <span class="dv">1</span>;</span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a>    } <span class="cf">else</span> {</span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a>      start_i[g] = start_i[g<span class="dv">-1</span>] + N[g<span class="dv">-1</span>];</span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a>    }</span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a>    </span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a>    end_i[g] = start_i[g] + N[g]-<span class="dv">1</span>;</span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a>  }</span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a>}</span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a></span>
<span id="cb8-24"><a href="#cb8-24" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb8-25"><a href="#cb8-25" tabindex="-1"></a>  </span>
<span id="cb8-26"><a href="#cb8-26" tabindex="-1"></a>  <span class="co">// parameters</span></span>
<span id="cb8-27"><a href="#cb8-27" tabindex="-1"></a>  <span class="dt">vector</span>[G] mu;</span>
<span id="cb8-28"><a href="#cb8-28" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt;[G] sigma;</span>
<span id="cb8-29"><a href="#cb8-29" tabindex="-1"></a>  </span>
<span id="cb8-30"><a href="#cb8-30" tabindex="-1"></a>  <span class="co">// hyperparameters</span></span>
<span id="cb8-31"><a href="#cb8-31" tabindex="-1"></a>  <span class="dt">real</span> mu_mu;</span>
<span id="cb8-32"><a href="#cb8-32" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; sigma_mu;</span>
<span id="cb8-33"><a href="#cb8-33" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; alpha_sigma;</span>
<span id="cb8-34"><a href="#cb8-34" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; beta_sigma;</span>
<span id="cb8-35"><a href="#cb8-35" tabindex="-1"></a>}</span>
<span id="cb8-36"><a href="#cb8-36" tabindex="-1"></a></span>
<span id="cb8-37"><a href="#cb8-37" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb8-38"><a href="#cb8-38" tabindex="-1"></a>  </span>
<span id="cb8-39"><a href="#cb8-39" tabindex="-1"></a>  <span class="co">// Likelihood for each group</span></span>
<span id="cb8-40"><a href="#cb8-40" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span>:G) {</span>
<span id="cb8-41"><a href="#cb8-41" tabindex="-1"></a>    X[start_i[i]:end_i[i]] ~ normal(mu[i], sigma[i]);</span>
<span id="cb8-42"><a href="#cb8-42" tabindex="-1"></a>  }</span>
<span id="cb8-43"><a href="#cb8-43" tabindex="-1"></a>  </span>
<span id="cb8-44"><a href="#cb8-44" tabindex="-1"></a>  <span class="co">// Priors</span></span>
<span id="cb8-45"><a href="#cb8-45" tabindex="-1"></a>  mu ~ normal(mu_mu, sigma_mu);</span>
<span id="cb8-46"><a href="#cb8-46" tabindex="-1"></a>  sigma ~ gamma(alpha_sigma, beta_sigma);</span>
<span id="cb8-47"><a href="#cb8-47" tabindex="-1"></a>  </span>
<span id="cb8-48"><a href="#cb8-48" tabindex="-1"></a>  <span class="co">// Hyperpriors</span></span>
<span id="cb8-49"><a href="#cb8-49" tabindex="-1"></a>  mu_mu ~ normal(<span class="dv">0</span>, <span class="dv">100</span>);</span>
<span id="cb8-50"><a href="#cb8-50" tabindex="-1"></a>  sigma_mu ~ gamma(<span class="dv">2</span>, <span class="fl">0.1</span>);</span>
<span id="cb8-51"><a href="#cb8-51" tabindex="-1"></a>  alpha_sigma ~ gamma(<span class="dv">2</span>, <span class="fl">0.01</span>);</span>
<span id="cb8-52"><a href="#cb8-52" tabindex="-1"></a>  beta_sigma ~ gamma(<span class="dv">2</span>, <span class="fl">0.01</span>);</span>
<span id="cb8-53"><a href="#cb8-53" tabindex="-1"></a>}</span>
<span id="cb8-54"><a href="#cb8-54" tabindex="-1"></a></span>
<span id="cb8-55"><a href="#cb8-55" tabindex="-1"></a><span class="kw">generated quantities</span> {</span>
<span id="cb8-56"><a href="#cb8-56" tabindex="-1"></a>  </span>
<span id="cb8-57"><a href="#cb8-57" tabindex="-1"></a>  <span class="dt">real</span> mu_tilde;</span>
<span id="cb8-58"><a href="#cb8-58" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; sigma_tilde;</span>
<span id="cb8-59"><a href="#cb8-59" tabindex="-1"></a>  <span class="dt">real</span> X_tilde; </span>
<span id="cb8-60"><a href="#cb8-60" tabindex="-1"></a>  </span>
<span id="cb8-61"><a href="#cb8-61" tabindex="-1"></a>  <span class="co">// Population distributions</span></span>
<span id="cb8-62"><a href="#cb8-62" tabindex="-1"></a>  mu_tilde = normal_rng(mu_mu, sigma_mu);</span>
<span id="cb8-63"><a href="#cb8-63" tabindex="-1"></a>  sigma_tilde = gamma_rng(alpha_sigma, beta_sigma);</span>
<span id="cb8-64"><a href="#cb8-64" tabindex="-1"></a>  </span>
<span id="cb8-65"><a href="#cb8-65" tabindex="-1"></a>  <span class="co">// Posterior predictive distribution</span></span>
<span id="cb8-66"><a href="#cb8-66" tabindex="-1"></a>  X_tilde = normal_rng(mu_tilde, sigma_tilde);</span>
<span id="cb8-67"><a href="#cb8-67" tabindex="-1"></a>  </span>
<span id="cb8-68"><a href="#cb8-68" tabindex="-1"></a>} </span></code></pre>
</div>
<p>Now we can call Stan and fit the model. Hierarchical models can
encounter convergence issues and for this reason, we’ll use 10000
iterations and set <code>adapt_delta = 0.99</code>. This controls the
acceptance probability in Stan’s adaptation period and will result in a
smaller step size in the Markov chain. Moreover, we’ll speed up the
inference by running 2 chains in parallel by setting
<code>cores = 2</code>.</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">stan_data</span> <span class="op">&lt;-</span> <span class="fu">list</span><span class="op">(</span>G <span class="op">=</span> <span class="fu">length</span><span class="op">(</span><span class="fu">unique</span><span class="op">(</span><span class="va">height_sim</span><span class="op">$</span><span class="va">Country</span><span class="op">)</span><span class="op">)</span>, </span>
<span>                  N <span class="op">=</span> <span class="fu">rep</span><span class="op">(</span><span class="va">N</span>, <span class="fu">length</span><span class="op">(</span><span class="va">Countries</span><span class="op">)</span><span class="op">)</span>, </span>
<span>                  X <span class="op">=</span> <span class="va">height_sim</span><span class="op">$</span><span class="va">Height</span><span class="op">)</span></span>
<span></span>
<span><span class="va">normal_hier_fit</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">sampling</span><span class="op">(</span><span class="va">normal_hier_model</span>,</span>
<span>                                   <span class="va">stan_data</span>, </span>
<span>                                   iter <span class="op">=</span> <span class="fl">10000</span>,</span>
<span>                                   chains <span class="op">=</span> <span class="fl">2</span>,</span>
<span>                                   <span class="co"># Use to avoid divergent transitions:</span></span>
<span>                                   control <span class="op">=</span> <span class="fu">list</span><span class="op">(</span>adapt_delta <span class="op">=</span> <span class="fl">0.99</span><span class="op">)</span>, </span>
<span>                                   cores <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre>
</div>
<p>For comparison, we will also run an unpooled analysis of heights,
which makes use of the following Stan file:</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">unpooled_summaries</span> <span class="op">&lt;-</span> <span class="fu">list</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">N_countries</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="va">my_country</span> <span class="op">&lt;-</span> <span class="fu">unique</span><span class="op">(</span><span class="va">height_sim</span><span class="op">$</span><span class="va">Country</span><span class="op">)</span><span class="op">[</span><span class="va">i</span><span class="op">]</span></span>
<span>  </span>
<span>  <span class="va">my_df</span> <span class="op">&lt;-</span> <span class="va">height_sim</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu">filter</span><span class="op">(</span><span class="va">Country</span> <span class="op">==</span> <span class="va">my_country</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="va">my_stan_data</span> <span class="op">&lt;-</span> <span class="fu">list</span><span class="op">(</span>N <span class="op">=</span>  <span class="va">my_df</span> <span class="op">%&gt;%</span> <span class="va">nrow</span>, </span>
<span>                       X <span class="op">=</span> <span class="va">my_df</span><span class="op">$</span><span class="va">Height</span><span class="op">)</span></span>
<span></span>
<span>  <span class="va">my_fit</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">sampling</span><span class="op">(</span><span class="va">normal_pooled_model</span>,</span>
<span>                              <span class="va">my_stan_data</span>, </span>
<span>                              iter <span class="op">=</span> <span class="fl">10000</span>,</span>
<span>                              chains <span class="op">=</span> <span class="fl">2</span>,</span>
<span>                                    <span class="co"># Use to get rid of divergent transitions:</span></span>
<span>                                    control <span class="op">=</span> <span class="fu">list</span><span class="op">(</span>adapt_delta <span class="op">=</span> <span class="fl">0.99</span><span class="op">)</span>, </span>
<span>                              cores <span class="op">=</span> <span class="fl">2</span>,</span>
<span>                            refresh <span class="op">=</span> <span class="fl">0</span></span>
<span>                            <span class="op">)</span></span>
<span>  </span>
<span>  </span>
<span>  <span class="va">unpooled_summaries</span><span class="op">[[</span><span class="va">i</span><span class="op">]</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">summary</span><span class="op">(</span><span class="va">my_fit</span>, <span class="fu">c</span><span class="op">(</span><span class="st">"mu"</span>, <span class="st">"sigma"</span><span class="op">)</span><span class="op">)</span><span class="op">$</span><span class="va">summary</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">data.frame</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">rownames_to_column</span><span class="op">(</span>var <span class="op">=</span> <span class="st">"par"</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>country <span class="op">=</span> <span class="va">my_country</span><span class="op">)</span></span>
<span>  </span>
<span><span class="op">}</span></span>
<span></span>
<span></span>
<span><span class="va">unpooled_summaries</span> <span class="op">&lt;-</span> <span class="fu">do.call</span><span class="op">(</span><span class="va">rbind</span>, <span class="va">unpooled_summaries</span><span class="op">)</span></span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="country-specific-estimates">Country-specific estimates<a class="anchor" aria-label="anchor" href="#country-specific-estimates"></a>
</h3>
<p>Let’s first compare the marginal posteriors for the country-specific
estimates from the hierarchical model (blue) and an unpooled model
(brown) that treats the parameters separately.</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">par_summary</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">summary</span><span class="op">(</span><span class="va">normal_hier_fit</span>, <span class="fu">c</span><span class="op">(</span><span class="st">"mu"</span>, <span class="st">"sigma"</span><span class="op">)</span><span class="op">)</span><span class="op">$</span><span class="va">summary</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">data.frame</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">rownames_to_column</span><span class="op">(</span>var <span class="op">=</span> <span class="st">"par"</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">separate</span><span class="op">(</span><span class="va">par</span>, into <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="st">"par"</span>, <span class="st">"country"</span><span class="op">)</span>, sep <span class="op">=</span> <span class="st">"\\["</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>country <span class="op">=</span> <span class="fu">gsub</span><span class="op">(</span><span class="st">"\\]"</span>, <span class="st">""</span>, <span class="va">country</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>country <span class="op">=</span> <span class="va">Countries</span><span class="op">[</span><span class="fu">as.integer</span><span class="op">(</span><span class="va">country</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span><span class="fu">geom_errorbar</span><span class="op">(</span>data <span class="op">=</span> <span class="va">par_summary</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">country</span>, ymin <span class="op">=</span> <span class="va">X2.5.</span>, ymax <span class="op">=</span> <span class="va">X97.5.</span><span class="op">)</span>,</span>
<span>              color <span class="op">=</span> <span class="va">posterior_color</span><span class="op">)</span> <span class="op">+</span> </span>
<span><span class="fu">geom_point</span><span class="op">(</span>data <span class="op">=</span> <span class="va">height_women10</span> <span class="op">%&gt;%</span> </span>
<span>             <span class="fu">rename_with</span><span class="op">(</span><span class="op">~</span> <span class="fu">c</span><span class="op">(</span><span class="st">'mu'</span>, <span class="st">'sigma'</span><span class="op">)</span>, <span class="fl">3</span><span class="op">:</span><span class="fl">4</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>             <span class="fu">gather</span><span class="op">(</span>key <span class="op">=</span> <span class="st">"par"</span>,</span>
<span>                    value <span class="op">=</span> <span class="st">"value"</span>,</span>
<span>                    <span class="op">-</span><span class="fu">c</span><span class="op">(</span><span class="va">Country</span>, <span class="va">Sex</span><span class="op">)</span><span class="op">)</span>, </span>
<span>           <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">Country</span>, y <span class="op">=</span> <span class="va">value</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span><span class="fu">geom_errorbar</span><span class="op">(</span>data <span class="op">=</span> <span class="va">unpooled_summaries</span>,</span>
<span>              <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">country</span>, ymin <span class="op">=</span> <span class="va">X2.5.</span>, ymax <span class="op">=</span> <span class="va">X97.5.</span><span class="op">)</span>,</span>
<span>              color <span class="op">=</span> <span class="st">"brown"</span><span class="op">)</span> <span class="op">+</span></span>
<span><span class="fu">facet_wrap</span><span class="op">(</span><span class="op">~</span> <span class="va">par</span>, scales <span class="op">=</span> <span class="st">"free"</span>, ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span><span class="fu">coord_flip</span><span class="op">(</span><span class="op">)</span> </span></code></pre>
</div>
<figure><img src="../fig/hierarchical-models-rendered-unnamed-chunk-11-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>Above, the black points represent the true values, and the intervals
are the 95% CIs for a hierarchical and non-hierarchical models,
respectively. As apparent, the CIs from the hierarchical model are more
concentrated and better capture the true values.</p>
<div id="discussion1" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<span class="callout-header">Discussion</span>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>Experiment with the data and fit. Explore the effect of sample size,
unequal sample sizes between countries, and the amount of countries, for
example.</p>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="hyperparameters">Hyperparameters<a class="anchor" aria-label="anchor" href="#hyperparameters"></a>
</h3>
<p>Let’s then plot the population distribution’s parameters, that is,
the hyperparameters. The sample-based values are included in the plots
of <span class="math inline">\(\mu_\mu\)</span> and <span class="math inline">\(\sigma_\mu\)</span> (why not for the other two
hyperparameters?). It seems that the model has slightly underestimated
the overall average and variance of the mean parameter <span class="math inline">\(\mu\)</span>, which is not suprising given the low
number of data points.</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## Population distributions:</span></span>
<span><span class="va">population_samples_l</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">extract</span><span class="op">(</span><span class="va">normal_hier_fit</span>,</span>
<span>                                       <span class="fu">c</span><span class="op">(</span><span class="st">"mu_mu"</span>, <span class="st">"sigma_mu"</span>, <span class="st">"alpha_sigma"</span>, <span class="st">"beta_sigma"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">do.call</span><span class="op">(</span><span class="va">cbind</span>, <span class="va">.</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">set_colnames</span><span class="op">(</span><span class="fu">c</span><span class="op">(</span><span class="st">"mu_mu"</span>, <span class="st">"sigma_mu"</span>, <span class="st">"alpha_sigma"</span>, <span class="st">"beta_sigma"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">data.frame</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>sample <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fu">nrow</span><span class="op">(</span><span class="va">.</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">gather</span><span class="op">(</span>key <span class="op">=</span> <span class="st">"hyperpar"</span>, value <span class="op">=</span> <span class="st">"value"</span>, <span class="op">-</span><span class="va">sample</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>data <span class="op">=</span> <span class="va">population_samples_l</span>, </span>
<span>                 <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">value</span>, y <span class="op">=</span> <span class="fu">after_stat</span><span class="op">(</span><span class="va">density</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                 fill <span class="op">=</span> <span class="va">posterior_color</span>,</span>
<span>                 bins <span class="op">=</span> <span class="fl">100</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>data <span class="op">=</span> <span class="va">height_women</span> <span class="op">%&gt;%</span> </span>
<span>               <span class="fu">rename_with</span><span class="op">(</span><span class="op">~</span> <span class="fu">c</span><span class="op">(</span><span class="st">'mu'</span>, <span class="st">'sigma'</span><span class="op">)</span>, <span class="fl">3</span><span class="op">:</span><span class="fl">4</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>               <span class="fu">filter</span><span class="op">(</span><span class="va">Sex</span> <span class="op">==</span> <span class="st">"Girls"</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>               <span class="fu">summarise</span><span class="op">(</span>mu_mu <span class="op">=</span> <span class="fu">mean</span><span class="op">(</span><span class="va">mu</span><span class="op">)</span>, sigma_mu <span class="op">=</span> <span class="fu">sd</span><span class="op">(</span><span class="va">mu</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>               <span class="fu">gather</span><span class="op">(</span>key <span class="op">=</span> <span class="st">"hyperpar"</span>, value <span class="op">=</span> <span class="st">"value"</span><span class="op">)</span>,</span>
<span>             <span class="fu">aes</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">value</span><span class="op">)</span></span>
<span>             <span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu">facet_wrap</span><span class="op">(</span><span class="op">~</span><span class="va">hyperpar</span>, scales <span class="op">=</span> <span class="st">"free"</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/hierarchical-models-rendered-unnamed-chunk-12-1.png" width="100%" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure>
</div>
<div class="section level3">
<h3 id="population-distributions">Population distributions<a class="anchor" aria-label="anchor" href="#population-distributions"></a>
</h3>
<p>Let’s then plot the population distributions and compare to the true
sample means and standard errors.</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">population_l</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">extract</span><span class="op">(</span><span class="va">normal_hier_fit</span>, <span class="fu">c</span><span class="op">(</span><span class="st">"mu_tilde"</span>, <span class="st">"sigma_tilde"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">do.call</span><span class="op">(</span><span class="va">cbind</span>, <span class="va">.</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">data.frame</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">set_colnames</span><span class="op">(</span> <span class="fu">c</span><span class="op">(</span><span class="st">"mu"</span>, <span class="st">"sigma"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>sample <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fu">nrow</span><span class="op">(</span><span class="va">.</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">gather</span><span class="op">(</span>key <span class="op">=</span> <span class="st">"par"</span>, value <span class="op">=</span> <span class="st">"value"</span>, <span class="op">-</span><span class="va">sample</span><span class="op">)</span></span>
<span></span>
<span></span>
<span> </span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>data <span class="op">=</span> <span class="va">population_l</span>,</span>
<span>                 <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">value</span>, y <span class="op">=</span> <span class="fu">after_stat</span><span class="op">(</span><span class="va">density</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                 bins <span class="op">=</span> <span class="fl">100</span>, fill <span class="op">=</span> <span class="va">posterior_color</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">geom_histogram</span><span class="op">(</span>data <span class="op">=</span> <span class="va">height_women</span> <span class="op">%&gt;%</span></span>
<span>                     <span class="fu">rename_with</span><span class="op">(</span><span class="op">~</span> <span class="fu">c</span><span class="op">(</span><span class="st">'mu'</span>, <span class="st">'sigma'</span><span class="op">)</span>, <span class="fl">3</span><span class="op">:</span><span class="fl">4</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>                     <span class="fu">gather</span><span class="op">(</span>key <span class="op">=</span> <span class="st">"par"</span>, value <span class="op">=</span> <span class="st">"value"</span>, <span class="op">-</span><span class="fu">c</span><span class="op">(</span><span class="va">Country</span>, <span class="va">Sex</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>                     <span class="fu">filter</span><span class="op">(</span><span class="va">Sex</span> <span class="op">==</span> <span class="st">"Girls"</span><span class="op">)</span>, </span>
<span>                   <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">value</span>, y <span class="op">=</span> <span class="fu">after_stat</span><span class="op">(</span><span class="va">density</span><span class="op">)</span><span class="op">)</span>, </span>
<span>                   alpha <span class="op">=</span> <span class="fl">0.75</span>, bins <span class="op">=</span> <span class="fl">30</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">facet_wrap</span><span class="op">(</span><span class="op">~</span><span class="va">par</span>, scales <span class="op">=</span> <span class="st">"free"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">labs</span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Blue = posterior; black = sample"</span><span class="op">)</span></span></code></pre>
</div>
<p><img src="../fig/hierarchical-models-rendered-unnamed-chunk-13-1.png" width="100%" style="display: block; margin: auto;" class="figure">
We can see that the population distribution is able to capture the
measured average heights and standard deviations relatively well,
although the within-country variation is estimated to be too
concentrated. However, remember that these estimates are based on a
limited sample: 10 out of 200 countries with 10 individuals in each
group.</p>
</div>
<div class="section level3">
<h3 id="posterior-predictive-distribution">Posterior predictive distribution<a class="anchor" aria-label="anchor" href="#posterior-predictive-distribution"></a>
</h3>
<p>Finally, let’s plot the posterior predictive distribution for the
whole population and overlay it with the simulated data based on all
countries.</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># For each country, generate some random girl's heights</span></span>
<span><span class="va">height_all</span> <span class="op">&lt;-</span> <span class="fu">lapply</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu">nrow</span><span class="op">(</span><span class="va">height_women</span><span class="op">)</span>, <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="va">my_df</span> <span class="op">&lt;-</span> <span class="va">height_women</span><span class="op">[</span><span class="va">i</span>, <span class="op">]</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu">rename_with</span><span class="op">(</span><span class="op">~</span> <span class="fu">c</span><span class="op">(</span><span class="st">'mu'</span>, <span class="st">'sigma'</span><span class="op">)</span>, <span class="fl">3</span><span class="op">:</span><span class="fl">4</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="fu">data.frame</span><span class="op">(</span>Country <span class="op">=</span> <span class="va">my_df</span><span class="op">$</span><span class="va">Country</span>, </span>
<span>             Sex <span class="op">=</span> <span class="va">my_df</span><span class="op">$</span><span class="va">Sex</span>, </span>
<span>             <span class="co"># Random normal values based on sample mu and sd</span></span>
<span>             Height <span class="op">=</span> <span class="fu">rnorm</span><span class="op">(</span><span class="va">N</span>, <span class="va">my_df</span><span class="op">$</span><span class="va">mu</span>, <span class="va">my_df</span><span class="op">$</span><span class="va">sigma</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="op">}</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">do.call</span><span class="op">(</span><span class="va">rbind</span>, <span class="va">.</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Extract the posterior predictive distribution</span></span>
<span><span class="va">PPD</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">extract</span><span class="op">(</span><span class="va">normal_hier_fit</span>, <span class="fu">c</span><span class="op">(</span><span class="st">"X_tilde"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">data.frame</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">set_colnames</span><span class="op">(</span> <span class="fu">c</span><span class="op">(</span><span class="st">"X_tilde"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>sample <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fu">nrow</span><span class="op">(</span><span class="va">.</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>data <span class="op">=</span> <span class="va">PPD</span>, </span>
<span>                 <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">X_tilde</span>, y <span class="op">=</span> <span class="fu">after_stat</span><span class="op">(</span><span class="va">density</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                 bins <span class="op">=</span> <span class="fl">100</span>,</span>
<span>                 fill <span class="op">=</span> <span class="va">posterior_color</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>data <span class="op">=</span> <span class="va">height_all</span>, </span>
<span>                 <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">Height</span>, y <span class="op">=</span> <span class="fu">after_stat</span><span class="op">(</span><span class="va">density</span><span class="op">)</span><span class="op">)</span>, </span>
<span>                 alpha <span class="op">=</span> <span class="fl">0.75</span>, </span>
<span>                 bins <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/hierarchical-models-rendered-unnamed-chunk-15-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure>
</div>
<div class="section level3">
<h3 id="extensions">Extensions<a class="anchor" aria-label="anchor" href="#extensions"></a>
</h3>
<p>Here, we analyzed the height for women in a randomly chosen countries
using a hierarchical model. The model could be extended further, for
instance, by adding hierarchy between sexes, continents,
developed/developing countries etc.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Hierarchical models are appropriate for scenarios where the study
population naturally divides into subgroups.</li>
<li>Hierarchical models borrow statistical strength across the
population groups.</li>
<li>Population distributions hold information about the variation of the
model parameters over the whole population.</li>
</ul>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="reading">Reading<a class="anchor" aria-label="anchor" href="#reading"></a>
</h2>
<hr class="half-width">
<ul>
<li>Bayesian Data Analysis (3rd ed.): Ch. 5</li>
<li>Statistical Rethinking (2nd ed.): Ch. 13</li>
<li>Bayes Rules!: Ch. 15-19</li>
</ul></section><section><h2 class="section-heading" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<hr class="half-width">
<p>[1] Height: Height and body-mass index trajectories of school-aged
children and adolescents from 1985 to 2019 in 200 countries and
territories: a pooled analysis of 2181 population-based studies with 65
million participants. Lancet 2020, 396:1511-1524</p>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-model-comparison"><p>Content from <a href="model-comparison.html">Model comparison</a></p>
<hr>
<p>Last updated on 2025-08-22 |

        <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/edit/main/episodes/model-comparison.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 62 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can competing models be compared?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<p>Get a basic understanding of comparing models with</p>
<ul>
<li><p>posterior predictive check</p></li>
<li><p>information criteria</p></li>
<li><p>Bayesian cross-validation</p></li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>There is often uncertainty about which model would be the most
appropriate choice a data being analysed. The aim of this episode is to
introduce some tools that can be used to compare models systematically.
We will explore three different approaches.</p>
<p>The first one is the posterior predictive check, which involves
comparing a fitted model’s predictions with the observed data. The
second approach is to use information criteria, which measure the
balance between model complexity and goodness-of-fit. The episode
concludes with Bayesian cross-validation.</p>
<section><h2 class="section-heading" id="data">Data<a class="anchor" aria-label="anchor" href="#data"></a>
</h2>
<hr class="half-width">
<p>Throughout the chapter, we will use the same simulated data set in
the examples, a set of <span class="math inline">\(N=88\)</span>
univariate numerical data points. The data is included in the course’s
data folder at</p>
<p>Looking at the data histogram, it’s evident that the data is
approximately symmetrically distributed around 0. However, there is some
dispersion in the data, and an extreme positive value, suggesting that
the tails might be longer than those of a normal distribution. The
Cauchy distribution is a potential alternative and below we will compare
the suitability of these two distributions on this data.</p>
<figure><img src="../fig/model-comparison-rendered-unnamed-chunk-2-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure></section><section><h2 class="section-heading" id="posterior-predictive-check">Posterior predictive check<a class="anchor" aria-label="anchor" href="#posterior-predictive-check"></a>
</h2>
<hr class="half-width">
<p>The idea of posterior predictive checking is to use the posterior
predictive distribution to simulate a replicate data set and compare it
to the observed data. The reasoning behind this approach is that if the
model is a good fit, then replicate data should look similar the
observed one. Qualitative discrepancies between the simulated and
observed data can imply that the model does not match the properties of
the data or the domain.</p>
<p>The comparison can be done in different ways. Visual comparison is an
option but a more rigorous approach is to compute the <em>posterior
predictive p-value</em> (<span class="math inline">\(p_B\)</span>),
which measures how well the model can reproduce the observed data.
Computing the <span class="math inline">\(p_B\)</span> requires
specifying a statistic whose value is compared between the posterior
predictions and the observations.</p>
<p>The steps of a posterior predictive check can be formulated in the
following points:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Generate replicate data:</strong> Use the posterior
predictive distribution to simulate replicate datasets <span class="math inline">\(X^{rep}\)</span> with characteristics matching the
observed data. In our example, this amounts to generating data with
<span class="math inline">\(N=88\)</span> for each posterior
sample.</li>
<li>
<strong>Choose test quantity <span class="math inline">\(T(X)\)</span>:</strong> Choose an aspect of the
data that you wish to check. We’ll use the maximum value as the test
quantity and compute it for the observed data and each replicate. It’s
important to note that not every imaginable data quantity will make a
good <span class="math inline">\(T(X)\)</span>, see chapter 6.3 in BDA3
for details.</li>
<li>
<strong>Compute <span class="math inline">\(p_B\)</span>:</strong>
The posterior predictive p-value is defined as the probability <span class="math inline">\(Pr(T(X^{rep}) \geq T(X) | X)\)</span>, that is,
the probability that the predictions produce test quantity values at
least as extreme as those found in the data. Using samples, it is
computed as the proportion of replicate data sets with <span class="math inline">\(T\)</span> not smaller than that of <span class="math inline">\(T(X)\)</span>. The closer the <span class="math inline">\(p_B\)</span>-value is to 1 (or 0), the larger the
evidence that the model cannot properly emulate the data.</li>
</ol>
<p>Next we will perform these steps for the normal and Cauchy
models.</p>
<div class="section level3">
<h3 id="normal-model">Normal model<a class="anchor" aria-label="anchor" href="#normal-model"></a>
</h3>
<p>Below is a Stan program for the normal model that produces the
replicate data in the generated quantities block. The values of
<code>X_rep</code> are generated in a loop using the random number
generator <code>normal_rng</code>. Notice that a single posterior sample
<span class="math inline">\((\mu_s, \sigma_s)\)</span> is used for each
evaluation of the generated quantities block, resulting in a
distribution of <span class="math inline">\(X^{rep}\)</span></p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">STAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode stan" tabindex="0"><code class="sourceCode stan"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N;</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>  <span class="dt">vector</span>[N] X;</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>}</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; sigma;</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>  <span class="dt">real</span> mu;</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>}</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a>  X ~ normal(mu, sigma);</span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a>  </span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a>  mu ~ normal(<span class="dv">0</span>, <span class="dv">1</span>);</span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>  sigma ~ gamma(<span class="dv">2</span>, <span class="dv">1</span>);</span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>}</span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a><span class="kw">generated quantities</span> {</span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>  <span class="dt">vector</span>[N] X_rep;</span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>  </span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a>    X_rep[i] = normal_rng(mu, sigma);</span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a>  }</span>
<span id="cb1-22"><a href="#cb1-22" tabindex="-1"></a>}</span></code></pre>
</div>
<p>Let’s fit model and extract the replicates.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Fit</span></span>
<span><span class="va">normal_fit</span> <span class="op">&lt;-</span> <span class="fu">sampling</span><span class="op">(</span><span class="va">normal_model</span>,</span>
<span>                       <span class="fu">list</span><span class="op">(</span>N <span class="op">=</span> <span class="va">N</span>, X <span class="op">=</span> <span class="va">df5</span><span class="op">$</span><span class="va">X</span><span class="op">)</span>, </span>
<span>                       refresh <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Extract </span></span>
<span><span class="va">X_rep</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">extract</span><span class="op">(</span><span class="va">normal_fit</span>, <span class="st">"X_rep"</span><span class="op">)</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">data.frame</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>sample <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fu">nrow</span><span class="op">(</span><span class="va">.</span><span class="op">)</span><span class="op">)</span></span></code></pre>
</div>
<p>Below is a comparison of 9 realizations of <span class="math inline">\(X^{rep}\)</span> (blue) against the data (grey;
the panel titles correspond to MCMC sample numbers). It is evident that
the tail properties are different between <span class="math inline">\(X^{rep}\)</span> and <span class="math inline">\(X\)</span>, and this discrepancy indicates an
issue with the model choice.</p>
<figure><img src="../fig/model-comparison-rendered-unnamed-chunk-5-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>Let’s quantify this discrepancy by computing the <span class="math inline">\(p_B\)</span> using the maximum of the data as a
test statistic. The maximum of the original data is max(<span class="math inline">\(X\)</span>) = 43.481. The posterior predictive
<span class="math inline">\(p\)</span>-value is <span class="math inline">\(p_B =\)</span> 0.</p>
<p>This means that the chosen statistic <span class="math inline">\(T\)</span> is at least as large as in the data in
100% of the replications, indicating strong evidence that the normal
model is a poor choice for the data.</p>
<p>The following histogram displays <span class="math inline">\(T(X) =
\max(X)\)</span> (vertical line) against the distribution of <span class="math inline">\(T(X^{rep})\)</span>.</p>
<figure><img src="../fig/model-comparison-rendered-unnamed-chunk-7-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure>
</div>
<div class="section level3">
<h3 id="cauchy-model">Cauchy model<a class="anchor" aria-label="anchor" href="#cauchy-model"></a>
</h3>
<p>Let’s do an identical analysis using the Cauchy model.</p>
<p>The results are generated with code essentially copy-pasted from
above, with a minor distinction in the Stan program.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">STAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode stan" tabindex="0"><code class="sourceCode stan"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N;</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>  <span class="dt">vector</span>[N] X;</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>}</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>  <span class="co">// Scale</span></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; sigma;</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>  <span class="co">// location</span></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>  <span class="dt">real</span> mu;</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>}</span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>  <span class="co">// location = mu and scale = sigma</span></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a>  X ~ cauchy(mu, sigma);</span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a>  </span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>  mu ~ normal(<span class="dv">0</span>, <span class="dv">1</span>);</span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a>  sigma ~ gamma(<span class="dv">2</span>, <span class="dv">1</span>);</span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a>}</span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a><span class="kw">generated quantities</span> {</span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a>  <span class="dt">vector</span>[N] X_rep;</span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a>    X_rep[i] = cauchy_rng(mu, sigma);</span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a>  }</span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a>}</span></code></pre>
</div>
<p>A comparison of data <span class="math inline">\(X\)</span> and <span class="math inline">\(X^{rep}\)</span> from the Cauchy model shows good
agreement between the posterior predictions and the data. The
distributions appear to closely match around 0, and the replicates
contain some extreme values similarly to the data.</p>
<figure><img src="../fig/model-comparison-rendered-unnamed-chunk-9-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>The maximum value observed in the data is similar to those from
replicate sets. Additionally, <span class="math inline">\(p_B=\)</span>
0, indicating no issues with the suitability of the model for the data.
distribution.</p>
<figure><img src="../fig/model-comparison-rendered-unnamed-chunk-10-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure>
</div>
</section><section><h2 class="section-heading" id="information-criteria">Information criteria<a class="anchor" aria-label="anchor" href="#information-criteria"></a>
</h2>
<hr class="half-width">
<p>Information criteria are statistics used for model comparison within
both Bayesian and classical frequentist frameworks. These criteria
provide a means to compare the relative suitability of a model to data
by estimating out-of-sample predictive accuracy while simultaneously
taking model complexity into account.</p>
<p>The Widely Applicable Information Criterion (WAIC) is an information
criteria developed within the Bayesian framework. WAIC is computed using
the log pointwise predictive density (lppd) of the data. Since the
predictions are based on the model fit with the the data lppd is an
overly confident estimate of the predictive capability. To take this
into account, a penalization term <span class="math inline">\(p_{WAIC}\)</span> is included:</p>
<p><span class="math display">\[WAIC = -2(\text{lppd} -
p_{WAIC}).\]</span> The log pointwise predictive density is computed as
$<em>{i=1}^N(</em>{s=1}^Sp(X_i | ^s)), $, where <span class="math inline">\(X_i, \,i=1,\ldots,N\)</span> are data points and
<span class="math inline">\(S\)</span> the number of posterior samples.
The penalization term <span class="math inline">\(p_{WAIC} =
\sum_{i=1}^N \text{Var}(\log p(y_i | \theta^s))\)</span> measures the
effective number of parameters (although this may not be apparent from
the formula). Because the definition contains a negative of the
difference <span class="math inline">\(\text{lppd} - p_{WAIC}\)</span>,
lower WAIC values imply a better fit.</p>
<p>Let’s use the WAIC to compare the normal and Cauchy models. First
we’ll need to fit both models on the data using the Stan programs
utilized above.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">stan_data</span> <span class="op">&lt;-</span> <span class="fu">list</span><span class="op">(</span>N <span class="op">=</span> <span class="va">N</span>, X <span class="op">=</span> <span class="va">df5</span><span class="op">$</span><span class="va">X</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Fit</span></span>
<span><span class="va">normal_fit</span> <span class="op">&lt;-</span> <span class="fu">sampling</span><span class="op">(</span><span class="va">normal_model</span>, <span class="va">stan_data</span>,</span>
<span>                       refresh <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span><span class="va">cauchy_fit</span> <span class="op">&lt;-</span> <span class="fu">sampling</span><span class="op">(</span><span class="va">cauchy_model</span>, <span class="va">stan_data</span>, </span>
<span>                       refresh <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Extract samples</span></span>
<span><span class="va">normal_samples</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">extract</span><span class="op">(</span><span class="va">normal_fit</span>, <span class="fu">c</span><span class="op">(</span><span class="st">"mu"</span>, <span class="st">"sigma"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="va">data.frame</span></span>
<span><span class="va">cauchy_samples</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">extract</span><span class="op">(</span><span class="va">cauchy_fit</span>, <span class="fu">c</span><span class="op">(</span><span class="st">"mu"</span>, <span class="st">"sigma"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="va">data.frame</span></span></code></pre>
</div>
<p>Then we will write a function for computing WAIC, but first a helper
function to compute posterior predictive density for a single point.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">get_ppd_point</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">samples</span>, <span class="va">model</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="co"># Loop over posterior samples  </span></span>
<span>  <span class="va">pp_dens</span> <span class="op">&lt;-</span> <span class="fu">lapply</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu">nrow</span><span class="op">(</span><span class="va">samples</span><span class="op">)</span>, <span class="kw">function</span><span class="op">(</span><span class="va">S</span><span class="op">)</span> <span class="op">{</span></span>
<span>    </span>
<span>    <span class="va">my_mu</span> <span class="op">&lt;-</span> <span class="va">samples</span><span class="op">[</span><span class="va">S</span>, <span class="st">"mu"</span><span class="op">]</span></span>
<span>    <span class="va">my_sigma</span> <span class="op">&lt;-</span> <span class="va">samples</span><span class="op">[</span><span class="va">S</span>, <span class="st">"sigma"</span><span class="op">]</span></span>
<span>    </span>
<span>    <span class="kw">if</span><span class="op">(</span><span class="va">model</span> <span class="op">==</span> <span class="st">"normal"</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="co"># Normal(x | mu, sigma^2)</span></span>
<span>      <span class="fu">dnorm</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>,</span>
<span>            mean <span class="op">=</span> <span class="va">my_mu</span>,</span>
<span>            sd <span class="op">=</span> <span class="va">my_sigma</span><span class="op">)</span></span>
<span>    <span class="op">}</span> <span class="kw">else</span> <span class="kw">if</span> <span class="op">(</span><span class="va">model</span> <span class="op">==</span> <span class="st">"cauchy"</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="co"># Cauchy(x | location = mu, scale = sigma^2)</span></span>
<span>      <span class="fu">dcauchy</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>,</span>
<span>              location <span class="op">=</span> <span class="va">my_mu</span>,</span>
<span>              scale <span class="op">=</span> <span class="op">)</span></span>
<span>    <span class="op">}</span></span>
<span>    </span>
<span>  <span class="op">}</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>    <span class="fu">unlist</span><span class="op">(</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="kw">return</span><span class="op">(</span><span class="va">pp_dens</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">WAIC</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">samples</span>, <span class="va">data</span>, <span class="va">model</span><span class="op">)</span><span class="op">{</span></span>
<span>  </span>
<span>  <span class="co"># Loop over data points</span></span>
<span>  <span class="va">pp_dens</span> <span class="op">&lt;-</span> <span class="fu">lapply</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu">length</span><span class="op">(</span><span class="va">data</span><span class="op">)</span>, <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu">get_ppd_point</span><span class="op">(</span><span class="va">data</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>, <span class="va">samples</span>, <span class="va">model</span><span class="op">)</span></span>
<span>  <span class="op">}</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>    <span class="fu">do.call</span><span class="op">(</span><span class="va">rbind</span>, <span class="va">.</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="va">lppd</span> <span class="op">&lt;-</span> <span class="fu">apply</span><span class="op">(</span>X <span class="op">=</span> <span class="va">pp_dens</span>,</span>
<span>                MARGIN <span class="op">=</span> <span class="fl">1</span>, </span>
<span>                FUN <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu">log</span><span class="op">(</span><span class="fu">mean</span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="va">sum</span></span>
<span>  </span>
<span>  <span class="va">bias</span> <span class="op">&lt;-</span> <span class="fu">apply</span><span class="op">(</span>X <span class="op">=</span> <span class="va">pp_dens</span>,</span>
<span>                MARGIN <span class="op">=</span> <span class="fl">1</span>, </span>
<span>                FUN <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu">var</span><span class="op">(</span><span class="fu">log</span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="va">sum</span></span>
<span>  </span>
<span>  <span class="co"># WAIC</span></span>
<span>  <span class="va">waic</span> <span class="op">=</span> <span class="op">-</span><span class="fl">2</span><span class="op">*</span><span class="op">(</span><span class="va">lppd</span> <span class="op">-</span> <span class="va">bias</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="kw">return</span><span class="op">(</span><span class="va">waic</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre>
</div>
<p>Applying this function to the posterior samples, we’ll obtain a lower
value for the Cauchy model, implying a better fit to the data. This is
in line with the posterior predictive check performed above.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">WAIC</span><span class="op">(</span><span class="va">normal_samples</span>, <span class="va">df5</span><span class="op">$</span><span class="va">X</span>, model <span class="op">=</span> <span class="st">"normal"</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[1] 582.6821</code></pre>
</div>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">WAIC</span><span class="op">(</span><span class="va">cauchy_samples</span>, <span class="va">df5</span><span class="op">$</span><span class="va">X</span>, model <span class="op">=</span> <span class="st">"cauchy"</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[1] 412.4815</code></pre>
</div>
</section><section><h2 class="section-heading" id="bayesian-cross-validation">Bayesian cross-validation<a class="anchor" aria-label="anchor" href="#bayesian-cross-validation"></a>
</h2>
<hr class="half-width">
<p>The final approach we take to model comparison in
cross-validation.</p>
<p>Cross-validation is a technique that estimates how well a model
predicts previously unseen data by using fits of the model to a subset
of the data to predict the rest of the data.</p>
<p>Performing cross-validation entails defining data partitioning for
model training and testing. The larger the proportion of the data used
for training, the better the accuracy. However, increasing the size of
training data leads to having to fit the model more times. In the
extreme case, when each data point is left out individually, the model
is fit <span class="math inline">\(N\)</span> times. This is called
leave-one-out cross-validation.</p>
<p>To evaluate the predictive accuracy we will use log predictive
density and take the sum over the different fits as the measure
accuracy. This is then compared to the predictive densities of the data
points based on the fit with all the data. This difference represents
the effective number of parameters <span class="math inline">\(p_{\text{loo-cv}}\)</span> that can be used for
comparing models.<br><span class="math display">\[p_{\text{loo-cv}} = \text{lppd} -
\text{lppd}_\text{loo-cv}.\]</span> Above, <span class="math inline">\(\text{lppd}_\text{loo-cv}\)</span> is the sum of
the log predictive densities of data points evaluated based on</p>
<p>Let’s implement this in R.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Loop over data partitions</span></span>
<span><span class="va">normal_loo_lpds</span> <span class="op">&lt;-</span> <span class="fu">lapply</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">N</span>, <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="co"># Subset data</span></span>
<span>  <span class="va">my_X</span> <span class="op">&lt;-</span> <span class="va">X</span><span class="op">[</span><span class="op">-</span><span class="va">i</span><span class="op">]</span></span>
<span>  <span class="va">my_x</span> <span class="op">&lt;-</span> <span class="va">X</span><span class="op">[</span><span class="va">i</span><span class="op">]</span></span>
<span>  </span>
<span>  <span class="co"># Fit model</span></span>
<span>  <span class="va">my_normal_fit</span> <span class="op">&lt;-</span> <span class="fu">sampling</span><span class="op">(</span><span class="va">normal_model</span>,</span>
<span>                            <span class="fu">list</span><span class="op">(</span>N <span class="op">=</span> <span class="fu">length</span><span class="op">(</span><span class="va">my_X</span><span class="op">)</span>,</span>
<span>                                 X <span class="op">=</span> <span class="va">my_X</span><span class="op">)</span>,</span>
<span>                            refresh <span class="op">=</span> <span class="fl">0</span></span>
<span>                            <span class="op">)</span> </span>
<span>  </span>
<span>  <span class="co"># Samples</span></span>
<span>  <span class="va">my_samples</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">extract</span><span class="op">(</span><span class="va">my_normal_fit</span>, <span class="fu">c</span><span class="op">(</span><span class="st">"mu"</span>, <span class="st">"sigma"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu">do.call</span><span class="op">(</span><span class="va">cbind</span>, <span class="va">.</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu">set_colnames</span><span class="op">(</span><span class="fu">c</span><span class="op">(</span><span class="st">"mu"</span>, <span class="st">"sigma"</span><span class="op">)</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># lppd</span></span>
<span>  <span class="va">my_lppd</span> <span class="op">&lt;-</span> <span class="fu">get_ppd_point</span><span class="op">(</span><span class="va">my_x</span>, <span class="va">my_samples</span>, <span class="st">"normal"</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="va">mean</span> <span class="op">%&gt;%</span> <span class="va">log</span></span>
<span>  </span>
<span>  <span class="fu">data.frame</span><span class="op">(</span><span class="va">i</span>, lppd <span class="op">=</span> <span class="va">my_lppd</span>, model <span class="op">=</span> <span class="st">"normal_loo"</span><span class="op">)</span></span>
<span>  </span>
<span><span class="op">}</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">do.call</span><span class="op">(</span><span class="va">rbind</span>, <span class="va">.</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Same for Cauchy:</span></span>
<span><span class="va">cauchy_loo_lpds</span> <span class="op">&lt;-</span> <span class="fu">lapply</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">N</span>, <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span> <span class="co"># Subset data</span></span>
<span>  <span class="va">my_X</span> <span class="op">&lt;-</span> <span class="va">X</span><span class="op">[</span><span class="op">-</span><span class="va">i</span><span class="op">]</span></span>
<span>  <span class="va">my_x</span> <span class="op">&lt;-</span> <span class="va">X</span><span class="op">[</span><span class="va">i</span><span class="op">]</span></span>
<span>  </span>
<span>  <span class="co"># Fit model</span></span>
<span>  <span class="va">my_cauchy_fit</span> <span class="op">&lt;-</span> <span class="fu">sampling</span><span class="op">(</span><span class="va">cauchy_model</span>,</span>
<span>                            <span class="fu">list</span><span class="op">(</span>N <span class="op">=</span> <span class="fu">length</span><span class="op">(</span><span class="va">my_X</span><span class="op">)</span>,</span>
<span>                                 X <span class="op">=</span> <span class="va">my_X</span><span class="op">)</span>,</span>
<span>                            refresh <span class="op">=</span> <span class="fl">0</span></span>
<span>                            <span class="op">)</span> </span>
<span>  </span>
<span>  <span class="co"># Samples</span></span>
<span>  <span class="va">my_samples</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">extract</span><span class="op">(</span><span class="va">my_cauchy_fit</span>, <span class="fu">c</span><span class="op">(</span><span class="st">"mu"</span>, <span class="st">"sigma"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu">do.call</span><span class="op">(</span><span class="va">cbind</span>, <span class="va">.</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu">set_colnames</span><span class="op">(</span><span class="fu">c</span><span class="op">(</span><span class="st">"mu"</span>, <span class="st">"sigma"</span><span class="op">)</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># lppd</span></span>
<span>  <span class="va">my_lppd</span> <span class="op">&lt;-</span> <span class="fu">get_ppd_point</span><span class="op">(</span><span class="va">my_x</span>, <span class="va">my_samples</span>, <span class="st">"cauchy"</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="va">mean</span> <span class="op">%&gt;%</span> <span class="va">log</span></span>
<span>  </span>
<span>  <span class="fu">data.frame</span><span class="op">(</span><span class="va">i</span>, lppd <span class="op">=</span> <span class="va">my_lppd</span>, model <span class="op">=</span> <span class="st">"cauchy_loo"</span><span class="op">)</span></span>
<span>  </span>
<span><span class="op">}</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">do.call</span><span class="op">(</span><span class="va">rbind</span>, <span class="va">.</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="co"># Predictive density for data points using full data in training</span></span>
<span><span class="va">normal_full_lpd</span> <span class="op">&lt;-</span> <span class="fu">lapply</span><span class="op">(</span><span class="fl">1</span>, <span class="kw">function</span><span class="op">(</span><span class="va">dummy</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="co"># Fit model</span></span>
<span>  <span class="va">my_normal_fit</span> <span class="op">&lt;-</span> <span class="fu">sampling</span><span class="op">(</span><span class="va">normal_model</span>,</span>
<span>                            <span class="fu">list</span><span class="op">(</span>N <span class="op">=</span> <span class="fu">length</span><span class="op">(</span><span class="va">X</span><span class="op">)</span>,</span>
<span>                                 X <span class="op">=</span> <span class="va">X</span><span class="op">)</span>, </span>
<span>                            refresh <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Get data</span></span>
<span>  <span class="va">my_samples</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">extract</span><span class="op">(</span><span class="va">my_normal_fit</span>, <span class="fu">c</span><span class="op">(</span><span class="st">"mu"</span>, <span class="st">"sigma"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu">do.call</span><span class="op">(</span><span class="va">cbind</span>, <span class="va">.</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu">set_colnames</span><span class="op">(</span><span class="fu">c</span><span class="op">(</span><span class="st">"mu"</span>, <span class="st">"sigma"</span><span class="op">)</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Compute lppd</span></span>
<span>  <span class="va">lppds</span> <span class="op">&lt;-</span> <span class="fu">lapply</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">N</span>, <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="op">{</span></span>
<span>    </span>
<span>    <span class="va">my_lppd</span> <span class="op">&lt;-</span> <span class="fu">get_ppd_point</span><span class="op">(</span><span class="va">X</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>, <span class="va">my_samples</span>, <span class="st">"normal"</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>      <span class="va">mean</span> <span class="op">%&gt;%</span> <span class="va">log</span></span>
<span>    </span>
<span>    <span class="fu">data.frame</span><span class="op">(</span><span class="va">i</span>, lppd <span class="op">=</span> <span class="va">my_lppd</span>, model <span class="op">=</span> <span class="st">"normal"</span><span class="op">)</span></span>
<span>  <span class="op">}</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu">do.call</span><span class="op">(</span><span class="va">rbind</span>, <span class="va">.</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="kw">return</span><span class="op">(</span><span class="va">lppds</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">do.call</span><span class="op">(</span><span class="va">rbind</span>, <span class="va">.</span><span class="op">)</span></span>
<span></span>
<span><span class="va">cauchy_full_lpd</span> <span class="op">&lt;-</span> <span class="fu">lapply</span><span class="op">(</span><span class="fl">1</span>, <span class="kw">function</span><span class="op">(</span><span class="va">dummy</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="co"># Fit model</span></span>
<span>  <span class="va">my_cauchy_fit</span> <span class="op">&lt;-</span> <span class="fu">sampling</span><span class="op">(</span><span class="va">cauchy_model</span>,</span>
<span>                            <span class="fu">list</span><span class="op">(</span>N <span class="op">=</span> <span class="fu">length</span><span class="op">(</span><span class="va">X</span><span class="op">)</span>,</span>
<span>                                 X <span class="op">=</span> <span class="va">X</span><span class="op">)</span>, </span>
<span>                            refresh <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Get data</span></span>
<span>  <span class="va">my_samples</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">extract</span><span class="op">(</span><span class="va">my_cauchy_fit</span>, <span class="fu">c</span><span class="op">(</span><span class="st">"mu"</span>, <span class="st">"sigma"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu">do.call</span><span class="op">(</span><span class="va">cbind</span>, <span class="va">.</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu">set_colnames</span><span class="op">(</span><span class="fu">c</span><span class="op">(</span><span class="st">"mu"</span>, <span class="st">"sigma"</span><span class="op">)</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Compute lppd</span></span>
<span>  <span class="va">lppds</span> <span class="op">&lt;-</span> <span class="fu">lapply</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">N</span>, <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="op">{</span></span>
<span>    </span>
<span>    <span class="va">my_lppd</span> <span class="op">&lt;-</span> <span class="fu">get_ppd_point</span><span class="op">(</span><span class="va">X</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>, <span class="va">my_samples</span>, <span class="st">"cauchy"</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>      <span class="va">mean</span> <span class="op">%&gt;%</span> <span class="va">log</span></span>
<span>    </span>
<span>    <span class="fu">data.frame</span><span class="op">(</span><span class="va">i</span>, lppd <span class="op">=</span> <span class="va">my_lppd</span>, model <span class="op">=</span> <span class="st">"cauchy"</span><span class="op">)</span></span>
<span>  <span class="op">}</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu">do.call</span><span class="op">(</span><span class="va">rbind</span>, <span class="va">.</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="kw">return</span><span class="op">(</span><span class="va">lppds</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">do.call</span><span class="op">(</span><span class="va">rbind</span>, <span class="va">.</span><span class="op">)</span></span></code></pre>
</div>
<p>Let’s combine the computed log densities, and compute model-wise
sums</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Combine</span></span>
<span><span class="va">lppds</span> <span class="op">&lt;-</span> <span class="fu">rbind</span><span class="op">(</span><span class="va">normal_loo_lpds</span>, </span>
<span>              <span class="va">normal_full_lpd</span>, </span>
<span>              <span class="va">cauchy_loo_lpds</span>,</span>
<span>              <span class="va">cauchy_full_lpd</span><span class="op">)</span></span>
<span></span>
<span><span class="va">lppd_summary</span> <span class="op">&lt;-</span> <span class="va">lppds</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">group_by</span><span class="op">(</span><span class="va">model</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">summarize</span><span class="op">(</span>lppd <span class="op">=</span> <span class="fu">sum</span><span class="op">(</span><span class="va">lppd</span><span class="op">)</span><span class="op">)</span></span></code></pre>
</div>
<p>Finally, we can compute the estimated of the effective number of
parameters. As with WAIC, smaller values imply better suitability. In
line with the posterior predictive check and WAIC, we see that, again,
the Cauchy distribution gives a better description of the data that the
normal model.</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Effective number of parameters</span></span>
<span><span class="va">p_loo_cv_normal</span> <span class="op">&lt;-</span> <span class="va">lppd_summary</span><span class="op">[</span><span class="va">lppd_summary</span><span class="op">$</span><span class="va">model</span> <span class="op">==</span> <span class="st">"normal"</span>, <span class="st">"lppd"</span><span class="op">]</span> <span class="op">-</span> <span class="va">lppd_summary</span><span class="op">[</span><span class="va">lppd_summary</span><span class="op">$</span><span class="va">model</span> <span class="op">==</span> <span class="st">"normal_loo"</span>, <span class="st">"lppd"</span><span class="op">]</span></span>
<span><span class="va">p_loo_cv_cauchy</span> <span class="op">&lt;-</span> <span class="va">lppd_summary</span><span class="op">[</span><span class="va">lppd_summary</span><span class="op">$</span><span class="va">model</span> <span class="op">==</span> <span class="st">"cauchy"</span>, <span class="st">"lppd"</span><span class="op">]</span> <span class="op">-</span> <span class="va">lppd_summary</span><span class="op">[</span><span class="va">lppd_summary</span><span class="op">$</span><span class="va">model</span> <span class="op">==</span> <span class="st">"cauchy_loo"</span>, <span class="st">"lppd"</span><span class="op">]</span></span>
<span></span>
<span></span>
<span><span class="fu">paste0</span><span class="op">(</span><span class="st">"Effective number of parameters, normal = "</span>, <span class="va">p_loo_cv_normal</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[1] "Effective number of parameters, normal = 33.1191161913168"</code></pre>
</div>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">paste0</span><span class="op">(</span><span class="st">"Effective number of parameters, cauchy = "</span>, <span class="va">p_loo_cv_cauchy</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[1] "Effective number of parameters, cauchy = 0.79387837262459"</code></pre>
</div>
<div id="callout1" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div class="callout-inner">
<div class="callout-content">
<p>There are packages that enable computing WAIC and approximate
leave-one-out score automatically so, in practice, there is seldom need
to implement these yourself. In episode 7 you will learn about these
options tools.</p>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Bayesian model comparison can be performed (for example) with
posterior predictive checks, information criteria, and
cross-validation.</li>
</ul>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="reading">Reading<a class="anchor" aria-label="anchor" href="#reading"></a>
</h2>
<hr class="half-width">
<ul>
<li><p>Statistical Rethinking: Ch. 7</p></li>
<li><p>BDA3: p.143: 6.3 Posterior predictive checking</p></li>
<li><p>PSIS-loo</p></li>
<li><p><a href="https://mc-stan.org/loo/articles/online-only/faq.html" class="external-link uri">https://mc-stan.org/loo/articles/online-only/faq.html</a></p></li>
</ul>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 --></section></section><section id="aio-gaussian-processes"><p>Content from <a href="gaussian-processes.html">Gaussian processes</a></p>
<hr>
<p>Last updated on 2025-08-22 |

        <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/edit/main/episodes/gaussian-processes.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 63 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How to do probabilistic non-parameteric regression?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Learn to perform Gaussian process regression with Stan</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>Gaussian processes (GPs) are a class of stochastic (random) processes
that are widely used for non-parametric regression, that is, when the
relationship between the predictors and the dependent variable has no
parametric form. Formally, a Gaussian process <span class="math inline">\(GP(\mu, K)\)</span> is defined as a collection of
random variables <span class="math inline">\(X\)</span> with the
property that any finite subset <span class="math inline">\(X_I \subset
X\)</span> follows a multivariate normal distribution with mean <span class="math inline">\(\mu\)</span> and covariance <span class="math inline">\(K\)</span>.</p>
<p>This definition implies a distribution over functions, meaning that
generating a realization from a GP produces a function. This in turn
implies that GPs can be used as priors for unknown functional forms
between variables.</p>
<p>As an example, consider modeling crop yields as a function of
fertilizer use. Presumably, there exists a non-linear trend between
these variables, as insufficient or excessive fertilizer use will lead
to suboptimal yields. In the absence of a parametric model, GPs can
function as a prior for the relationship between fertilizer and yield,
<span class="math inline">\(f\)</span>. In its simplest form, measured
yields <span class="math inline">\(y\)</span> could be modeled as noisy
observations from <span class="math inline">\(f(x)\)</span>, where <span class="math inline">\(x\)</span> is the amount of fertilizer used:</p>
<p><span class="math display">\[\begin{align}
y &amp;\sim N(f(x), \sigma^2) \\
f(x) &amp;\sim GP(\mu, K).
\end{align} \]</span></p>
<p>As with all priors, the chosen hyperparameters (here <span class="math inline">\(\mu, \, K\)</span>) influence the inference. The
mean parameter <span class="math inline">\(\mu\)</span> defines the
average level of the process, while the covariance function <span class="math inline">\(K\)</span> exerts a more defining effect on the
process characteristics.</p>
<p>Perhaps the most frequently used covariance function is the squared
exponential kernel <span class="math inline">\(K_{SE}(x, x’) = \alpha^2
\exp{ \frac{(x - x’)^2}{2 \lambda} }\)</span>. The parameter <span class="math inline">\(\alpha^2\)</span> sets the variance of the
process, while <span class="math inline">\(\lambda\)</span> determines
the scale of the correlation; increasing <span class="math inline">\(\lambda\)</span> increases the correlation between
<span class="math inline">\(x\)</span> and <span class="math inline">\(x’\)</span>. In the figure below, we’ve plotted
some realizations from a GP with <span class="math inline">\(\mu = (0,
0, \ldots, 0)\)</span> and squared exponential covariance function with
<span class="math inline">\(\alpha = 1\)</span> and <span class="math inline">\(\lambda = 25\)</span>. The input space <span class="math inline">\(X\)</span> is the integers between 0 and 100.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">set.seed</span><span class="op">(</span><span class="fl">6436</span><span class="op">)</span></span>
<span></span>
<span><span class="va">sq_exp_cov</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">lambda</span>, <span class="va">alpha</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">n</span> <span class="op">&lt;-</span> <span class="fu">length</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="va">K</span> <span class="op">&lt;-</span> <span class="fu">matrix</span><span class="op">(</span><span class="fl">0</span>, <span class="va">n</span>, <span class="va">n</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw">for</span> <span class="op">(</span><span class="va">j</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="va">diff</span> <span class="op">&lt;-</span> <span class="fu">sqrt</span><span class="op">(</span><span class="fu">sum</span><span class="op">(</span><span class="op">(</span><span class="va">x</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">-</span> <span class="va">x</span><span class="op">[</span><span class="va">j</span><span class="op">]</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span>      <span class="va">K</span><span class="op">[</span><span class="va">i</span>,<span class="va">j</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="va">alpha</span><span class="op">^</span><span class="fl">2</span> <span class="op">*</span> <span class="fu">exp</span><span class="op">(</span><span class="op">-</span><span class="va">diff</span><span class="op">^</span><span class="fl">2</span> <span class="op">/</span> <span class="op">(</span><span class="fl">2</span> <span class="op">*</span> <span class="va">lambda</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="op">}</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="kw">return</span><span class="op">(</span><span class="va">K</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fl">0</span><span class="op">:</span><span class="fl">100</span></span>
<span><span class="va">alpha</span> <span class="op">&lt;-</span> <span class="fl">1</span></span>
<span><span class="va">lambda</span> <span class="op">&lt;-</span> <span class="fl">25</span></span>
<span></span>
<span><span class="co"># Sample from multivariate normal</span></span>
<span><span class="va">gp_samples</span> <span class="op">&lt;-</span> <span class="fu">rmvnorm</span><span class="op">(</span><span class="fl">10</span>, sigma <span class="op">=</span> <span class="fu">sq_exp_cov</span><span class="op">(</span><span class="va">x</span>, <span class="va">lambda</span>, <span class="va">alpha</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">gp_samples_l</span> <span class="op">&lt;-</span> <span class="va">gp_samples</span> <span class="op">%&gt;%</span></span>
<span>  <span class="va">t</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="va">data.frame</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>x <span class="op">=</span> <span class="fu">seq</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">100</span>, by <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">gather</span><span class="op">(</span>key <span class="op">=</span> <span class="st">"sample"</span>, value <span class="op">=</span> <span class="st">"y"</span>, <span class="op">-</span><span class="va">x</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="va">gp_sample_p</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span>data <span class="op">=</span> <span class="va">gp_samples_l</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span>, group <span class="op">=</span> <span class="va">sample</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="va">gp_sample_p</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/gaussian-processes-rendered-unnamed-chunk-2-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><div id="discussion1" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<span class="callout-header">Discussion</span>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<ol style="list-style-type: decimal">
<li><p>Generate samples from the GP above with different values of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\lambda\)</span> to get intuition about the role
of these hyperparameters.</p></li>
<li><p>Implement the exponential covariance kernel defined as <span class="math inline">\(K_{exp}(x, x’) = \alpha^2 \exp{ \frac{|x -
x’|}{\lambda} }\)</span> and generate samples using this kernel. What is
the qualitative difference to samples generated with squared exponential
covariance?</p></li>
</ol>
</div>
</div>
</div>
<p>Next, we’ll explore some examples that make use of Gaussian
processes.</p>
<section><h2 class="section-heading" id="example-1-gaussian-process-regression">Example 1: Gaussian process regression<a class="anchor" aria-label="anchor" href="#example-1-gaussian-process-regression"></a>
</h2>
<hr class="half-width">
<p>Assume we’d like to estimate the relationship between variables <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> based on the following 5 data
points.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">df6</span> <span class="op">&lt;-</span> <span class="fu">data.frame</span><span class="op">(</span>x <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="op">-</span><span class="fl">2.76</span>, <span class="fl">2.46</span>, <span class="op">-</span><span class="fl">1.52</span>, <span class="op">-</span><span class="fl">4.34</span>, <span class="fl">4.54</span>,  <span class="fl">1</span><span class="op">)</span>,</span>
<span>                 y <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="op">-</span><span class="fl">0.81</span>, <span class="op">-</span><span class="fl">0.85</span>, <span class="fl">0.76</span>, <span class="op">-</span><span class="fl">0.41</span>, <span class="op">-</span><span class="fl">1.48</span>,  <span class="fl">0.2</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot </span></span>
<span><span class="va">p_data</span> <span class="op">&lt;-</span> <span class="va">df6</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span><span class="va">x</span>,<span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_point</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="va">p_data</span></span></code></pre>
</div>
<figure><img src="../fig/gaussian-processes-rendered-unnamed-chunk-3-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>We’ll assume <span class="math inline">\(y\)</span> are noisy
observations from some unknown function <span class="math inline">\(f(x)\)</span> for which we’ll give a GP prior.
Because we will not recover any functional (such as polynomial) form for
<span class="math inline">\(f\)</span>, we will only learn the value of
<span class="math inline">\(f\)</span> at separate predetermined
locations <span class="math inline">\(x\)</span>. The covariance
function needs to be computed in all those points. Let’s estimate <span class="math inline">\(f\)</span> on a grid of points spanning the
interval (-5, 5), stored in vector <code>x_pred</code>:</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x_pred</span> <span class="op">&lt;-</span> <span class="fu">seq</span><span class="op">(</span><span class="op">-</span><span class="fl">5</span>, <span class="fl">5</span>, by <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span><span class="va">N_pred</span> <span class="op">&lt;-</span> <span class="fu">length</span><span class="op">(</span><span class="va">x_pred</span><span class="op">)</span></span></code></pre>
</div>
<p>Next we’ll build the Stan program. The model structure is simple: the
model block defines the likelihood as the normal distribution with mean
<span class="math inline">\(f(x)\)</span>:
<code>y ~ normal(f[1:N_data], sigma)</code>. Notice that this is a
vectorized statement so the mean <span class="math inline">\(y_i\)</span> equals <span class="math inline">\(f(x_i)\)</span> for all <span class="math inline">\(i\)</span>.</p>
<p>The parameter vector <code>f</code> contains the values of <span class="math inline">\(f\)</span> corresponding to the data points, in
addition to the locations where we want interpolate. The covariance
function is computed in the transformed data block, where first a vector
of concatenated data and prediction locations is build. For
computational stability, it is customary to add a small value on the
diagonal of the covariance matrix. This ensures that the matrix is
positive semi-definite.</p>
<p>Take a moment to digest the structure of the Stan program.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">STAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode stan" tabindex="0"><code class="sourceCode stan"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>  <span class="co">// Data</span></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N_data;</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>  <span class="dt">real</span> y[N_data];</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>  <span class="dt">real</span> x_data[N_data];</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>  </span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>  <span class="co">// GP hyperparameters</span></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; alpha;</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; lambda;</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>  </span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a>  <span class="co">// Observation error</span></span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; sigma;</span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a>  </span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a>  <span class="co">// Prediction points</span></span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N_pred;</span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a>  <span class="dt">real</span> x_pred[N_pred];</span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a>}</span>
<span id="cb4-18"><a href="#cb4-18" tabindex="-1"></a><span class="kw">transformed data</span> {</span>
<span id="cb4-19"><a href="#cb4-19" tabindex="-1"></a>  <span class="co">// Number of data and prediction points</span></span>
<span id="cb4-20"><a href="#cb4-20" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N = N_data + N_pred;</span>
<span id="cb4-21"><a href="#cb4-21" tabindex="-1"></a>  </span>
<span id="cb4-22"><a href="#cb4-22" tabindex="-1"></a>  <span class="dt">real</span> x[N];</span>
<span id="cb4-23"><a href="#cb4-23" tabindex="-1"></a>  <span class="dt">matrix</span>[N, N] K;</span>
<span id="cb4-24"><a href="#cb4-24" tabindex="-1"></a>  </span>
<span id="cb4-25"><a href="#cb4-25" tabindex="-1"></a>  x[<span class="dv">1</span>:N_data] = x_data;</span>
<span id="cb4-26"><a href="#cb4-26" tabindex="-1"></a>  x[(N_data+<span class="dv">1</span>):N] = x_pred;</span>
<span id="cb4-27"><a href="#cb4-27" tabindex="-1"></a></span>
<span id="cb4-28"><a href="#cb4-28" tabindex="-1"></a>  <span class="co">// Covariance function</span></span>
<span id="cb4-29"><a href="#cb4-29" tabindex="-1"></a>  K = gp_exp_quad_cov(x, alpha, lambda);</span>
<span id="cb4-30"><a href="#cb4-30" tabindex="-1"></a></span>
<span id="cb4-31"><a href="#cb4-31" tabindex="-1"></a>  <span class="co">// Add nugget on diagonal for numerical stability</span></span>
<span id="cb4-32"><a href="#cb4-32" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb4-33"><a href="#cb4-33" tabindex="-1"></a>    K[n, n] = K[n, n] + <span class="fl">1e-6</span>;</span>
<span id="cb4-34"><a href="#cb4-34" tabindex="-1"></a>  }</span>
<span id="cb4-35"><a href="#cb4-35" tabindex="-1"></a></span>
<span id="cb4-36"><a href="#cb4-36" tabindex="-1"></a>}</span>
<span id="cb4-37"><a href="#cb4-37" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb4-38"><a href="#cb4-38" tabindex="-1"></a>  <span class="dt">vector</span>[N] f;</span>
<span id="cb4-39"><a href="#cb4-39" tabindex="-1"></a>}</span>
<span id="cb4-40"><a href="#cb4-40" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb4-41"><a href="#cb4-41" tabindex="-1"></a>  <span class="co">// Likelihood</span></span>
<span id="cb4-42"><a href="#cb4-42" tabindex="-1"></a>  y ~ normal(f[<span class="dv">1</span>:N_data], sigma);</span>
<span id="cb4-43"><a href="#cb4-43" tabindex="-1"></a>  <span class="co">// GP prior</span></span>
<span id="cb4-44"><a href="#cb4-44" tabindex="-1"></a>  f ~ multi_normal(rep_vector(<span class="dv">0</span>, N), K);</span>
<span id="cb4-45"><a href="#cb4-45" tabindex="-1"></a>}</span></code></pre>
</div>
<p>Let’s fit the model. We’ll use hyperparameter values <span class="math inline">\(\lambda = 1\)</span>, <span class="math inline">\(\alpha = 1\)</span> and set the observation error
standard deviation to <span class="math inline">\(\sigma =
0.1\)</span>.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Fit</span></span>
<span><span class="va">gp_samples</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">sampling</span><span class="op">(</span><span class="va">gp_model</span>,</span>
<span>                       <span class="fu">list</span><span class="op">(</span>N_data <span class="op">=</span> <span class="fu">nrow</span><span class="op">(</span><span class="va">df6</span><span class="op">)</span>,</span>
<span>                            x_data <span class="op">=</span> <span class="fu">as.array</span><span class="op">(</span><span class="va">df6</span><span class="op">$</span><span class="va">x</span><span class="op">)</span>,</span>
<span>                            y <span class="op">=</span> <span class="fu">as.array</span><span class="op">(</span><span class="va">df6</span><span class="op">$</span><span class="va">y</span><span class="op">)</span>,</span>
<span>                            lambda <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                            alpha <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                            sigma <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span>                            N_pred <span class="op">=</span> <span class="va">N_pred</span>,</span>
<span>                            x_pred <span class="op">=</span> <span class="va">x_pred</span><span class="op">)</span>,</span>
<span>                       chains <span class="op">=</span> <span class="fl">1</span>, iter <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>
SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1:
Chain 1: Gradient evaluation took 8.4e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.84 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1:
Chain 1:
Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup)
Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup)
Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup)
Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup)
Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup)
Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup)
Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling)
Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling)
Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling)
Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling)
Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling)
Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling)
Chain 1:
Chain 1:  Elapsed Time: 32.263 seconds (Warm-up)
Chain 1:                36.505 seconds (Sampling)
Chain 1:                68.768 seconds (Total)
Chain 1: </code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">WARNING<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="warning" tabindex="0"><code>Warning: There were 496 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 10. See
https://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded</code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">WARNING<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="warning" tabindex="0"><code>Warning: Examine the pairs() plot to diagnose sampling problems</code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">WARNING<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="warning" tabindex="0"><code>Warning: The largest R-hat is 2.12, indicating chains have not mixed.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#r-hat</code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">WARNING<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="warning" tabindex="0"><code>Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#bulk-ess</code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">WARNING<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="warning" tabindex="0"><code>Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#tail-ess</code></pre>
</div>
<p>The inference takes some time (about a minute on a standard laptop)
even though we only use (an insufficient) single chain and 1000
iterations. Stan also throws warnings about convergence issues. Let’s
ignore these at this point, and look at the output.</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">f_samples</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">extract</span><span class="op">(</span><span class="va">gp_samples</span>, <span class="st">"f"</span><span class="op">)</span><span class="op">[[</span><span class="st">"f"</span><span class="op">]</span><span class="op">]</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="va">t</span> <span class="op">%&gt;%</span> <span class="fu">data.frame</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>x <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="va">df6</span><span class="op">$</span><span class="va">x</span>, <span class="va">x_pred</span><span class="op">)</span><span class="op">)</span> <span class="co"># data and prediction locations</span></span>
<span></span>
<span><span class="va">f_samples_l</span> <span class="op">&lt;-</span> <span class="va">f_samples</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">gather</span><span class="op">(</span>key <span class="op">=</span> <span class="st">"sample"</span>, value <span class="op">=</span> <span class="st">"f"</span>, <span class="op">-</span><span class="va">x</span><span class="op">)</span></span>
<span></span>
<span><span class="va">p_f</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span></span>
<span>    data <span class="op">=</span> <span class="va">f_samples_l</span>,</span>
<span>    <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">f</span>, group <span class="op">=</span> <span class="va">sample</span><span class="op">)</span>,</span>
<span>    alpha <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>data <span class="op">=</span> <span class="va">df6</span>, </span>
<span>             <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span>, color <span class="op">=</span><span class="st">"red"</span><span class="op">)</span> </span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="va">p_f</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/gaussian-processes-rendered-unnamed-chunk-7-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>The figure contains the data points in red and samples from the
posterior distribution of <span class="math inline">\(f\)</span> in
black. Each posterior sample corresponds to a function. This
distribution essentially captures the model’s interpretation of the
underlying trend within the data. The estimate for the trend seems
plausible.</p>
<div id="challenge1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>In the figure above, where is the posterior uncertainty the highest
and why? What controls the uncertainty at the locations of the data? If
we made the prediction range wider, say, from -10 to 10, what would the
posterior look like at the extremes?</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<p>Uncertainty grows at locations away from the data points and starts
to resemble the prior. At the data locations, the uncertainty is
controlled by the parameter <span class="math inline">\(\sigma\)</span>.
Far from the data, the posterior would be centered around 0 and have
variance <span class="math inline">\(\alpha^2\)</span>.</p>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="cholesky-parameterization">Cholesky parameterization<a class="anchor" aria-label="anchor" href="#cholesky-parameterization"></a>
</h2>
<hr class="half-width">
<p>Running the previous example look a few minutes even though the
amount data and number of prediction locations was modest. Scalability
is a weak point of Gaussian processes but luckily there is a trick that
can be used to speed up the inference and to improve convergence.</p>
<p>By using the Cholesky decomposition of the covariance function <span class="math inline">\(K = LL^T\)</span>, the target function <span class="math inline">\(f\)</span> can be reparameterized as <span class="math inline">\(f = \mu + L\eta\)</span>. Now, if the random
variable <span class="math inline">\(\eta\)</span> is distributed as
multivariate normal with mean 0 and identity covariance matrix, it
implies that <span class="math inline">\(f \sim GP(\mu, K)\)</span>.</p>
<p>The Stan program below implements this parameterization. The Cholesky
decomposition is performed at the end of the transformed data block and
the reparameterization in the transformed parameters block. The
likelihood statement is unchanged but prior is now given for <span class="math inline">\(\eta\)</span>. Other parts of the program are
identical to the previous example.</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">STAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode stan" tabindex="0"><code class="sourceCode stan"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>  <span class="co">// Data</span></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N_data;</span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>  <span class="dt">real</span> y[N_data];</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>  <span class="dt">real</span> x_data[N_data];</span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a>  </span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a>  <span class="co">// GP hyperparameters</span></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; alpha;</span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; lambda;</span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a>  </span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; sigma;</span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a>  </span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a>  <span class="co">// Prediction points</span></span>
<span id="cb13-14"><a href="#cb13-14" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N_pred;</span>
<span id="cb13-15"><a href="#cb13-15" tabindex="-1"></a>  <span class="dt">real</span> x_pred[N_pred];</span>
<span id="cb13-16"><a href="#cb13-16" tabindex="-1"></a>}</span>
<span id="cb13-17"><a href="#cb13-17" tabindex="-1"></a><span class="kw">transformed data</span> {</span>
<span id="cb13-18"><a href="#cb13-18" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N = N_data + N_pred;</span>
<span id="cb13-19"><a href="#cb13-19" tabindex="-1"></a>  </span>
<span id="cb13-20"><a href="#cb13-20" tabindex="-1"></a>  <span class="dt">real</span> x[N];</span>
<span id="cb13-21"><a href="#cb13-21" tabindex="-1"></a>  <span class="dt">matrix</span>[N, N] K;</span>
<span id="cb13-22"><a href="#cb13-22" tabindex="-1"></a>  <span class="dt">matrix</span>[N, N] L;</span>
<span id="cb13-23"><a href="#cb13-23" tabindex="-1"></a>  </span>
<span id="cb13-24"><a href="#cb13-24" tabindex="-1"></a>  x[<span class="dv">1</span>:N_data] = x_data;</span>
<span id="cb13-25"><a href="#cb13-25" tabindex="-1"></a>  x[(N_data+<span class="dv">1</span>):N] = x_pred;</span>
<span id="cb13-26"><a href="#cb13-26" tabindex="-1"></a></span>
<span id="cb13-27"><a href="#cb13-27" tabindex="-1"></a>  <span class="co">// Covariance function</span></span>
<span id="cb13-28"><a href="#cb13-28" tabindex="-1"></a>  K = gp_exp_quad_cov(x, alpha, lambda);</span>
<span id="cb13-29"><a href="#cb13-29" tabindex="-1"></a>  </span>
<span id="cb13-30"><a href="#cb13-30" tabindex="-1"></a>  <span class="co">// Add nugget on diagonal for numerical stability</span></span>
<span id="cb13-31"><a href="#cb13-31" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb13-32"><a href="#cb13-32" tabindex="-1"></a>    K[n, n] = K[n, n] + <span class="fl">1e-6</span>;</span>
<span id="cb13-33"><a href="#cb13-33" tabindex="-1"></a>  }</span>
<span id="cb13-34"><a href="#cb13-34" tabindex="-1"></a></span>
<span id="cb13-35"><a href="#cb13-35" tabindex="-1"></a>  L = cholesky_decompose(K);</span>
<span id="cb13-36"><a href="#cb13-36" tabindex="-1"></a>}</span>
<span id="cb13-37"><a href="#cb13-37" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb13-38"><a href="#cb13-38" tabindex="-1"></a>  <span class="dt">vector</span>[N] eta;</span>
<span id="cb13-39"><a href="#cb13-39" tabindex="-1"></a>}</span>
<span id="cb13-40"><a href="#cb13-40" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span>
<span id="cb13-41"><a href="#cb13-41" tabindex="-1"></a>  <span class="co">// mu = (0, 0, ..., 0)</span></span>
<span id="cb13-42"><a href="#cb13-42" tabindex="-1"></a>  <span class="dt">vector</span>[N] f = L*eta;</span>
<span id="cb13-43"><a href="#cb13-43" tabindex="-1"></a>}</span>
<span id="cb13-44"><a href="#cb13-44" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb13-45"><a href="#cb13-45" tabindex="-1"></a>  <span class="co">// Likelihood</span></span>
<span id="cb13-46"><a href="#cb13-46" tabindex="-1"></a>  y ~ normal(f[<span class="dv">1</span>:N_data], sigma);</span>
<span id="cb13-47"><a href="#cb13-47" tabindex="-1"></a>  <span class="co">// GP</span></span>
<span id="cb13-48"><a href="#cb13-48" tabindex="-1"></a>  eta ~ normal(<span class="dv">0</span>, <span class="dv">1</span>);</span>
<span id="cb13-49"><a href="#cb13-49" tabindex="-1"></a>}</span></code></pre>
</div>
<p>Let’s compile and fit this model using the same data. Fitting is
completed in a few seconds with no convergence issues:</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">gp_cholesky_samples</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">sampling</span><span class="op">(</span><span class="va">gp_cholesky_model</span>,</span>
<span>                       <span class="fu">list</span><span class="op">(</span>N_data <span class="op">=</span> <span class="fu">nrow</span><span class="op">(</span><span class="va">df6</span><span class="op">)</span>,</span>
<span>                            x_data <span class="op">=</span> <span class="fu">as.array</span><span class="op">(</span><span class="va">df6</span><span class="op">$</span><span class="va">x</span><span class="op">)</span>,</span>
<span>                            y <span class="op">=</span> <span class="fu">as.array</span><span class="op">(</span><span class="va">df6</span><span class="op">$</span><span class="va">y</span><span class="op">)</span>,</span>
<span>                            lambda <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                            alpha <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                            sigma <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span>                            N_pred <span class="op">=</span> <span class="va">N_pred</span>,</span>
<span>                            x_pred <span class="op">=</span> <span class="va">x_pred</span><span class="op">)</span>,</span>
<span>                       chains <span class="op">=</span> <span class="fl">1</span>, iter <span class="op">=</span> <span class="fl">2000</span>, </span>
<span>                       refresh <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span></code></pre>
</div>
<p>Let’s examine the results. How is the posterior different from the
one recovered without the Cholesky parameterization?</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">f_cholesky_samples</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">extract</span><span class="op">(</span><span class="va">gp_cholesky_samples</span>, <span class="st">"f"</span><span class="op">)</span><span class="op">[[</span><span class="st">"f"</span><span class="op">]</span><span class="op">]</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="va">t</span> <span class="op">%&gt;%</span> <span class="fu">data.frame</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>x <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="va">df6</span><span class="op">$</span><span class="va">x</span>, <span class="va">x_pred</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">f_cholesky_samples_l</span> <span class="op">&lt;-</span> <span class="va">f_cholesky_samples</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">gather</span><span class="op">(</span>key <span class="op">=</span> <span class="st">"sample"</span>, value <span class="op">=</span> <span class="st">"f"</span>, <span class="op">-</span><span class="va">x</span><span class="op">)</span></span>
<span></span>
<span><span class="va">p_cholesky_f</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span></span>
<span>    data <span class="op">=</span> <span class="va">f_cholesky_samples_l</span>,</span>
<span>    <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">f</span>, group <span class="op">=</span> <span class="va">sample</span><span class="op">)</span>,</span>
<span>    alpha <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>data <span class="op">=</span> <span class="va">df6</span>, </span>
<span>             <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span>, color <span class="op">=</span><span class="st">"red"</span><span class="op">)</span> </span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="va">p_cholesky_f</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/gaussian-processes-rendered-unnamed-chunk-10-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><div id="challenge2" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>For the previous example, compute the posterior probability for <span class="math inline">\(f(0) &gt; 0\)</span>.</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" data-bs-parent="#accordionSolution2" aria-labelledby="headingSolution2">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Marginal posterior at x == 0</span></span>
<span><span class="va">posterior_at_0</span> <span class="op">&lt;-</span> <span class="va">f_cholesky_samples_l</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">filter</span><span class="op">(</span><span class="va">x</span> <span class="op">==</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">mean</span><span class="op">(</span><span class="va">posterior_at_0</span> <span class="op">&gt;</span> <span class="fl">0</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[1] 0.5946667</code></pre>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="example-2-logistic-gaussian-process-regression">Example 2: Logistic Gaussian process regression<a class="anchor" aria-label="anchor" href="#example-2-logistic-gaussian-process-regression"></a>
</h2>
<hr class="half-width">
<p>Gaussian processes can also be used as priors in models where the
relationship between the explanatory and response variables is more
complex.</p>
<p>Consider, for example, predicting the presence of some insect species
in different regions based on average annual temperature. Now the
response variable <span class="math inline">\(y\)</span> is binary with
<span class="math inline">\(y=0\)</span> and <span class="math inline">\(y=1\)</span> corresponding to absence and
presence, respectfully.</p>
<p>The following simulated data contains observations from 40 locations
including presence/absence observations for an insect species and yearly
average temperature. Plotting the data suggests there is a temperature
range where the species can exists.</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">insect</span> <span class="op">&lt;-</span> <span class="fu">data.frame</span><span class="op">(</span></span>
<span>  x <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="fl">1.74</span>, <span class="fl">13.46</span>, <span class="fl">3.69</span>, <span class="fl">16.09</span>, <span class="fl">8.52</span>, <span class="fl">11.11</span>, <span class="fl">19.32</span>, <span class="fl">5.79</span>, <span class="fl">11.44</span>, <span class="fl">2.32</span>, <span class="fl">0.67</span>, <span class="fl">23.29</span>, <span class="fl">14.1</span>, <span class="fl">16.96</span>, <span class="fl">16.29</span>, <span class="fl">20.16</span>, <span class="fl">12.68</span>, <span class="fl">3.61</span>, <span class="fl">14.22</span>, <span class="fl">11.1</span>, <span class="fl">8.02</span>, <span class="fl">13.35</span>, <span class="fl">24.48</span>, <span class="fl">4.04</span>, <span class="fl">21.41</span>, <span class="fl">6.64</span>, <span class="fl">1.36</span>, <span class="fl">8.97</span>, <span class="fl">17.87</span>, <span class="fl">3.51</span>, <span class="fl">15.68</span>, <span class="fl">8.12</span>, <span class="fl">1.38</span>, <span class="fl">13.39</span>, <span class="fl">3.01</span>, <span class="fl">13.84</span>, <span class="fl">5.29</span>, <span class="fl">20.13</span>, <span class="fl">5.57</span>, <span class="fl">24.51</span>, <span class="fl">3.94</span>, <span class="fl">17.53</span>, <span class="fl">10.62</span>, <span class="fl">3.26</span>, <span class="fl">19.78</span>, <span class="fl">21.93</span>, <span class="fl">21.47</span>, <span class="fl">18.3</span>, <span class="fl">15.91</span>, <span class="fl">8.51</span><span class="op">)</span>,</span>
<span>  y <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="va">insect</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="va">p</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/gaussian-processes-rendered-unnamed-chunk-13-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>One way of modeling presence/absence data is with logistic
regression:</p>
<p><span class="math display">\[ y \sim \text{Bernoulli}(\theta) \\
\theta = \frac{1}{1 + e^{-(\alpha + \beta x)}},\]</span> where <span class="math inline">\(\alpha, \beta\)</span> are real numbers and <span class="math inline">\(\theta\)</span> is the probability of <span class="math inline">\(y = 1\)</span>.</p>
<p>However, in this standard form, the relationship between temperature
and presence is monotonous: assuming <span class="math inline">\(\beta
&gt; 0\)</span>, higher temperatures imply higher probability of
presence. This is in disagreement with the data and, of course, with
reality. For this reason, we will modify the model so that the term
<span class="math inline">\(\beta x\)</span> is replaced with a
non-parametric function <span class="math inline">\(f(x)\)</span>, that
is given a GP prior. For the baseline parameter <span class="math inline">\(\alpha\)</span>, we will use a normal prior <span class="math inline">\(N(0, 10)\)</span>.</p>
<p>In the model block, we utilize the built-in Stan function
<code>bernoulli_logit</code> to write the likelihood statement. The
probability of presence as a function of temperature <span class="math inline">\(\theta\)</span> is generated in the generated
quantities block.</p>
<div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">STAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode stan" tabindex="0"><code class="sourceCode stan"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a>  <span class="co">// Data</span></span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N_data;</span>
<span id="cb19-4"><a href="#cb19-4" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>, <span class="kw">upper</span>=<span class="dv">1</span>&gt; y[N_data];</span>
<span id="cb19-5"><a href="#cb19-5" tabindex="-1"></a>  <span class="dt">real</span> x_data[N_data];</span>
<span id="cb19-6"><a href="#cb19-6" tabindex="-1"></a></span>
<span id="cb19-7"><a href="#cb19-7" tabindex="-1"></a>  <span class="co">// Prediction points</span></span>
<span id="cb19-8"><a href="#cb19-8" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N_pred;</span>
<span id="cb19-9"><a href="#cb19-9" tabindex="-1"></a>  <span class="dt">real</span> x_pred[N_pred];</span>
<span id="cb19-10"><a href="#cb19-10" tabindex="-1"></a></span>
<span id="cb19-11"><a href="#cb19-11" tabindex="-1"></a>  <span class="co">// GP hyperparameters</span></span>
<span id="cb19-12"><a href="#cb19-12" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; alpha;</span>
<span id="cb19-13"><a href="#cb19-13" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; lambda;</span>
<span id="cb19-14"><a href="#cb19-14" tabindex="-1"></a>}</span>
<span id="cb19-15"><a href="#cb19-15" tabindex="-1"></a><span class="kw">transformed data</span> {</span>
<span id="cb19-16"><a href="#cb19-16" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N = N_data + N_pred;</span>
<span id="cb19-17"><a href="#cb19-17" tabindex="-1"></a></span>
<span id="cb19-18"><a href="#cb19-18" tabindex="-1"></a>  <span class="dt">real</span> x[N];</span>
<span id="cb19-19"><a href="#cb19-19" tabindex="-1"></a>  <span class="dt">matrix</span>[N, N] K;</span>
<span id="cb19-20"><a href="#cb19-20" tabindex="-1"></a>  <span class="dt">matrix</span>[N, N] L;</span>
<span id="cb19-21"><a href="#cb19-21" tabindex="-1"></a></span>
<span id="cb19-22"><a href="#cb19-22" tabindex="-1"></a>  x[<span class="dv">1</span>:N_data] = x_data;</span>
<span id="cb19-23"><a href="#cb19-23" tabindex="-1"></a>  x[(N_data+<span class="dv">1</span>):N] = x_pred;</span>
<span id="cb19-24"><a href="#cb19-24" tabindex="-1"></a></span>
<span id="cb19-25"><a href="#cb19-25" tabindex="-1"></a>  <span class="co">// Covariance function</span></span>
<span id="cb19-26"><a href="#cb19-26" tabindex="-1"></a>  K = gp_exp_quad_cov(x, alpha, lambda);</span>
<span id="cb19-27"><a href="#cb19-27" tabindex="-1"></a></span>
<span id="cb19-28"><a href="#cb19-28" tabindex="-1"></a>  <span class="co">// Add nugget on diagonal for numerical stability</span></span>
<span id="cb19-29"><a href="#cb19-29" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb19-30"><a href="#cb19-30" tabindex="-1"></a>    K[n, n] = K[n, n] + <span class="fl">1e-6</span>;</span>
<span id="cb19-31"><a href="#cb19-31" tabindex="-1"></a>  }</span>
<span id="cb19-32"><a href="#cb19-32" tabindex="-1"></a></span>
<span id="cb19-33"><a href="#cb19-33" tabindex="-1"></a>  L = cholesky_decompose(K);</span>
<span id="cb19-34"><a href="#cb19-34" tabindex="-1"></a></span>
<span id="cb19-35"><a href="#cb19-35" tabindex="-1"></a>}</span>
<span id="cb19-36"><a href="#cb19-36" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb19-37"><a href="#cb19-37" tabindex="-1"></a>  <span class="dt">real</span> a;</span>
<span id="cb19-38"><a href="#cb19-38" tabindex="-1"></a>  <span class="dt">vector</span>[N] eta;</span>
<span id="cb19-39"><a href="#cb19-39" tabindex="-1"></a>}</span>
<span id="cb19-40"><a href="#cb19-40" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span>
<span id="cb19-41"><a href="#cb19-41" tabindex="-1"></a>  <span class="co">// mu = (0, 0, ..., 0)</span></span>
<span id="cb19-42"><a href="#cb19-42" tabindex="-1"></a>  <span class="dt">vector</span>[N] f = L*eta;</span>
<span id="cb19-43"><a href="#cb19-43" tabindex="-1"></a>}</span>
<span id="cb19-44"><a href="#cb19-44" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb19-45"><a href="#cb19-45" tabindex="-1"></a></span>
<span id="cb19-46"><a href="#cb19-46" tabindex="-1"></a>  <span class="co">// Likelihood</span></span>
<span id="cb19-47"><a href="#cb19-47" tabindex="-1"></a>  y ~ bernoulli_logit(a + f[<span class="dv">1</span>:N_data]);</span>
<span id="cb19-48"><a href="#cb19-48" tabindex="-1"></a>  <span class="co">// Priors</span></span>
<span id="cb19-49"><a href="#cb19-49" tabindex="-1"></a>  a ~ normal(<span class="dv">0</span>, <span class="dv">10</span>);</span>
<span id="cb19-50"><a href="#cb19-50" tabindex="-1"></a>  eta ~ normal(<span class="dv">0</span>, <span class="dv">1</span>);</span>
<span id="cb19-51"><a href="#cb19-51" tabindex="-1"></a>}</span>
<span id="cb19-52"><a href="#cb19-52" tabindex="-1"></a><span class="kw">generated quantities</span>{</span>
<span id="cb19-53"><a href="#cb19-53" tabindex="-1"></a>  <span class="dt">vector</span>[N] theta = <span class="dv">1</span> / (<span class="dv">1</span> + exp(-(alpha + f)));</span>
<span id="cb19-54"><a href="#cb19-54" tabindex="-1"></a>}</span></code></pre>
</div>
<p>Let’s fit the model and extract the posterior summary of <span class="math inline">\(\theta\)</span>.</p>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x_pred</span> <span class="op">&lt;-</span> <span class="fu">seq</span><span class="op">(</span><span class="fu">min</span><span class="op">(</span><span class="va">insect</span><span class="op">$</span><span class="va">x</span><span class="op">)</span>, <span class="fu">max</span><span class="op">(</span><span class="va">insect</span><span class="op">$</span><span class="va">x</span><span class="op">)</span>, length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span><span class="va">N_pred</span> <span class="op">&lt;-</span> <span class="fu">length</span><span class="op">(</span><span class="va">x_pred</span><span class="op">)</span></span>
<span></span>
<span><span class="va">logistic_gp_fit</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">sampling</span><span class="op">(</span><span class="va">logistic_gp_model</span>,</span>
<span>                                   <span class="fu">list</span><span class="op">(</span>N_data <span class="op">=</span> <span class="fu">nrow</span><span class="op">(</span><span class="va">insect</span><span class="op">)</span>,</span>
<span>                                        y <span class="op">=</span> <span class="va">insect</span><span class="op">$</span><span class="va">y</span>,</span>
<span>                                        x_data <span class="op">=</span> <span class="va">insect</span><span class="op">$</span><span class="va">x</span>,</span>
<span>                                        alpha <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                                        lambda <span class="op">=</span> <span class="fl">3</span>,</span>
<span>                                        N_pred <span class="op">=</span> <span class="va">N_pred</span>,</span>
<span>                                        x_pred <span class="op">=</span> <span class="va">x_pred</span><span class="op">)</span>,</span>
<span>                                   refresh <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="va">theta_summary</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">summary</span><span class="op">(</span><span class="va">logistic_gp_fit</span>, <span class="st">"theta"</span><span class="op">)</span><span class="op">$</span><span class="va">summary</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">data.frame</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">select</span><span class="op">(</span>lower_2.5 <span class="op">=</span> <span class="va">X2.5.</span>, <span class="va">mean</span>, upper_97.5 <span class="op">=</span> <span class="va">X97.5.</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>x <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="va">insect</span><span class="op">$</span><span class="va">x</span>, <span class="va">x_pred</span><span class="op">)</span><span class="op">)</span></span></code></pre>
</div>
<p>Then we’ll look at the posterior of <span class="math inline">\(\theta\)</span>, the probability of presence of
the species and overlay it with the data. The posterior looks reasonable
in the sense that the posterior of <span class="math inline">\(\theta\)</span> is higher in the temperature range
where presence was observed. However, the posterior values seem too high
across the temperature range and, moreover, start veering up at the
ends. Why might this be?</p>
<div class="codewrapper sourceCode" id="cb21">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">p_theta</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_ribbon</span><span class="op">(</span>data <span class="op">=</span> <span class="va">theta_summary</span>,</span>
<span>              <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, ymin <span class="op">=</span> <span class="va">lower_2.5</span>, ymax <span class="op">=</span> <span class="va">upper_97.5</span><span class="op">)</span>,</span>
<span>              fill <span class="op">=</span> <span class="va">posterior_color</span>, alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>data <span class="op">=</span> <span class="va">theta_summary</span>,</span>
<span>            <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">mean</span><span class="op">)</span>, color <span class="op">=</span> <span class="va">posterior_color</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>data <span class="op">=</span> <span class="va">insect</span>,</span>
<span>             <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">p_theta</span></span></code></pre>
</div>
<figure><img src="../fig/gaussian-processes-rendered-unnamed-chunk-16-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><div id="challenge3" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>Think of ways to modify the Stan program for the logistic GP
regression so that the posterior behavior is more reasonable in the
prediction range.</p>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3"> Show me the solution </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" data-bs-parent="#accordionSolution3" aria-labelledby="headingSolution3">
<div class="accordion-body">
<p>Let’s modify the program by setting the GP mean to a negative value
and treating the length scale as a parameter.</p>
<div class="codewrapper sourceCode" id="cb22">
<h3 class="code-label">STAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode stan" tabindex="0"><code class="sourceCode stan"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a>  <span class="co">// Data</span></span>
<span id="cb22-3"><a href="#cb22-3" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N_data;</span>
<span id="cb22-4"><a href="#cb22-4" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>, <span class="kw">upper</span>=<span class="dv">1</span>&gt; y[N_data];</span>
<span id="cb22-5"><a href="#cb22-5" tabindex="-1"></a>  <span class="dt">real</span> x_data[N_data];</span>
<span id="cb22-6"><a href="#cb22-6" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" tabindex="-1"></a>  <span class="co">// Prediction points</span></span>
<span id="cb22-8"><a href="#cb22-8" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N_pred;</span>
<span id="cb22-9"><a href="#cb22-9" tabindex="-1"></a>  <span class="dt">real</span> x_pred[N_pred];</span>
<span id="cb22-10"><a href="#cb22-10" tabindex="-1"></a></span>
<span id="cb22-11"><a href="#cb22-11" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; alpha;</span>
<span id="cb22-12"><a href="#cb22-12" tabindex="-1"></a>}</span>
<span id="cb22-13"><a href="#cb22-13" tabindex="-1"></a><span class="kw">transformed data</span> {</span>
<span id="cb22-14"><a href="#cb22-14" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N = N_data + N_pred;</span>
<span id="cb22-15"><a href="#cb22-15" tabindex="-1"></a>  <span class="dt">real</span> x[N];</span>
<span id="cb22-16"><a href="#cb22-16" tabindex="-1"></a>  x[<span class="dv">1</span>:N_data] = x_data;</span>
<span id="cb22-17"><a href="#cb22-17" tabindex="-1"></a>  x[(N_data+<span class="dv">1</span>):N] = x_pred;</span>
<span id="cb22-18"><a href="#cb22-18" tabindex="-1"></a>}</span>
<span id="cb22-19"><a href="#cb22-19" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb22-20"><a href="#cb22-20" tabindex="-1"></a>  <span class="dt">real</span> a;</span>
<span id="cb22-21"><a href="#cb22-21" tabindex="-1"></a>  <span class="dt">vector</span>[N] eta;</span>
<span id="cb22-22"><a href="#cb22-22" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; lambda;</span>
<span id="cb22-23"><a href="#cb22-23" tabindex="-1"></a>}</span>
<span id="cb22-24"><a href="#cb22-24" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span>
<span id="cb22-25"><a href="#cb22-25" tabindex="-1"></a></span>
<span id="cb22-26"><a href="#cb22-26" tabindex="-1"></a>  <span class="dt">matrix</span>[N, N] K;</span>
<span id="cb22-27"><a href="#cb22-27" tabindex="-1"></a>  <span class="dt">matrix</span>[N, N] L;</span>
<span id="cb22-28"><a href="#cb22-28" tabindex="-1"></a>  <span class="dt">vector</span>[N] f;</span>
<span id="cb22-29"><a href="#cb22-29" tabindex="-1"></a></span>
<span id="cb22-30"><a href="#cb22-30" tabindex="-1"></a>  <span class="co">// Covariance function</span></span>
<span id="cb22-31"><a href="#cb22-31" tabindex="-1"></a>  K = gp_exp_quad_cov(x, alpha, lambda);</span>
<span id="cb22-32"><a href="#cb22-32" tabindex="-1"></a></span>
<span id="cb22-33"><a href="#cb22-33" tabindex="-1"></a>  <span class="co">// Add nugget on diagonal for numerical stability</span></span>
<span id="cb22-34"><a href="#cb22-34" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb22-35"><a href="#cb22-35" tabindex="-1"></a>    K[n, n] = K[n, n] + <span class="fl">1e-6</span>;</span>
<span id="cb22-36"><a href="#cb22-36" tabindex="-1"></a>  }</span>
<span id="cb22-37"><a href="#cb22-37" tabindex="-1"></a></span>
<span id="cb22-38"><a href="#cb22-38" tabindex="-1"></a>  L = cholesky_decompose(K);</span>
<span id="cb22-39"><a href="#cb22-39" tabindex="-1"></a>  f = rep_vector(-<span class="dv">3</span>, N) + L*eta;</span>
<span id="cb22-40"><a href="#cb22-40" tabindex="-1"></a>}</span>
<span id="cb22-41"><a href="#cb22-41" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb22-42"><a href="#cb22-42" tabindex="-1"></a>  <span class="co">// Likelihood</span></span>
<span id="cb22-43"><a href="#cb22-43" tabindex="-1"></a>  y ~ bernoulli_logit(a + f[<span class="dv">1</span>:N_data]);</span>
<span id="cb22-44"><a href="#cb22-44" tabindex="-1"></a>  <span class="co">// Priors</span></span>
<span id="cb22-45"><a href="#cb22-45" tabindex="-1"></a>  a ~ normal(<span class="dv">0</span>, <span class="dv">10</span>);</span>
<span id="cb22-46"><a href="#cb22-46" tabindex="-1"></a>  eta ~ normal(<span class="dv">0</span>, <span class="dv">1</span>);</span>
<span id="cb22-47"><a href="#cb22-47" tabindex="-1"></a>  lambda ~ gamma(<span class="dv">2</span>, <span class="dv">1</span>);</span>
<span id="cb22-48"><a href="#cb22-48" tabindex="-1"></a>}</span>
<span id="cb22-49"><a href="#cb22-49" tabindex="-1"></a><span class="kw">generated quantities</span>{</span>
<span id="cb22-50"><a href="#cb22-50" tabindex="-1"></a>  <span class="dt">vector</span>[N] theta = <span class="dv">1</span> / (<span class="dv">1</span> + exp(-(alpha + f)));</span>
<span id="cb22-51"><a href="#cb22-51" tabindex="-1"></a>}</span></code></pre>
</div>
<p>Refit the model and check posterior</p>
<div class="codewrapper sourceCode" id="cb23">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">logistic_gp_fit2</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">sampling</span><span class="op">(</span><span class="va">logistic_gp_model2</span>,</span>
<span>                                   <span class="fu">list</span><span class="op">(</span>N_data <span class="op">=</span> <span class="fu">nrow</span><span class="op">(</span><span class="va">insect</span><span class="op">)</span>,</span>
<span>                                        y <span class="op">=</span> <span class="va">insect</span><span class="op">$</span><span class="va">y</span>,</span>
<span>                                        x_data <span class="op">=</span> <span class="va">insect</span><span class="op">$</span><span class="va">x</span>,</span>
<span>                                        alpha <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                                        N_pred <span class="op">=</span> <span class="va">N_pred</span>,</span>
<span>                                        x_pred <span class="op">=</span> <span class="va">x_pred</span><span class="op">)</span>,</span>
<span>                                   chains <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>
SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1:
Chain 1: Gradient evaluation took 0.001276 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 12.76 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1:
Chain 1:
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1:
Chain 1:  Elapsed Time: 17.856 seconds (Warm-up)
Chain 1:                17.438 seconds (Sampling)
Chain 1:                35.294 seconds (Total)
Chain 1: </code></pre>
</div>
<div class="codewrapper sourceCode" id="cb25">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">theta_summary2</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">summary</span><span class="op">(</span><span class="va">logistic_gp_fit2</span>, <span class="st">"theta"</span><span class="op">)</span><span class="op">$</span><span class="va">summary</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">data.frame</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">select</span><span class="op">(</span>lower_2.5 <span class="op">=</span> <span class="va">X2.5.</span>, <span class="va">mean</span>, upper_97.5 <span class="op">=</span> <span class="va">X97.5.</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>x <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="va">insect</span><span class="op">$</span><span class="va">x</span>, <span class="va">x_pred</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">p_theta2</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_ribbon</span><span class="op">(</span>data <span class="op">=</span> <span class="va">theta_summary2</span>,</span>
<span>              <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, ymin <span class="op">=</span> <span class="va">lower_2.5</span>, ymax <span class="op">=</span> <span class="va">upper_97.5</span><span class="op">)</span>,</span>
<span>              fill <span class="op">=</span> <span class="va">posterior_color</span>, alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>data <span class="op">=</span> <span class="va">theta_summary2</span>,</span>
<span>            <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">mean</span><span class="op">)</span>, color <span class="op">=</span> <span class="va">posterior_color</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>data <span class="op">=</span> <span class="va">insect</span>,</span>
<span>             <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">p_theta2</span></span></code></pre>
</div>
<figure><img src="../fig/gaussian-processes-rendered-unnamed-chunk-18-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure>
</div>
</div>
</div>
</div>
<div id="discussion2" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<span class="callout-header">Discussion</span>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>Generate a posterior for the optimal temperature.</p>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>GPs provide a means for non-parametric regression.</li>
<li>A GP has two parameters: mean, and covariance.</li>
<li>GPs can be used a part of more complex models.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-stan-extensions"><p>Content from <a href="stan-extensions.html">Stan extensions</a></p>
<hr>
<p>Last updated on 2025-08-22 |

        <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/edit/main/episodes/stan-extensions.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 12 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>Which packages take advantage of Stan and how to use them?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Learn to use Stan with additional R packages</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>In this chapter, we will introduce packages that take advantage of
Stan. The covered packages are <code>loo</code>, which enables
approximate Bayesian cross-validation, <code>bayesplot</code>, which
contains plotting tools, and <code>brms</code>, which allows calling
Stan using common R syntax, without having to write the Stan code.</p>
<section><h2 class="section-heading" id="loo">
<code>loo</code><a class="anchor" aria-label="anchor" href="#loo"></a>
</h2>
<hr class="half-width">
<p>The <code>loo</code> package allows computing approximate
leave-one-out cross-validation (loo-cv) for models fitted with Stan. The
approximation is based on something called Pareto smoothed importance
sampling (PSIS) [1]. The package can also be used for computing WAIC and
model weights for average predictive distributions.</p>
<div class="section level3">
<h3 id="example-1">Example 1<a class="anchor" aria-label="anchor" href="#example-1"></a>
</h3>
<p>We will demonstrate <code>loo</code> package usage on the model
comparison example studied in Episode 5. We will fit the normal and
Cauchy models on the same synthetic data, then use the tools provided in
<code>loo</code> to compute and compare the approximate loo-cv scores
for these two models.</p>
<p>To be able to utilize the package functions, we need to add a
log-likelihood computation in the Stan code, in the generated quantities
block. The object containing the log-likelihood needs to be named
<code>log_lik</code> so the ‘loo’ functions can find it. Below, we
demonstrate this with the two models we are comparing.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">STAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode stan" tabindex="0"><code class="sourceCode stan"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co">// Normal model</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N;</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>  <span class="dt">vector</span>[N] X;</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>}</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; sigma;</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>  <span class="dt">real</span> mu;</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>}</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a>  X ~ normal(mu, sigma);</span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a>  </span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>  mu ~ normal(<span class="dv">0</span>, <span class="dv">1</span>);</span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>  sigma ~ gamma(<span class="dv">2</span>, <span class="dv">1</span>);</span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a>}</span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a><span class="kw">generated quantities</span> {</span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>  <span class="dt">vector</span>[N] X_rep;</span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a>  </span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a>    X_rep[i] = normal_rng(mu, sigma);</span>
<span id="cb1-22"><a href="#cb1-22" tabindex="-1"></a>  }</span>
<span id="cb1-23"><a href="#cb1-23" tabindex="-1"></a>  </span>
<span id="cb1-24"><a href="#cb1-24" tabindex="-1"></a>  <span class="co">// Calculating log-likelihood for loo</span></span>
<span id="cb1-25"><a href="#cb1-25" tabindex="-1"></a>  <span class="dt">vector</span>[N] log_lik;</span>
<span id="cb1-26"><a href="#cb1-26" tabindex="-1"></a>  </span>
<span id="cb1-27"><a href="#cb1-27" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb1-28"><a href="#cb1-28" tabindex="-1"></a>  log_lik[i] = normal_lpdf(X[i] | mu, sigma);</span>
<span id="cb1-29"><a href="#cb1-29" tabindex="-1"></a>  }</span>
<span id="cb1-30"><a href="#cb1-30" tabindex="-1"></a>}</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">STAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode stan" tabindex="0"><code class="sourceCode stan"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co">// Cauchy model</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N;</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>  <span class="dt">vector</span>[N] X;</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>}</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>  <span class="co">// Scale</span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; sigma;</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>  <span class="co">// location</span></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a>  <span class="dt">real</span> mu;</span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>}</span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a>  <span class="co">// location = mu and scale = sigma</span></span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a>  X ~ cauchy(mu, sigma);</span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a>  </span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a>  mu ~ normal(<span class="dv">0</span>, <span class="dv">1</span>);</span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a>  sigma ~ gamma(<span class="dv">2</span>, <span class="dv">1</span>);</span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a>}</span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a><span class="kw">generated quantities</span> {</span>
<span id="cb2-20"><a href="#cb2-20" tabindex="-1"></a>  <span class="dt">vector</span>[N] X_rep;</span>
<span id="cb2-21"><a href="#cb2-21" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb2-22"><a href="#cb2-22" tabindex="-1"></a>    X_rep[i] = cauchy_rng(mu, sigma);</span>
<span id="cb2-23"><a href="#cb2-23" tabindex="-1"></a>  }</span>
<span id="cb2-24"><a href="#cb2-24" tabindex="-1"></a>  </span>
<span id="cb2-25"><a href="#cb2-25" tabindex="-1"></a>  <span class="co">// Calculating log-likelihood for loo</span></span>
<span id="cb2-26"><a href="#cb2-26" tabindex="-1"></a>  <span class="dt">vector</span>[N] log_lik;</span>
<span id="cb2-27"><a href="#cb2-27" tabindex="-1"></a>  </span>
<span id="cb2-28"><a href="#cb2-28" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb2-29"><a href="#cb2-29" tabindex="-1"></a>  log_lik[i] = cauchy_lpdf(X[i] | mu, sigma);</span>
<span id="cb2-30"><a href="#cb2-30" tabindex="-1"></a>  }</span>
<span id="cb2-31"><a href="#cb2-31" tabindex="-1"></a>}</span></code></pre>
</div>
<p>Now we can fit the models in the usual way.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Fit normal model</span></span>
<span><span class="va">normal_fit</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">sampling</span><span class="op">(</span><span class="va">normal_model_loo</span>,</span>
<span>                       <span class="fu">list</span><span class="op">(</span>N <span class="op">=</span> <span class="va">N</span>, X <span class="op">=</span> <span class="va">df5</span><span class="op">$</span><span class="va">X</span><span class="op">)</span>, </span>
<span>                       refresh <span class="op">=</span> <span class="fl">0</span>, seed <span class="op">=</span> <span class="fl">2024</span><span class="op">)</span></span>
<span><span class="co"># Fit cauchy model</span></span>
<span><span class="va">cauchy_fit</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">sampling</span><span class="op">(</span><span class="va">cauchy_model_loo</span>,</span>
<span>                       <span class="fu">list</span><span class="op">(</span>N <span class="op">=</span> <span class="va">N</span>, X <span class="op">=</span> <span class="va">df5</span><span class="op">$</span><span class="va">X</span><span class="op">)</span>, </span>
<span>                       refresh <span class="op">=</span> <span class="fl">0</span>, seed <span class="op">=</span> <span class="fl">2024</span><span class="op">)</span></span></code></pre>
</div>
<p>We can now compute PSIS-LOO for both of the models with
<code>loo::loo</code> function. After the calling the function,
information about the fit can be viewed by printing the <code>loo</code>
objects.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># PSIS-LOO computation for normal model</span></span>
<span><span class="va">normal_loo</span> <span class="op">&lt;-</span> <span class="fu">loo</span><span class="fu">::</span><span class="fu">loo</span><span class="op">(</span><span class="va">normal_fit</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">WARNING<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="warning" tabindex="0"><code>Warning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.</code></pre>
</div>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">print</span><span class="op">(</span><span class="va">normal_loo</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>
Computed from 4000 by 88 log-likelihood matrix.

         Estimate   SE
elpd_loo   -288.8 41.6
p_loo        18.5 17.6
looic       577.7 83.3
------
MCSE of elpd_loo is NA.
MCSE and ESS estimates assume MCMC draws (r_eff in [0.8, 0.9]).

Pareto k diagnostic values:
                         Count Pct.    Min. ESS
(-Inf, 0.7]   (good)     87    98.9%   2167
   (0.7, 1]   (bad)       0     0.0%   &lt;NA&gt;
   (1, Inf)   (very bad)  1     1.1%   &lt;NA&gt;
See help('pareto-k-diagnostic') for details.</code></pre>
</div>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># PSIS-LOO computation for cauchy model</span></span>
<span><span class="va">cauchy_loo</span> <span class="op">&lt;-</span> <span class="fu">loo</span><span class="fu">::</span><span class="fu">loo</span><span class="op">(</span><span class="va">cauchy_fit</span><span class="op">)</span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="va">cauchy_loo</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>
Computed from 4000 by 88 log-likelihood matrix.

         Estimate   SE
elpd_loo   -206.9 14.7
p_loo         2.0  0.0
looic       413.8 29.3
------
MCSE of elpd_loo is 0.0.
MCSE and ESS estimates assume MCMC draws (r_eff in [0.7, 0.8]).

All Pareto k estimates are good (k &lt; 0.7).
See help('pareto-k-diagnostic') for details.</code></pre>
</div>
<p>Running <code>print</code> returns <span class="math inline">\(\widehat{\text{elpd}}_{\text{loo}}\)</span>
(expected log pointwise predictive density), <span class="math inline">\(\hat{p}_{loo}\)</span> (estimated number of
parameters) and <span class="math inline">\(\text{looic}\)</span> (LOO
information criterion) values and their standard errors. It also returns
a table with the Pareto <span class="math inline">\(k\)</span>
diagnostic values, which are used to asses the reliability of the
estimates. Values below 1 are required for reliable PSIS estimates.</p>
<p>Model comparison can be done by using the
<code>loo::loo_compare</code> function on the <code>loo</code> objects.
The comparison is based on the models’ elpd values.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Comparing models based on loo</span></span>
<span><span class="fu">loo</span><span class="fu">::</span><span class="fu">loo_compare</span><span class="op">(</span><span class="va">normal_loo</span>, <span class="va">cauchy_loo</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>       elpd_diff se_diff
model2   0.0       0.0
model1 -81.9      36.2  </code></pre>
</div>
<p>The comparison shows that the elpd difference is larger than the
standard error, indicating that the cauchy model is expected to have
better predictive performance than the normal model. This is in line
with what we saw in chapter 5: the Cauchy distribution is a superior
model for the data.</p>
<div id="challenge1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p><code>loo</code> can also be used to compute WAIC for Bayesian
models. Calculate WAIC for the two models and then compare them.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<p>First we need to extract the log-likelihood values from the fitted
model object.</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Extracting loglik</span></span>
<span><span class="va">normal_loglik</span> <span class="op">&lt;-</span> <span class="fu">loo</span><span class="fu">::</span><span class="fu">extract_log_lik</span><span class="op">(</span><span class="va">normal_fit</span><span class="op">)</span></span>
<span><span class="va">cauchy_loglik</span> <span class="op">&lt;-</span> <span class="fu">loo</span><span class="fu">::</span><span class="fu">extract_log_lik</span><span class="op">(</span><span class="va">cauchy_fit</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Computing WAIC for the models</span></span>
<span><span class="va">normal_waic</span> <span class="op">&lt;-</span> <span class="fu">loo</span><span class="fu">::</span><span class="fu">waic</span><span class="op">(</span><span class="va">normal_loglik</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">WARNING<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="warning" tabindex="0"><code>Warning:
1 (1.1%) p_waic estimates greater than 0.4. We recommend trying loo instead.</code></pre>
</div>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">print</span><span class="op">(</span><span class="va">normal_waic</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>
Computed from 4000 by 88 log-likelihood matrix.

          Estimate   SE
elpd_waic   -290.0 42.8
p_waic        19.7 18.8
waic         580.1 85.6

1 (1.1%) p_waic estimates greater than 0.4. We recommend trying loo instead. </code></pre>
</div>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cauchy_waic</span> <span class="op">&lt;-</span> <span class="fu">loo</span><span class="fu">::</span><span class="fu">waic</span><span class="op">(</span><span class="va">cauchy_loglik</span><span class="op">)</span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="va">cauchy_waic</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>
Computed from 4000 by 88 log-likelihood matrix.

          Estimate   SE
elpd_waic   -206.9 14.7
p_waic         2.0  0.0
waic         413.8 29.3</code></pre>
</div>
<p>Computing WAIC for the model return values for <span class="math inline">\(\widehat{\text{eldp}}_{\text{WAIC}}\)</span>,
<span class="math inline">\(\hat{p}_{\text{WAIC}}\)</span> and <span class="math inline">\(\widehat{\text{WAIC}}\)</span>. Models can be
compared based on WAIC using the same function as with PSIS-LOO.</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Comparing models based on WAIC</span></span>
<span><span class="fu">loo</span><span class="fu">::</span><span class="fu">loo_compare</span><span class="op">(</span><span class="va">normal_waic</span>, <span class="va">cauchy_waic</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>       elpd_diff se_diff
model2   0.0       0.0
model1 -83.1      37.4  </code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="bayesplot">
<code>bayesplot</code><a class="anchor" aria-label="anchor" href="#bayesplot"></a>
</h2>
<hr class="half-width">
<p>Next, we will look at the the <code>bayesplot</code> R package. The
package provides a library of plotting functions for fitted Stan models.
The created plots are <code>ggplot</code> objects, meaning that the
plots can be customized with the functions from <code>ggplot2</code>
package. The package enables plotting posterior draws, visual MCMC
diagnostics and graphical posterior and prior predictive checking. The
functions of the package also work with model fit with the popular
packages <code>brms</code> and <code>rstanarm</code>.</p>
<div class="section level3">
<h3 id="example-1-continued">Example 1 continued<a class="anchor" aria-label="anchor" href="#example-1-continued"></a>
</h3>
<p>We will demonstrate using <code>bayesplot</code> with the Cauchy
model used in the first example. First, we need to extract the posterior
draws. Then, we will plot uncertainty intervals for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>.</p>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Extracting draws</span></span>
<span><span class="va">cauchy_draws</span> <span class="op">&lt;-</span> <span class="fu">as.array</span><span class="op">(</span><span class="va">cauchy_fit</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plotting uncertainty intervals</span></span>
<span><span class="fu">bayesplot</span><span class="fu">::</span><span class="fu">mcmc_intervals</span><span class="op">(</span><span class="va">cauchy_draws</span>, pars <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="st">"mu"</span>, <span class="st">"sigma"</span><span class="op">)</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/stan-extensions-rendered-unnamed-chunk-10-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>Alternatively, we can plot the (marginal) posterior sample histograms
or densities with credible intervals as shaded areas as follows:</p>
<div class="codewrapper sourceCode" id="cb21">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Plotting estimated density curves</span></span>
<span><span class="fu">bayesplot</span><span class="fu">::</span><span class="fu">mcmc_areas</span><span class="op">(</span><span class="va">cauchy_draws</span>, pars <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="st">"mu"</span>, <span class="st">"sigma"</span><span class="op">)</span>,</span>
<span>                      prob <span class="op">=</span> <span class="fl">0.95</span>,</span>
<span>                      point_est <span class="op">=</span> <span class="st">"mean"</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/stan-extensions-rendered-unnamed-chunk-11-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><div class="codewrapper sourceCode" id="cb22">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Plotting histogram</span></span>
<span><span class="fu">bayesplot</span><span class="fu">::</span><span class="fu">mcmc_hist</span><span class="op">(</span><span class="va">cauchy_draws</span>, pars <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="st">"mu"</span>, <span class="st">"sigma"</span><span class="op">)</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/stan-extensions-rendered-unnamed-chunk-11-2.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p><code>bayesplot</code> also provides functions for assessing MCMC
convergence and visualizing fit diagnostics. For example, we can
generate trace plots for the chains:</p>
<div class="codewrapper sourceCode" id="cb23">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Plotting trace plot</span></span>
<span><span class="fu">bayesplot</span><span class="fu">::</span><span class="fu">mcmc_trace</span><span class="op">(</span><span class="va">cauchy_draws</span>, pars <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="st">"mu"</span>, <span class="st">"sigma"</span><span class="op">)</span>,</span>
<span>                      facet_args <span class="op">=</span> <span class="fu">list</span><span class="op">(</span>ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/stan-extensions-rendered-unnamed-chunk-12-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><div id="challenge2" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>Perform a graphical posterior predictive checks with
<code>bayesplot</code>. Using the Cauchy model fit generated above, plot
the density of <span class="math inline">\(X_{rep}\)</span> samples
overlaid with the density of <span class="math inline">\(X\)</span>.
Alternatively, you can plot the corresponding histograms.</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" data-bs-parent="#accordionSolution2" aria-labelledby="headingSolution2">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb24">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Extracting replicates and getting a subset</span></span>
<span><span class="fu">set.seed</span><span class="op">(</span><span class="fl">2024</span><span class="op">)</span></span>
<span><span class="va">X_rep</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">extract</span><span class="op">(</span><span class="va">cauchy_fit</span>, <span class="st">"X_rep"</span><span class="op">)</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">data.frame</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>    <span class="fu">mutate</span><span class="op">(</span>sample <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fu">nrow</span><span class="op">(</span><span class="va">.</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">N_rep</span> <span class="op">&lt;-</span> <span class="fl">9</span></span>
<span></span>
<span><span class="va">X_rep_sub</span> <span class="op">&lt;-</span> <span class="va">X_rep</span> <span class="op">%&gt;%</span> <span class="fu">filter</span><span class="op">(</span><span class="va">sample</span> <span class="op">%in%</span></span>
<span>                                <span class="fu">sample</span><span class="op">(</span><span class="va">X_rep</span><span class="op">$</span><span class="va">sample</span>,</span>
<span>                                       <span class="va">N_rep</span>,</span>
<span>                                       replace <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">X_rep_sub</span> <span class="op">&lt;-</span> <span class="va">X_rep_sub</span><span class="op">[</span>, <span class="op">-</span><span class="fl">89</span><span class="op">]</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">as.matrix</span><span class="op">(</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb25">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Plot density</span></span>
<span><span class="co"># Limit x range for better illustration</span></span>
<span><span class="fu">bayesplot</span><span class="fu">::</span><span class="fu">ppc_dens_overlay</span><span class="op">(</span>y <span class="op">=</span> <span class="va">df5</span><span class="op">$</span><span class="va">X</span>, yrep <span class="op">=</span> <span class="va">X_rep_sub</span><span class="op">)</span> <span class="op">+</span> <span class="fu">xlim</span><span class="op">(</span><span class="op">-</span><span class="fl">25</span>, <span class="fl">50</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/stan-extensions-rendered-unnamed-chunk-14-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><div class="codewrapper sourceCode" id="cb26">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Plot histograms</span></span>
<span><span class="fu">bayesplot</span><span class="fu">::</span><span class="fu">ppc_hist</span><span class="op">(</span>y <span class="op">=</span> <span class="va">df5</span><span class="op">$</span><span class="va">X</span>, yrep <span class="op">=</span> <span class="va">X_rep_sub</span><span class="op">)</span> <span class="op">+</span> <span class="fu">xlim</span><span class="op">(</span><span class="op">-</span><span class="fl">25</span>,<span class="fl">50</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/stan-extensions-rendered-unnamed-chunk-15-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="brms-r-package">
<code>brms</code> R package<a class="anchor" aria-label="anchor" href="#brms-r-package"></a>
</h2>
<hr class="half-width">
<p>We will now introduce the <code>brms</code> R package. The package
allows fitting probabilistic generalized (non-)linear models with Stan.
A large range of distributions and link functions are supported, in
addition to multilevel structure. Moreover, several built-in functions
are available for priors.</p>
<p>Models are specified using familiar R formula syntax, input into an R
function which compiles and calls the Stan model in the backend.</p>
<p>The package also provides tools for evaluating the fit and MCMC
convergence. These tools, in turn, use functions from the
<code>loo</code> and <code>bayesplot</code> packages, that is, many of
the same tools we covered earlier in this Episode.</p>
<p>Next, we will demonstrate usage of the package with two different
examples.</p>
<div class="section level3">
<h3 id="example-2-survival-modeling">Example 2: Survival modeling<a class="anchor" aria-label="anchor" href="#example-2-survival-modeling"></a>
</h3>
<p>In this example, we will demonstrate fitting a Cox proportional
hazard model with <code>brms</code>. However, first, we will briefly
describe and model and idea in survival modeling.</p>
<p>The Cox model is a standard approach used in survival modeling, in
which the outcome of interest is the time to some event. A common
application is medical studies where patients are followed in time until
an event (e.g. death) or until censoring. A subject is censored if the
event doesn’t occur during the follow-up.</p>
<p>An important ingredient in survival modeling is the hazard function,
representing the instantaneous risk for an event at time <span class="math inline">\(t\)</span>, defined as <span class="math inline">\(\lambda(t)=\text{lim}_{h \to 0+} \frac{1}{h}P(t
\le T&lt;t+h|T\ge t)\)</span>. In the Cox model, the hazard function is
of the form <span class="math inline">\(\lambda(t_i,Z_i,\theta)=\lambda_0(t_i)\text{exp}(\beta^\prime
Z_i)\)</span>.</p>
<p>The baseline hazard function <span class="math inline">\(\lambda_0(t_i)\)</span> represents the hazard when
the covariates are set to their baselines, and is the same for each
subject <span class="math inline">\(i\)</span>. Commonly, the functional
form the baseline hazard is not specified. The second part of the hazard
function contains subject-specific covariates, <span class="math inline">\(\text{exp}(\beta^\prime Z_i)\)</span>.</p>
<p>The exponentials of the effects <span class="math inline">\(\beta\)</span> are called hazard ratios, which
measure the hazard in one group against the hazard in another group.</p>
<p>When fitting the Cox model, <code>brms</code> uses M-splines for the
baseline hazard. Splines are functions built from piecewise-defined
polynomials. In other words, the baseline hazard is a combination of
several different polynomial functions. M-splines are non-negative
spline functions, which is important for reasons we omit. However,
hopefully, the reader can appreciate the simplicity of the upcoming
<code>brms</code> function call.</p>
<p>Before fitting the model, we will take a look at the
<code>lung</code> dataset from the <code>survival</code> R package,
which we will be analyzing below. The dataset consists of survival times
of patients with advanced lung cancer including some clinical
covariates.</p>
<div class="codewrapper sourceCode" id="cb27">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Get data</span></span>
<span><span class="va">lung</span> <span class="op">&lt;-</span> <span class="fu">survival</span><span class="fu">::</span><span class="va">lung</span></span>
<span></span>
<span><span class="co"># Take a peek</span></span>
<span><span class="fu">head</span><span class="op">(</span><span class="va">lung</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>  inst time status age sex ph.ecog ph.karno pat.karno meal.cal wt.loss
1    3  306      2  74   1       1       90       100     1175      NA
2    3  455      2  68   1       0       90        90     1225      15
3    3 1010      1  56   1       0       90        90       NA      15
4    5  210      2  57   1       1       90        60     1150      11
5    1  883      2  60   1       0      100        90       NA       0
6   12 1022      1  74   1       1       50        80      513       0</code></pre>
</div>
<p>The variable <code>status</code> denotes if an event (death) was
observed or if the subject was censored. We will use three covariates:
<code>age</code>, <code>sex</code> and <code>ph.karno</code>. The
variable <code>ph.karno</code> describes how well a patient can perform
daily activities rated by a physician. We will split the variable into
two categories “high” and “low.”</p>
<p>Cox model can be fit with <code>brms::brm()</code> function by
specifying <code>family = brmsfamily("cox")</code>. Censored data points
are indicated with the <code>cens(1 - status)</code> argument. We will
use a standard <span class="math inline">\(\text{Normal}(0, 10)\)</span>
prior for the population-level effects, with the argument
<code>prior(normal(0,10), class = b)</code>. The option
<code>class = b</code> sets the prior for all population-level
effects.</p>
<div class="codewrapper sourceCode" id="cb29">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Let's change status coding from 2/1 to 1/0</span></span>
<span><span class="va">lung</span><span class="op">$</span><span class="va">status</span> <span class="op">&lt;-</span> <span class="va">lung</span><span class="op">$</span><span class="va">status</span> <span class="op">-</span> <span class="fl">1</span></span>
<span></span>
<span><span class="co"># Remove observations with NA ph.karno</span></span>
<span><span class="va">lung</span> <span class="op">&lt;-</span> <span class="va">lung</span><span class="op">[</span><span class="op">!</span><span class="fu">is.na</span><span class="op">(</span><span class="va">lung</span><span class="op">$</span><span class="va">ph.karno</span><span class="op">)</span>,<span class="op">]</span></span>
<span></span>
<span><span class="co"># Creating new variable for ph.karno status</span></span>
<span><span class="va">lung</span><span class="op">$</span><span class="va">ph.karno_status</span> <span class="op">&lt;-</span> <span class="fu">cut</span><span class="op">(</span><span class="va">lung</span><span class="op">$</span><span class="va">ph.karno</span>,</span>
<span>                            breaks <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">70</span>, <span class="fl">100</span><span class="op">)</span>,</span>
<span>                            labels <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="st">"low"</span>, <span class="st">"high"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Fitting the model</span></span>
<span><span class="va">fit_cox</span> <span class="op">&lt;-</span> <span class="fu">brms</span><span class="fu">::</span><span class="fu">brm</span><span class="op">(</span><span class="va">time</span> <span class="op">|</span> <span class="fu">cens</span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">status</span><span class="op">)</span> <span class="op">~</span> <span class="va">sex</span> <span class="op">+</span> <span class="va">age</span> <span class="op">+</span> <span class="va">ph.karno_status</span>,</span>
<span>             data <span class="op">=</span> <span class="va">lung</span>, family <span class="op">=</span> <span class="fu">brmsfamily</span><span class="op">(</span><span class="st">"cox"</span><span class="op">)</span>, seed <span class="op">=</span> <span class="fl">2024</span>,</span>
<span>             silent <span class="op">=</span> <span class="fl">2</span>, refresh <span class="op">=</span> <span class="fl">0</span>, cores <span class="op">=</span> <span class="fl">4</span>,</span>
<span>             prior <span class="op">=</span> <span class="fu">prior</span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>,<span class="fl">10</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">b</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># Summary of the fit</span></span>
<span><span class="fu">summary</span><span class="op">(</span><span class="va">fit_cox</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code> Family: cox
  Links: mu = log
Formula: time | cens(1 - status) ~ sex + age + ph.karno_status
   Data: lung (Number of observations: 227)
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Regression Coefficients:
                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept               1.27      0.68    -0.11     2.57 1.00     4304     2666
sex                    -0.50      0.16    -0.83    -0.19 1.00     4768     2842
age                     0.01      0.01    -0.01     0.03 1.00     4607     2784
ph.karno_statushigh    -0.36      0.18    -0.70    -0.02 1.00     4471     2616

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
<p>The summary output of the <code>brms</code> fit prints coefficient
estimates, and also returns Rhat, Bulk_ESS and Tail_ESS values, which
can be used to assess the convergence of the model.</p>
<p>It is important to notice that the coefficients are the log hazard
ratios, which means we still need to exponentiate them. The
<code>bayesplot::mcmc_intervals()</code> function allows transforming
the parameters before plotting with <code>transform = "exp"</code>
argument.</p>
<div class="codewrapper sourceCode" id="cb31">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Get hazard values</span></span>
<span><span class="va">sum_cox</span> <span class="op">&lt;-</span> <span class="fu">summary</span><span class="op">(</span><span class="va">fit_cox</span><span class="op">)</span></span>
<span><span class="fu">exp</span><span class="op">(</span><span class="va">sum_cox</span><span class="op">$</span><span class="va">fixed</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>                     Estimate Est.Error  l-95% CI   u-95% CI
Intercept           3.5576154  1.970680 0.8962140 13.1193479
sex                 0.6044998  1.179035 0.4369700  0.8279120
age                 1.0130229  1.009435 0.9945742  1.0318059
ph.karno_statushigh 0.6956990  1.193047 0.4959062  0.9847118</code></pre>
</div>
<div class="codewrapper sourceCode" id="cb33">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Credible intervals</span></span>
<span><span class="fu">bayesplot</span><span class="fu">::</span><span class="fu">mcmc_intervals</span><span class="op">(</span><span class="va">fit_cox</span>,</span>
<span>                          pars <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="st">"b_sex"</span>, <span class="st">"b_age"</span>, <span class="st">"b_ph.karno_statushigh"</span><span class="op">)</span>,</span>
<span>                          transform <span class="op">=</span> <span class="st">"exp"</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/stan-extensions-rendered-unnamed-chunk-18-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>Based on the estimates, it seems that age has only a minor effect on
the hazard. Female sex and being “high” in <code>ph.karno</code> imply
smaller hazards, meaning that these factors are protective.</p>
<p>After fitting the model, we can print information about the priors
used with the function <code>brms::get_prior</code>.</p>
<div class="codewrapper sourceCode" id="cb34">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Get priors for the cox model</span></span>
<span><span class="fu">brms</span><span class="fu">::</span><span class="fu">get_prior</span><span class="op">(</span><span class="va">fit_cox</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>                  prior     class                coef group resp dpar nlpar lb
          normal(0, 10)         b
          normal(0, 10)         b                 age
          normal(0, 10)         b ph.karno_statushigh
          normal(0, 10)         b                 sex
 student_t(3, 5.6, 2.5) Intercept
           dirichlet(1)     sbhaz
 ub       source
            user
    (vectorized)
    (vectorized)
    (vectorized)
         default
         default</code></pre>
</div>
<p>The population-level effects have the normal prior we specified. In
<code>brms</code>, the default prior for the intercept is Student’s
t-distribution with three degrees of freedom. The Stan program
<code>brms</code> ran under the hood can be printed with the
<code>brms::stancode</code> function.</p>
<div class="codewrapper sourceCode" id="cb36">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Print the Stan code</span></span>
<span><span class="fu">brms</span><span class="fu">::</span><span class="fu">stancode</span><span class="op">(</span><span class="va">fit_cox</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>// generated with brms 2.22.0
functions {
  /* distribution functions of the Cox proportional hazards model
   * parameterize hazard(t) = baseline(t) * mu
   * so that higher values of 'mu' imply lower survival times
   * Args:
   *   y: the response value; currently ignored as the relevant
   *     information is passed via 'bhaz' and 'cbhaz'
   *   mu: positive location parameter
   *   bhaz: baseline hazard
   *   cbhaz: cumulative baseline hazard
   */
  real cox_lhaz(real y, real mu, real bhaz, real cbhaz) {
    return log(bhaz) + log(mu);
  }
  vector cox_lhaz(vector y, vector mu, vector bhaz, vector cbhaz) {
    return log(bhaz) + log(mu);
  }

  // equivalent to the log survival function
  real cox_lccdf(real y, real mu, real bhaz, real cbhaz) {
    return - cbhaz * mu;
  }
  real cox_lccdf(vector y, vector mu, vector bhaz, vector cbhaz) {
    return - dot_product(cbhaz, mu);
  }

  real cox_lcdf(real y, real mu, real bhaz, real cbhaz) {
    return log1m_exp(cox_lccdf(y | mu, bhaz, cbhaz));
  }
  real cox_lcdf(vector y, vector mu, vector bhaz, vector cbhaz) {
    return sum(log1m_exp(- cbhaz .* mu));
  }

  real cox_lpdf(real y, real mu, real bhaz, real cbhaz) {
    return cox_lhaz(y, mu, bhaz, cbhaz) + cox_lccdf(y | mu, bhaz, cbhaz);
  }
  real cox_lpdf(vector y, vector mu, vector bhaz, vector cbhaz) {
    return sum(cox_lhaz(y, mu, bhaz, cbhaz)) + cox_lccdf(y | mu, bhaz, cbhaz);
  }

  // Distribution functions of the Cox model in log parameterization
  real cox_log_lhaz(real y, real log_mu, real bhaz, real cbhaz) {
    return log(bhaz) + log_mu;
  }
  vector cox_log_lhaz(vector y, vector log_mu, vector bhaz, vector cbhaz) {
    return log(bhaz) + log_mu;
  }

  real cox_log_lccdf(real y, real log_mu, real bhaz, real cbhaz) {
    return - cbhaz * exp(log_mu);
  }
  real cox_log_lccdf(vector y, vector log_mu, vector bhaz, vector cbhaz) {
    return - dot_product(cbhaz, exp(log_mu));
  }

  real cox_log_lcdf(real y, real log_mu, real bhaz, real cbhaz) {
    return log1m_exp(cox_log_lccdf(y | log_mu, bhaz, cbhaz));
  }
  real cox_log_lcdf(vector y, vector log_mu, vector bhaz, vector cbhaz) {
    return sum(log1m_exp(- cbhaz .* exp(log_mu)));
  }

  real cox_log_lpdf(real y, real log_mu, real bhaz, real cbhaz) {
    return cox_log_lhaz(y, log_mu, bhaz, cbhaz) +
           cox_log_lccdf(y | log_mu, bhaz, cbhaz);
  }
  real cox_log_lpdf(vector y, vector log_mu, vector bhaz, vector cbhaz) {
    return sum(cox_log_lhaz(y, log_mu, bhaz, cbhaz)) +
           cox_log_lccdf(y | log_mu, bhaz, cbhaz);
  }
}
data {
  int&lt;lower=1&gt; N;  // total number of observations
  vector[N] Y;  // response variable
  // censoring indicator: 0 = event, 1 = right, -1 = left, 2 = interval censored
  array[N] int&lt;lower=-1,upper=2&gt; cens;
  int&lt;lower=1&gt; K;  // number of population-level effects
  matrix[N, K] X;  // population-level design matrix
  int&lt;lower=1&gt; Kc;  // number of population-level effects after centering
  // data for flexible baseline functions
  int Kbhaz;  // number of basis functions
  // design matrix of the baseline function
  matrix[N, Kbhaz] Zbhaz;
  // design matrix of the cumulative baseline function
  matrix[N, Kbhaz] Zcbhaz;
  // a-priori concentration vector of baseline coefficients
  vector&lt;lower=0&gt;[Kbhaz] con_sbhaz;
  int prior_only;  // should the likelihood be ignored?
}
transformed data {
  // indices of censored data
  int Nevent = 0;
  int Nrcens = 0;
  int Nlcens = 0;
  array[N] int Jevent;
  array[N] int Jrcens;
  array[N] int Jlcens;
  matrix[N, Kc] Xc;  // centered version of X without an intercept
  vector[Kc] means_X;  // column means of X before centering
  // collect indices of censored data
  for (n in 1:N) {
    if (cens[n] == 0) {
      Nevent += 1;
      Jevent[Nevent] = n;
    } else if (cens[n] == 1) {
      Nrcens += 1;
      Jrcens[Nrcens] = n;
    } else if (cens[n] == -1) {
      Nlcens += 1;
      Jlcens[Nlcens] = n;
    }
  }
  for (i in 2:K) {
    means_X[i - 1] = mean(X[, i]);
    Xc[, i - 1] = X[, i] - means_X[i - 1];
  }
}
parameters {
  vector[Kc] b;  // regression coefficients
  real Intercept;  // temporary intercept for centered predictors
  // baseline hazard coefficients
  simplex[Kbhaz] sbhaz;
}
transformed parameters {
  real lprior = 0;  // prior contributions to the log posterior
  lprior += normal_lpdf(b | 0, 10);
  lprior += student_t_lpdf(Intercept | 3, 5.6, 2.5);
  lprior += dirichlet_lpdf(sbhaz | con_sbhaz);
}
model {
  // likelihood including constants
  if (!prior_only) {
    // compute values of baseline function
    vector[N] bhaz = Zbhaz * sbhaz;
    // compute values of cumulative baseline function
    vector[N] cbhaz = Zcbhaz * sbhaz;
    // initialize linear predictor term
    vector[N] mu = rep_vector(0.0, N);
    mu += Intercept + Xc * b;
    // vectorized log-likelihood contributions of censored data
    target += cox_log_lpdf(Y[Jevent[1:Nevent]] | mu[Jevent[1:Nevent]], bhaz[Jevent[1:Nevent]], cbhaz[Jevent[1:Nevent]]);
    target += cox_log_lccdf(Y[Jrcens[1:Nrcens]] | mu[Jrcens[1:Nrcens]], bhaz[Jrcens[1:Nrcens]], cbhaz[Jrcens[1:Nrcens]]);
    target += cox_log_lcdf(Y[Jlcens[1:Nlcens]] | mu[Jlcens[1:Nlcens]], bhaz[Jlcens[1:Nlcens]], cbhaz[Jlcens[1:Nlcens]]);
  }
  // priors including constants
  target += lprior;
}
generated quantities {
  // actual population-level intercept
  real b_Intercept = Intercept - dot_product(means_X, b);
}</code></pre>
</div>
</div>
<div class="section level3">
<h3 id="example-3-hierarchical-binomial-model">Example 3: Hierarchical binomial model<a class="anchor" aria-label="anchor" href="#example-3-hierarchical-binomial-model"></a>
</h3>
<p>We will now demonstrate one of the key focuses of <code>brms</code>,
fitting hierarchical models. The syntax for specifying hierarchical
models is similar as in the <code>lme4</code> package, which is used to
fit frequentist multilevel models in R.</p>
<p>For this example, we will be using is the <code>VerbAgg</code> data
from <code>lme4</code> package. The data consist of item responses to a
questionnaire on verbal aggression.</p>
<div class="codewrapper sourceCode" id="cb38">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Get data</span></span>
<span><span class="va">VerbAgg</span> <span class="op">&lt;-</span> <span class="fu">lme4</span><span class="fu">::</span><span class="va">VerbAgg</span></span>
<span></span>
<span><span class="fu">head</span><span class="op">(</span><span class="va">VerbAgg</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>  Anger Gender        item    resp id btype  situ mode r2
1    20      M S1WantCurse      no  1 curse other want  N
2    11      M S1WantCurse      no  2 curse other want  N
3    17      F S1WantCurse perhaps  3 curse other want  Y
4    21      F S1WantCurse perhaps  4 curse other want  Y
5    17      F S1WantCurse perhaps  5 curse other want  Y
6    21      F S1WantCurse     yes  6 curse other want  Y</code></pre>
</div>
<p>We will estimate population-level effects for Anger, Gender, btype
and situ, and includea group-level intercept for id. The variable of
interest is the binary r2, which contains the response to an question in
the questionnaire. We will use <span class="math inline">\(\text{Normal}(0, 10)\)</span> as the prior for all
the population-level effects. For the standard deviation of group-level
effect we will set a (half-)<span class="math inline">\(\text{Cauchy}(0,
5)\)</span> prior. By default, <code>brms</code> uses half-Student’s
t-distribution with three degrees of freedom for standard deviation
parameters. The group-level intercept for variable id is specified with
the argument <code>(1|id)</code>. Let’s now fit the model.</p>
<div class="codewrapper sourceCode" id="cb40">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Change coding for r2</span></span>
<span><span class="va">VerbAgg</span> <span class="op">&lt;-</span> <span class="va">VerbAgg</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>r2 <span class="op">=</span> <span class="fu">ifelse</span><span class="op">(</span><span class="va">r2</span> <span class="op">==</span> <span class="st">"N"</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># Fit model</span></span>
<span><span class="va">fit_hier</span> <span class="op">&lt;-</span> <span class="fu">brms</span><span class="fu">::</span><span class="fu">brm</span><span class="op">(</span><span class="va">r2</span> <span class="op">~</span> <span class="va">Anger</span> <span class="op">+</span> <span class="va">Gender</span> <span class="op">+</span> <span class="va">btype</span> <span class="op">+</span> <span class="va">situ</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span><span class="op">|</span><span class="va">id</span><span class="op">)</span>,</span>
<span>                      family <span class="op">=</span> <span class="va">bernoulli</span>, </span>
<span>                      data <span class="op">=</span> <span class="va">VerbAgg</span>,</span>
<span>                      seed <span class="op">=</span> <span class="fl">2024</span>, cores <span class="op">=</span> <span class="fl">4</span>, silent <span class="op">=</span> <span class="fl">2</span>, refresh <span class="op">=</span> <span class="fl">0</span>,</span>
<span>                      prior <span class="op">=</span> <span class="fu">prior</span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">b</span><span class="op">)</span> <span class="op">+</span> </span>
<span>                        <span class="fu">prior</span><span class="op">(</span><span class="fu">cauchy</span><span class="op">(</span><span class="fl">0</span>,<span class="fl">5</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">sd</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># Summary</span></span>
<span><span class="fu">summary</span><span class="op">(</span><span class="va">fit_hier</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code> Family: bernoulli
  Links: mu = logit
Formula: r2 ~ Anger + Gender + btype + situ + (1 | id)
   Data: VerbAgg (Number of observations: 7584)
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Multilevel Hyperparameters:
~id (Number of levels: 316)
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)     1.30      0.07     1.17     1.43 1.00     1086     1687

Regression Coefficients:
           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept      0.21      0.34    -0.49     0.87 1.01      637     1035
Anger          0.05      0.02     0.02     0.09 1.01      664     1026
GenderM        0.31      0.19    -0.05     0.68 1.00      580     1257
btypescold    -1.03      0.07    -1.17    -0.90 1.00     4963     3254
btypeshout    -2.00      0.07    -2.14    -1.85 1.00     4867     3286
situself      -1.01      0.06    -1.12    -0.89 1.00     5877     3022

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
<p>The conditional effects of the predictors can easily be plotted with
the function <code>brms::conditional_effects</code>.</p>
<div class="codewrapper sourceCode" id="cb42">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Conditional effects</span></span>
<span><span class="va">plots</span> <span class="op">&lt;-</span> <span class="fu">plot</span><span class="op">(</span><span class="fu">conditional_effects</span><span class="op">(</span><span class="va">fit_hier</span><span class="op">)</span>, plot <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="fu">cowplot</span><span class="fu">::</span><span class="fu">plot_grid</span><span class="op">(</span><span class="va">plots</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>, <span class="va">plots</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span>, <span class="va">plots</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span>, <span class="va">plots</span><span class="op">[[</span><span class="fl">4</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/stan-extensions-rendered-unnamed-chunk-23-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>The function can also plot variable interactions. Let’s plot the
conditional effect for interaction between Anger and btype.</p>
<div class="codewrapper sourceCode" id="cb43">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Plot conditional effect for interaction of Anger and btype</span></span>
<span><span class="fu">plot</span><span class="op">(</span><span class="fu">conditional_effects</span><span class="op">(</span><span class="va">fit_hier</span>, effects <span class="op">=</span> <span class="st">"Anger:btype"</span><span class="op">)</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/stan-extensions-rendered-unnamed-chunk-24-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>Let us now do a slight alteration in model and add another
group-level intercept for the item variable. The priors are same as in
the first model. The <code>update</code> function can be used to modify
the formula without writing it anew in its entirety.</p>
<div class="codewrapper sourceCode" id="cb44">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Update model</span></span>
<span><span class="va">fit_hier2</span> <span class="op">&lt;-</span> <span class="fu">update</span><span class="op">(</span><span class="va">fit_hier</span>, formula. <span class="op">=</span> <span class="op">~</span> <span class="va">.</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span><span class="op">|</span><span class="va">item</span><span class="op">)</span>, newdata <span class="op">=</span> <span class="va">VerbAgg</span>, seed <span class="op">=</span> <span class="fl">2024</span>,</span>
<span>                    cores <span class="op">=</span> <span class="fl">4</span>, silent <span class="op">=</span> <span class="fl">2</span>, refresh <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span><span class="co"># Summary</span></span>
<span><span class="fu">summary</span><span class="op">(</span><span class="va">fit_hier2</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code> Family: bernoulli
  Links: mu = logit
Formula: r2 ~ Anger + Gender + btype + situ + (1 | id) + (1 | item)
   Data: VerbAgg (Number of observations: 7584)
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Multilevel Hyperparameters:
~id (Number of levels: 316)
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)     1.36      0.07     1.23     1.51 1.00     1347     1922

~item (Number of levels: 24)
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)     0.59      0.11     0.42     0.84 1.00     1404     2252

Regression Coefficients:
           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept      0.18      0.44    -0.65     1.05 1.01      831     1522
Anger          0.06      0.02     0.02     0.09 1.00      801     1568
GenderM        0.32      0.20    -0.07     0.72 1.00      847     1333
btypescold    -1.06      0.30    -1.63    -0.43 1.00     1191     1561
btypeshout    -2.11      0.30    -2.71    -1.52 1.00     1284     1889
situself      -1.05      0.25    -1.54    -0.55 1.00     1156     1828

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
<p>Another useful aspect of <code>update</code> is that it allows
resampling from the model without having to recompile the model, for
example, using different number of iterations. However, changes to the
model itself require recompilation.</p>
<p>To end this section, let’s compare the two models by using
<code>brms::loo()</code>. This works in the same way as the
<code>loo::loo_compare</code>.</p>
<div class="codewrapper sourceCode" id="cb46">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Compare models</span></span>
<span><span class="fu">brms</span><span class="fu">::</span><span class="fu">loo</span><span class="op">(</span><span class="va">fit_hier</span>, <span class="va">fit_hier2</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Output of model 'fit_hier':

Computed from 4000 by 7584 log-likelihood matrix.

         Estimate   SE
elpd_loo  -4004.9 42.9
p_loo       268.0  3.7
looic      8009.7 85.8
------
MCSE of elpd_loo is 0.2.
MCSE and ESS estimates assume MCMC draws (r_eff in [1.1, 2.2]).

All Pareto k estimates are good (k &lt; 0.7).
See help('pareto-k-diagnostic') for details.

Output of model 'fit_hier2':

Computed from 4000 by 7584 log-likelihood matrix.

         Estimate   SE
elpd_loo  -3866.9 43.9
p_loo       287.0  4.1
looic      7733.8 87.8
------
MCSE of elpd_loo is 0.2.
MCSE and ESS estimates assume MCMC draws (r_eff in [1.1, 2.6]).

All Pareto k estimates are good (k &lt; 0.7).
See help('pareto-k-diagnostic') for details.

Model comparisons:
          elpd_diff se_diff
fit_hier2    0.0       0.0
fit_hier  -138.0      16.2 </code></pre>
</div>
<p>Based on the output, the second model provides a superior fit
compared to the first model.</p>
<div id="discussion1" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<span class="callout-header">Discussion</span>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>Experiment with different priors for the model. How much does the
chosen prior affect the results? Is there a big difference between a
flat and the weakly informative prior used above?</p>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="other-packages-built-on-stan">Other packages built on Stan<a class="anchor" aria-label="anchor" href="#other-packages-built-on-stan"></a>
</h2>
<hr class="half-width">
<p>In addition to the ones covered here, there are several other
packages that take advantage of Stan. Here we will briefly introduce
some of them. <a href="https://mc-stan.org/cmdstanr/index.html" class="external-link">CmdStanR</a> is a
lightweight command-line-based interface for Stan and provides and
alternative for rstan. <a href="https://mc-stan.org/rstanarm/" class="external-link">rstanarm</a> emulates the model
fitting R functions using Stan. The package can do lot of the same
things as <code>brms</code>, but they do have differences, for example
<code>rstanarm</code> models come pre-compiled while <code>brms</code>
compiles the models when called.</p>
<p><a href="https://mc-stan.org/shinystan/" class="external-link">shinystan</a> uses Shiny and
provides user with interactive, customizable visual and numerical
summaries of model parameters and convergence diagnostics. <a href="https://mc-stan.org/projpred/" class="external-link">projpred</a> performs projection
predictive variable selection for various models. The package works with
models from <code>brms</code> and <code>rstanarm</code>. <a href="https://mc-stan.org/posterior/" class="external-link">posterior</a> provides tools for
manipulating posterior draws, and contains methods for common
operations, such as, subsetting and binding, and producing posterior
summaries, and diagnostics.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>There are several R packages that provide more user-friendly ways of
using Stan.</li>
<li>
<code>brms</code> package can be used to fit a vast array of
different Bayesian models.</li>
<li>
<code>bayesplot</code> package is a library for various plotting
tools.</li>
<li>Approximate leave-one-out cross-validation can be performed with the
<code>loo</code> package.</li>
</ul>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="reading">Reading<a class="anchor" aria-label="anchor" href="#reading"></a>
</h2>
<hr class="half-width">
<ul>
<li><p><a href="https://paul-buerkner.github.io/brms/index.html" class="external-link">brms
website</a></p></li>
<li><p><a href="http://mc-stan.org/bayesplot/" class="external-link">bayesplot
website</a></p></li>
<li><p><a href="https://mc-stan.org/loo/" class="external-link">loo website</a></p></li>
</ul></section><section><h2 class="section-heading" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<hr class="half-width">
<ul>
<li>[1] A. Vehtari <em>et al.</em>, Pareto Smoothed Importance Sampling,
<em>Journal of Machine Learning Research</em> 25 (2024) 1-58.</li>
</ul>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 --></section></section><section id="aio-exercises"><p>Content from <a href="exercises.html">Exercises</a></p>
<hr>
<p>Last updated on 2025-08-22 |

        <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/edit/main/episodes/exercises.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 12 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can I get routine in probabilistic programming?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<p>The purpose of this Episode is to provide material for practicing
probabilistic programming. The exercises are listed under the Episode
they approximately refer to.</p>
</div>
</div>
</div>
</div>
</div>
<div class="section level1">
<h1 id="basics">1. Basics<a class="anchor" aria-label="anchor" href="#basics"></a>
</h1>
<div class="section level2">
<h2 id="grid-approximation-normal-model-with-unknown-mean">1.1 Grid approximation: normal model with unknown mean<a class="anchor" aria-label="anchor" href="#grid-approximation-normal-model-with-unknown-mean"></a>
</h2>
<p>Generate 1000 data points from the normal model. Use a randomly
generated mean parameter, <span class="math inline">\(\mu \sim
N(0,1)\)</span> and set the standard deviation <span class="math inline">\(\sigma=1\)</span>.</p>
<p>The grid approximation for this model was introduced in Episode XX
but the implementation doesn’t work for the generated data. Locate the
source of error and make the necessary modifications to get the program
working.</p>
<p>Plot the posterior of <span class="math inline">\(\mu\)</span>.</p>
</div>
<div class="section level2">
<h2 id="grid-approximation-gamma-poisson">1.2 Grid approximation: Gamma-Poisson<a class="anchor" aria-label="anchor" href="#grid-approximation-gamma-poisson"></a>
</h2>
<p>The Gamma-Poisson model can be stated as:</p>
<p><span class="math display">\[y_i \sim \text{Pois}(\lambda) \\
\lambda \sim \Gamma(1, 1), \]</span></p>
<p>where <span class="math inline">\(y_i\)</span> are non-negative data
points, and Pois is the Poisson distribution with rate parameter <span class="math inline">\(\lambda &gt; 0\)</span>. Implement a grid
approximation for this model.</p>
<p>Apparently (<a href="https://en.wikipedia.org/wiki/Poisson_distribution" class="external-link uri">https://en.wikipedia.org/wiki/Poisson_distribution</a>), the
number of chewing gum on a sidewalk tile is approximately Poisson
distributed.</p>
<p>Estimate the average number of gum on a Reykjavik side walk tile
(lambda), using the data</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu">c</span><span class="op">(</span><span class="fl">2</span>,<span class="fl">7</span>,<span class="fl">4</span>,<span class="fl">3</span>,<span class="fl">5</span>,<span class="fl">2</span>,<span class="fl">7</span>,<span class="fl">5</span>,<span class="fl">5</span>,<span class="fl">5</span><span class="op">)</span></span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="less-data-means-bigger-prior-effect">1.3 Less data means bigger prior effect<a class="anchor" aria-label="anchor" href="#less-data-means-bigger-prior-effect"></a>
</h2>
<p>Show that as the amount of available data increases, the effect of
the prior decreases.</p>
<p>Instructions:</p>
<ul>
<li>Simulate a series of coin tosses:
<ul>
<li>Generate <span class="math inline">\(p \sim \text{Uniform}(0,
1)\)</span>.</li>
<li>Simulate a sequence of 50 tosses with Pr(heads) = p. </li>
</ul>
</li>
<li>Fit the grid approximation using the first 1, 5, 10, 15,…, 50
tosses.
<ul>
<li>Use a Beta prior for p.</li>
</ul>
</li>
<li>Compare the posteriors the prior.</li>
</ul>
</div>
<div class="section level2">
<h2 id="grid-approximation-for-a-normal-model-with-unknown-mean-and-standard-deviation">1.4 Grid approximation: for a normal model with unknown mean and
standard deviation<a class="anchor" aria-label="anchor" href="#grid-approximation-for-a-normal-model-with-unknown-mean-and-standard-deviation"></a>
</h2>
<p>The following data is a collection of daily milk yield (in liters)
for dairy cows.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu">c</span><span class="op">(</span><span class="fl">30.25</span>, <span class="fl">34.98</span>, <span class="fl">29.66</span>, <span class="fl">20.14</span>, <span class="fl">23.92</span>, <span class="fl">38.61</span>, <span class="fl">36.89</span>, <span class="fl">34.68</span>, <span class="fl">25.83</span>, <span class="fl">29.93</span><span class="op">)</span></span></code></pre>
</div>
<p>Using the grid approximation for the normal model, estimate the
average daily yield <span class="math inline">\(\mu\)</span>.</p>
<p>Use some non-uniform priors.</p>
<p>Plot the marginal posterior for <span class="math inline">\(\mu\)</span> and compute the 90% credible interval
for the marginal.</p>
<p>What is the probability that the average daily milk yield is more
than 30 liters?</p>
</div>
<div class="section level2">
<h2 id="sampling-the-gamma">1.5 Sampling the Gamma<a class="anchor" aria-label="anchor" href="#sampling-the-gamma"></a>
</h2>
<p>Let’s model the following observations X with the exponential
likelihood, <span class="math inline">\(\text{Exp}(\lambda)\)</span>:</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">X</span> <span class="op">&lt;-</span>  <span class="fu">c</span><span class="op">(</span><span class="fl">0.166</span>, <span class="fl">1.08</span>, <span class="fl">1.875</span>, <span class="fl">0.413</span>, <span class="fl">1.369</span>, <span class="fl">0.463</span>, <span class="fl">0.735</span>, </span>
<span>       <span class="fl">0.24</span>, <span class="fl">0.774</span>, <span class="fl">1.09</span>, <span class="fl">0.463</span>, <span class="fl">0.916</span>, <span class="fl">0.225</span>,</span>
<span>        <span class="fl">0.889</span>, <span class="fl">0.051</span>, <span class="fl">0.688</span>, <span class="fl">0.119</span>, <span class="fl">0.078</span>, <span class="fl">1.624</span>, <span class="fl">0.553</span>, <span class="fl">0.523</span>, </span>
<span>       <span class="fl">0.644</span>, <span class="fl">0.284</span>, <span class="fl">1.744</span>, <span class="fl">1.468</span><span class="op">)</span></span></code></pre>
</div>
<p>If we use a <span class="math inline">\(\Gamma(2, 1)\)</span> prior,
the posterior distribution can be shown to be</p>
<p><span class="math inline">\(p(\lambda | X) = \Gamma(2 + n, 1 + X_1 +
X_2 + ... + X_n),\)</span></p>
<p>where <span class="math inline">\(n\)</span> is the number of
observations.</p>
<p>Generate 5000 samples from the posterior and compute 1. the posterior
mean and mode 2. the 50% and 95% credible intervals 3. the probabilities
<span class="math inline">\(Pr(\lambda &gt; 1), Pr( 1 &lt; \lambda &lt;
1.5), Pr(\lambda &lt; 1 \text{  or } \lambda &gt; 1.5)\)</span></p>
</div>
<div class="section level2">
<h2 id="grid-approximation-cauchy-distribution">1.6 Grid approximation: Cauchy distribution<a class="anchor" aria-label="anchor" href="#grid-approximation-cauchy-distribution"></a>
</h2>
<p>(Emulated from BDA3: p59. Ex.11)</p>
<p>Suppose y1,…,y5 are independent samples from a Cauchy distribution
with scale 1 and unknown location <span class="math inline">\(\theta\)</span>. Given the observations <span class="math inline">\((y_1, . . . , y_5) = (43, 44, 45, 46.5,
47.5)\)</span>:</p>
<ol style="list-style-type: lower-alpha">
<li>Compute the unnormalized posterior density function, <span class="math inline">\(p(\theta)p(y|\theta)\)</span>, on a grid of points
<span class="math inline">\(\theta = 0, 1/m , 2/m ,..., 100\)</span>,
for some large integer <span class="math inline">\(m\)</span>. Using the
grid approximation, compute and plot the normalized posterior density
function as a function of <span class="math inline">\(\theta\)</span>.
Assume a uniform prior for over [0, 100].</li>
<li>Generate 1000 samples of <span class="math inline">\(\theta\)</span>
from the posterior and plot a histogram of the samples.</li>
<li>Use each of the samples generated in b) to generate a new data point
<span class="math inline">\(y_6\)</span> from the likelihood function
and plot a histogram of these draws.</li>
</ol>
</div>
<div class="section level2">
<h2 id="sampling-the-normal">1.7 Sampling the Normal<a class="anchor" aria-label="anchor" href="#sampling-the-normal"></a>
</h2>
<p>The posterior for the normal model with unknown <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> can be sampled as follows
(BDA3:p.65):</p>
<ol style="list-style-type: decimal">
<li>Sample the variance from <span class="math inline">\(\sigma^2 \sim
Inv-\chi^2(n-1, \text{Var}(X))\)</span>
</li>
<li>Sample the mean from <span class="math inline">\(\mu | \sigma^2 ~
N(\bar{X}, \frac{\sigma^2}{n})\)</span>
</li>
</ol>
<p>Here <span class="math inline">\(\bar{X}\)</span> is the mean of the
data points <span class="math inline">\(X = \{X_1, X_2, ...,
X_n\}\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li>Generate 5000 samples from the posterior using the data</li>
</ol>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu">c</span><span class="op">(</span><span class="fl">21.1</span>, <span class="fl">20.8</span>, <span class="fl">21.9</span>, <span class="fl">20.5</span>, <span class="fl">18.7</span>, <span class="fl">24.1</span>, <span class="fl">18.6</span>, <span class="fl">15.4</span>, <span class="fl">16.9</span>, <span class="fl">20.8</span><span class="op">)</span></span></code></pre>
</div>
<ol start="2" style="list-style-type: lower-alpha">
<li>Compute the posterior for the coefficient of variation <span class="math inline">\(CV = \frac{\sigma}{\mu}\)</span>.</li>
<li>Generate samples for an unseen data point <span class="math inline">\(\tilde{X}\)</span>.</li>
<li>Compare the distribution in c) to one generated using only the MAP
estimate. Is there a discrepancy and why?</li>
</ol>
</div>
<div class="section level2">
<h2 id="hpdi">1.8 HPDI<a class="anchor" aria-label="anchor" href="#hpdi"></a>
</h2>
<p>Another approach to summarizing the posterior is to compute the
<em>shortest</em> interval that contains <span class="math inline">\(p\%\)</span> of the posterior. Such interval is
called highest posterior density interval (HPDI).</p>
<p>Write a function that returns the highest posterior density interval,
given a set of posterior samples.</p>
<p>Assume that the analytical form of a posterior is known to be
Gamma(3, 20). Generate samples from this distribution and compute the
90% HPDI. Compare it to the 90% credible interval.</p>
<p>Hint: If you sort the posterior samples in order, each set of n
consecutive samples contains <span class="math inline">\(100 \cdot
\frac{n}{N} \%\)</span> of the posterior, where <span class="math inline">\(N\)</span> is the total number of samples.</p>
<!-- ************************************************************************ -->
</div>
</div>
<div class="section level1">
<h1 id="stan">2. Stan<a class="anchor" aria-label="anchor" href="#stan"></a>
</h1>
<div class="section level2">
<h2 id="gamma-poisson-model">2.1 Gamma-Poisson model<a class="anchor" aria-label="anchor" href="#gamma-poisson-model"></a>
</h2>
<p>The Gamma-Poisson model can be stated as:</p>
<p><span class="math display">\[y_i \sim \text{Pois}(\lambda) \\
\lambda \sim \Gamma(1, 1), \]</span></p>
<p>where <span class="math inline">\(y_i\)</span> are non-negative data
points, and Pois is the Poisson distribution with rate parameter <span class="math inline">\(\lambda &gt; 0\)</span>.</p>
<p>Implement the model in Stan. Do it so that the parameter beta is
input as part of data. Heuristically, what effect does altering beta
have on the prior shape?</p>
<p>Fit the model using the data</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu">c</span><span class="op">(</span><span class="fl">2</span>,<span class="fl">7</span>,<span class="fl">4</span>,<span class="fl">3</span>,<span class="fl">5</span>,<span class="fl">2</span>,<span class="fl">7</span>,<span class="fl">5</span>,<span class="fl">5</span>,<span class="fl">5</span><span class="op">)</span></span></code></pre>
</div>
<p>Compute the MAP, mean and 90% CIs and include them in a figure with a
histogram of posterior samples.</p>
</div>
<div class="section level2">
<h2 id="dice">2.2 Dice<a class="anchor" aria-label="anchor" href="#dice"></a>
</h2>
<p>Write a Stan program that implements the following statistical
model:</p>
<p><span class="math display">\[y \sim \text{categorial}(\theta) \\
\theta \sim \text{Dir}(1, 1, ..., 1), \]</span></p>
<p>where <span class="math inline">\(\theta\)</span> is a 6-dimensional
probability vector and Dir is the Dirichlet distribution.</p>
<p>Use the program to assess the fairness of a 6 sided dice. In other
words, estimate the probabilities of each side on a roll using the
following data.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu">c</span><span class="op">(</span><span class="fl">3</span>, <span class="fl">2</span>, <span class="fl">6</span>, <span class="fl">3</span>, <span class="fl">6</span>, <span class="fl">2</span>, <span class="fl">5</span>, <span class="fl">6</span>, <span class="fl">5</span>, <span class="fl">6</span>, <span class="fl">4</span>, <span class="fl">1</span>, <span class="fl">4</span>, <span class="fl">2</span>, <span class="fl">5</span>, <span class="fl">4</span>, <span class="fl">6</span>, <span class="fl">6</span>, <span class="fl">5</span>, <span class="fl">4</span>, <span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">3</span>, <span class="fl">4</span>, <span class="fl">2</span>, <span class="fl">3</span>, <span class="fl">4</span>, <span class="fl">4</span>, <span class="fl">4</span>, <span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">4</span>, <span class="fl">4</span>, <span class="fl">1</span>, <span class="fl">6</span>, <span class="fl">4</span>, <span class="fl">6</span>, <span class="fl">5</span>, <span class="fl">5</span>, <span class="fl">2</span>, <span class="fl">6</span>, <span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">4</span>, <span class="fl">4</span>, <span class="fl">1</span>,  <span class="fl">6</span>,  <span class="fl">6</span>, <span class="fl">1</span>, <span class="fl">6</span>, <span class="fl">4</span>, <span class="fl">5</span>, <span class="fl">5</span>, <span class="fl">3</span>, <span class="fl">4</span>, <span class="fl">2</span>, <span class="fl">6</span>, <span class="fl">6</span>, <span class="fl">5</span>, <span class="fl">2</span>, <span class="fl">6</span>, <span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">4</span>, <span class="fl">4</span>, <span class="fl">4</span>, <span class="fl">6</span>, <span class="fl">3</span>, <span class="fl">5</span>, <span class="fl">3</span>, <span class="fl">6</span>, <span class="fl">5</span>, <span class="fl">3</span>, <span class="fl">3</span>, <span class="fl">2</span>, <span class="fl">3</span>, <span class="fl">3</span>, <span class="fl">5</span>, <span class="fl">3</span>, <span class="fl">3</span>, <span class="fl">4</span>, <span class="fl">6</span>, <span class="fl">4</span>, <span class="fl">3</span>, <span class="fl">6</span>, <span class="fl">6</span>, <span class="fl">4</span>, <span class="fl">4</span>, <span class="fl">6</span>, <span class="fl">5</span>, <span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">5</span>, <span class="fl">1</span>, <span class="fl">2</span>, <span class="fl">4</span>, <span class="fl">4</span>, <span class="fl">1</span><span class="op">)</span> </span></code></pre>
</div>
<ol style="list-style-type: decimal">
<li><p>Plot the marginal posteriors for each <span class="math inline">\(\theta_i\)</span>.</p></li>
<li><p>Is the dice fair? Quantify this somehow</p></li>
</ol>
<p>Hint: You can e.g. compute a posterior probability difference of some
of the dice faces.</p>
</div>
<div class="section level2">
<h2 id="normal-model">2.3 Normal model<a class="anchor" aria-label="anchor" href="#normal-model"></a>
</h2>
<p>Implement the Normal model in Stan.</p>
<p>In the generated quantities block: - Generate a posterior predictive
distribution - Generate posterior for <span class="math inline">\(CV =
\frac{\mu}{\sigma}.\)</span></p>
<p>Fit the model using the data</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu">c</span><span class="op">(</span><span class="fl">3.7</span>, <span class="fl">2.8</span>, <span class="fl">4.03</span>, <span class="fl">2.11</span>, <span class="fl">2.58</span>, <span class="fl">0.96</span>, <span class="fl">1.74</span>, <span class="fl">0.34</span>, <span class="fl">0.75</span>, <span class="fl">2.07</span><span class="op">)</span></span></code></pre>
</div>
<p>Plot the posterior distribution and color the points according to the
condition <span class="math inline">\(CV &lt; 1\)</span>.</p>
</div>
<div class="section level2">
<h2 id="time-series-modeling">2.4. Time series modeling<a class="anchor" aria-label="anchor" href="#time-series-modeling"></a>
</h2>
<p>The AR(1) process is defined by the recursion: <span class="math display">\[x_i \sim N(\phi \cdot x_{i-1},
\sigma^2),\]</span> where <span class="math inline">\(i\)</span> is a
time index. In other words, given some initial value <span class="math inline">\(x_1\)</span>, the next value <span class="math inline">\(x_2\)</span> is generated from a normal
distribution with mean <span class="math inline">\(\phi\cdot
x_1\)</span> and variance <span class="math inline">\(\sigma^2\)</span>.
This pattern continues for the successive values.</p>
<p>Write a Stan program that estimates the parameters <span class="math inline">\(\phi\)</span> and <span class="math inline">\(\sigma\)</span> of the AR(1) process.</p>
<p>Using the data in <code>data/time_series.txt</code>, do the
following:</p>
<ol style="list-style-type: decimal">
<li>Estimate the parameters <span class="math inline">\(\phi\)</span>
and <span class="math inline">\(\sigma\)</span>.</li>
<li>Starting from <span class="math inline">\(x_{new} = 5\)</span>
predict the process 50 values into the future and plot the
predictions.</li>
</ol>
</div>
</div>
<div class="section level1">
<h1 id="mcmc">3. MCMC<a class="anchor" aria-label="anchor" href="#mcmc"></a>
</h1>
<div class="section level2">
<h2 id="binomial-model">3.1 Binomial model<a class="anchor" aria-label="anchor" href="#binomial-model"></a>
</h2>
<p>Implement the Metropolis-Hastings algorithm for the beta-binomial
model.</p>
<p>Assume there are 50 people of whom 7 are left-handed. Estimate the
probability of being left-handed in the wider population.</p>
<p>Use <span class="math inline">\(p(\theta^* | \theta_{now}) =
\text{Beta}(\theta^* | 2, 2)\)</span> as your proposal distribution,
where <span class="math inline">\(\theta^*\)</span> is the proposal and
<span class="math inline">\(\theta_{now}\)</span> the current
sample.</p>
<p>Compute the proportion of accepted proposals for the sampler.</p>
</div>
<div class="section level2">
<h2 id="gibbs-sampler">3.2. Gibbs sampler<a class="anchor" aria-label="anchor" href="#gibbs-sampler"></a>
</h2>
<p>Consider the distribution <span class="math display">\[ p(x, y) = C
\cdot \exp^{-(x^2y^2 + x^2 + y^2 -8x -8y)/2},\]</span> where <span class="math inline">\(C\)</span> is a normalizing constant. It is known
that the conditional distribution of x given y is the normal
distribution <span class="math inline">\(p(x|y) = N(\mu,
\sigma^2)\)</span>, where the mean <span class="math inline">\(\mu =
4/(1 + y^2)\)</span> and the standard deviation <span class="math inline">\(\sigma = \sqrt{1/(1 + y^2)}\)</span>. Due to
symmetry, <span class="math inline">\(p(y|x)\)</span> can be recovered
simply by changing <span class="math inline">\(y\)</span>’s to <span class="math inline">\(x\)</span>’s in <span class="math inline">\(p(x|y)\)</span>.</p>
<p>The Gibbs sampler is a special case of the Metropolis-Hastings
algorithm. It can be stated as follows:</p>
<ol style="list-style-type: decimal">
<li>Choose some initial values for the parameters, <span class="math inline">\(x_0\)</span> and <span class="math inline">\(y_0\)</span> in our case.</li>
<li>For <span class="math inline">\(i = 1, ..., N\)</span> do:
<ol style="list-style-type: lower-alpha">
<li>Draw <span class="math inline">\(x_i\)</span> from <span class="math inline">\(p(x_i|y_{i-1})\)</span>
</li>
<li>Draw <span class="math inline">\(y_i\)</span> from <span class="math inline">\(p(y_i|x_i)\)</span>
</li>
</ol>
</li>
</ol>
<p>(In this notation <span class="math inline">\(x_i\)</span> refers to
the <span class="math inline">\(x\)</span> sample at step <span class="math inline">\(i\)</span>, <span class="math inline">\(y_{i-1}\)</span> to the y sample at step <span class="math inline">\(i-1\)</span> and so on)</p>
<p>Build a Gibbs sampler that draws samples from <span class="math inline">\(p(x, y)\)</span>. Visualize the resulting
distribution.</p>
</div>
<div class="section level2">
<h2 id="gamma-with-discrete-rate">3.3. Gamma with discrete rate<a class="anchor" aria-label="anchor" href="#gamma-with-discrete-rate"></a>
</h2>
<p>The data</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu">c</span><span class="op">(</span><span class="fl">10.61</span>, <span class="fl">4.76</span>, <span class="fl">11.25</span>, <span class="fl">5.55</span>, <span class="fl">23.81</span>, <span class="fl">7.45</span>, <span class="fl">17.31</span>, <span class="fl">15.08</span>, <span class="fl">8.19</span>, <span class="fl">15</span>, <span class="fl">4.29</span>, <span class="fl">10.95</span>, <span class="fl">15.45</span>, <span class="fl">10.09</span>, <span class="fl">7.96</span>, <span class="fl">12.35</span>, <span class="fl">11.43</span>, <span class="fl">7.33</span>, <span class="fl">8.17</span>, <span class="fl">21</span><span class="op">)</span></span></code></pre>
</div>
<p>is modelled with a <span class="math inline">\(\Gamma(\alpha,
\beta)\)</span> distribution, where the shape <span class="math inline">\(\alpha = 5\)</span>, but the rate <span class="math inline">\(\beta\)</span> is unknown. However, it is known
that beta can only take values <span class="math inline">\(1.1^N\)</span>, where <span class="math inline">\(N\)</span> is an integer.</p>
<p>Implement a Metropolis-Hastings sampler for this model.</p>
<p>Use a proposal distribution that gives equal probability for moving
one step up <span class="math inline">\((N^* = N+1)\)</span> or down
<span class="math inline">\((N^* = N-1)\)</span>, and some positive
probability for staying still <span class="math inline">\((N^*=N)\)</span>.</p>
<p>Generate the initial value randomly: <span class="math inline">\(N_0
\sim \text{Uniform}(-100, 100)\)</span> and compute an estimate for
<span class="math inline">\(\beta\)</span>.</p>
</div>
<div class="section level2">
<h2 id="hatr">3.4. <span class="math inline">\(\hat{R}\)</span>
<a class="anchor" aria-label="anchor" href="#hatr"></a>
</h2>
<p>Write a function that returns the <span class="math inline">\(\hat{R}\)</span> statistic for a collection of
MCMC chains. Compute <span class="math inline">\(\hat{R}\)</span> for
the samples from one of the exercises 3.1-3.3, and plot the trace
plots.</p>
<p>See p.285 in BDA3 for the definition of <span class="math inline">\(\hat{R}\)</span>.</p>
</div>
</div>
<div class="section level1">
<h1 id="hierarchical-models">4. Hierarchical models<a class="anchor" aria-label="anchor" href="#hierarchical-models"></a>
</h1>
<div class="section level2">
<h2 id="model-analysis">4.1. Model analysis<a class="anchor" aria-label="anchor" href="#model-analysis"></a>
</h2>
<p>Examine the following statistical models. Determine if they exhibit a
hierarchical structure. If not, introduce modifications to make them
hierarchical.</p>
<p>Below, the subscript <span class="math inline">\(i\)</span> denotes a
data point, while <span class="math inline">\(g\)</span> designates a
population subgroup.</p>
<ol style="list-style-type: lower-alpha"><li>
</li></ol>
<p><span class="math display">\[
y_{g, i} \sim N(a_g + b \cdot x_{g,i}, \sigma^2) \\
a_g \sim N(0, 1) \\
b \sim N(0, 1)  \\
\sigma \sim \text{Exponential}(1) \\
\]</span></p>
<ol start="2" style="list-style-type: lower-alpha"><li>
</li></ol>
<p><span class="math display">\[
y_{g,i} \sim \text{Binom}(N, p_{g,i})  \\
\text{logit}(p_{g,i}) = a_g + b \cdot x_i  \\
a_{g} \sim N(\alpha, 1)   \\
\alpha \sim N(0, 10)   \\
b \sim N(0, 1)
\]</span></p>
<ol start="3" style="list-style-type: lower-alpha"><li>
</li></ol>
<p><span class="math display">\[
X_i \sim \Gamma(\alpha, \beta)   \\
\alpha \sim \Gamma(1, 1)   \\
\beta \sim \Gamma(1, 1)
\]</span></p>
</div>
<div class="section level2">
<h2 id="hierarchical-gamma-poisson">4.2. Hierarchical Gamma-Poisson<a class="anchor" aria-label="anchor" href="#hierarchical-gamma-poisson"></a>
</h2>
<p>A hierarchical Gamma-Poisson model can be stated as follows:</p>
<p><span class="math display">\[
y_i \sim \text{Pois}(\lambda) \\
\lambda \sim \Gamma(1, \beta) \\
\beta \sim \Gamma(2, 1) \\
\]</span></p>
<p>Use data</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">y</span> <span class="op">&lt;-</span>  <span class="fu">c</span><span class="op">(</span><span class="fl">2</span>,<span class="fl">7</span>,<span class="fl">4</span>,<span class="fl">3</span>,<span class="fl">5</span>,<span class="fl">2</span>,<span class="fl">7</span>,<span class="fl">5</span>,<span class="fl">5</span>,<span class="fl">5</span><span class="op">)</span></span></code></pre>
</div>
<p>Implement the model in Stan.</p>
<p>Identify the data subgroups. Visualize the posterior distribution of
beta. Generate samples from the population distribution of <span class="math inline">\(\lambda\)</span> in the generated quantities block
and plot them in a histogram.</p>
</div>
<div class="section level2">
<h2 id="hierarchical-poisson-regression">4.3. Hierarchical Poisson regression<a class="anchor" aria-label="anchor" href="#hierarchical-poisson-regression"></a>
</h2>
<p>A Poisson regression model can be specified as <span class="math inline">\(y_i \sim \text{Pois}(\exp^{\alpha + \beta
x_i})\)</span>, where <span class="math inline">\(x_i\)</span> and <span class="math inline">\(y_i\)</span> are corresponding data points.</p>
<p>Apply Poisson regression to model the annual rental count <span class="math inline">\((y_i)\)</span> for homestay apartments located at
a distance <span class="math inline">\(x_i\)</span> from the city
center.</p>
<p>The data comprises 25 randomly selected apartments in 10 different
cities. The file <code>data/apartment_x.txt</code> contains the
distances of apartments to the center, with rows representing cities and
columns representing apartments. The file
<code>data/apartment_y.txt</code> contains the number of rentals during
the surveyed year for the same apartments.</p>
<p>Build a Stan program for hierarchical Poisson regression, with
hierarchical structure for both <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>.</p>
<p>Generate and visualize posteriors for the population distributions of
<span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. What is the probability that <span class="math inline">\(\beta &gt; 0\)</span> in the population? What
implications does <span class="math inline">\(\beta &gt; 0\)</span> have
in terms of the application?</p>
</div>
<div class="section level2">
<h2 id="hierarchical-binomial-model">4.4. Hierarchical binomial model<a class="anchor" aria-label="anchor" href="#hierarchical-binomial-model"></a>
</h2>
<p>As commonly acknowledged, multiple humanoid species inhabit various
solar systems within the Milky Way galaxy.</p>
<p>The file, <code>data/handedness.txt</code>, contains data on the
handedness of some of these species, with <span class="math inline">\(N\)</span> representing the sample size and <span class="math inline">\(x\)</span> denoting the count of left-handed
specimens. The objective is to estimate the prevalence of
left-handedness, <span class="math inline">\(\theta\)</span>.</p>
<p>Develop Stan programs for both unpooled and partially pooled binomial
models. Utilize the unpooled model to fit the completely pooled
model.</p>
<p>Incorporate Beta priors for <span class="math inline">\(\theta\)</span>. Compare the estimates, such as
means, derived from the distinct pooling strategies.</p>
</div>
</div>
<div class="section level1">
<h1 id="model-comparison">5. Model comparison<a class="anchor" aria-label="anchor" href="#model-comparison"></a>
</h1>
<div class="section level2">
<h2 id="prior-predictive-check">5.1 Prior predictive check<a class="anchor" aria-label="anchor" href="#prior-predictive-check"></a>
</h2>
<p>In a salmon farm research facility, the relationship between the
length of salmons (in meters, <span class="math inline">\(y\)</span>)
and the amount of food provided (in grams, <span class="math inline">\(x\)</span>) is studied. The amount of food
administered in 21 salmon pools is meticulously controlled, ranging from
40 to 60 grams per individual salmon in one-gram increments.</p>
<p>The chosen statistical model is linear regression:</p>
<p><span class="math display">\[
y \sim N(a + bx, \sigma^2) \\
a, b \sim N(0, 1) \\
\sigma \sim \Gamma(2, 1) \\
\]</span></p>
<p>Generate the <a href="https://mc-stan.org/docs/2_26/stan-users-guide/prior-predictive-checks.html" class="external-link">prior
predictive distribution</a>, plot it, and visually assess the validity
of the priors.</p>
</div>
<div class="section level2">
<h2 id="posterior-predictive-check">5.2. Posterior predictive check<a class="anchor" aria-label="anchor" href="#posterior-predictive-check"></a>
</h2>
<p>The white noise process is perhaps the simplest non-trivial time
series model. If <span class="math inline">\(i\)</span> is the time
index, then the model can be specified as <span class="math inline">\(x_i \sim N(0, \sigma^2)\)</span> for all <span class="math inline">\(i = 1, \ldots ,N\)</span>.</p>
<p>The file <code>data/white_noise.txt</code> contains a time series.
Plot the data.</p>
<p>Build a Stan program for the white noise model to estimate <span class="math inline">\(\sigma\)</span> and use it on the provided
data.</p>
<p>Perform a posterior predictive check by using lag-1 autocorrelation
as the test statistic. Compute the posterior predictive p-value.</p>
<p>Hint: lag-1 autocorrelation is simply the Pearson correlation between
<span class="math inline">\(x_{1:(N-1)}\)</span> and <span class="math inline">\(x_{2:N}\)</span></p>
</div>
</div>
<div class="section level1">
<h1 id="gaussian-processes">6. Gaussian processes<a class="anchor" aria-label="anchor" href="#gaussian-processes"></a>
</h1>
<div class="section level2">
<h2 id="gp-prediction">6.1. GP prediction<a class="anchor" aria-label="anchor" href="#gp-prediction"></a>
</h2>
<p>Consider the following data <span class="math inline">\((x,
y)\)</span>:</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu">c</span><span class="op">(</span><span class="fl">6.86</span>, <span class="op">-</span><span class="fl">7.88</span>, <span class="fl">1.59</span>, <span class="fl">5.95</span>, <span class="op">-</span><span class="fl">2.55</span>, <span class="op">-</span><span class="fl">1.96</span>, <span class="fl">3.77</span>, <span class="op">-</span><span class="fl">6.74</span>, <span class="op">-</span><span class="fl">6.83</span>, <span class="fl">8.42</span>, <span class="op">-</span><span class="fl">4.95</span>, <span class="op">-</span><span class="fl">6.29</span>, <span class="fl">9.58</span>, <span class="op">-</span><span class="fl">1.95</span>, <span class="fl">7.6</span>, <span class="fl">1.97</span>, <span class="fl">7.75</span>, <span class="fl">8.34</span>, <span class="fl">9.22</span>, <span class="op">-</span><span class="fl">6.31</span>, <span class="fl">1.73</span>, <span class="fl">9.58</span>, <span class="fl">6.86</span>, <span class="fl">1.46</span>, <span class="op">-</span><span class="fl">6.7</span>, <span class="op">-</span><span class="fl">9.9</span>, <span class="fl">6.81</span>, <span class="op">-</span><span class="fl">6.38</span>, <span class="fl">3.52</span>, <span class="op">-</span><span class="fl">4.36</span>, <span class="op">-</span><span class="fl">3.46</span>, <span class="fl">7.7</span>, <span class="op">-</span><span class="fl">7.63</span>, <span class="fl">3.51</span>, <span class="fl">5.57</span>, <span class="fl">3.2</span>, <span class="fl">2.04</span>, <span class="fl">6.33</span>, <span class="op">-</span><span class="fl">7.84</span>, <span class="op">-</span><span class="fl">2.85</span>, <span class="op">-</span><span class="fl">7.86</span>, <span class="op">-</span><span class="fl">5.14</span>, <span class="op">-</span><span class="fl">6.18</span>, <span class="op">-</span><span class="fl">9.35</span>, <span class="op">-</span><span class="fl">5.59</span>, <span class="op">-</span><span class="fl">6.86</span>, <span class="fl">4.2</span>, <span class="fl">8.83</span>, <span class="fl">8.04</span> <span class="op">)</span></span>
<span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu">c</span><span class="op">(</span><span class="fl">2.95</span>, <span class="op">-</span><span class="fl">6.7</span>, <span class="fl">0.8</span>, <span class="op">-</span><span class="fl">1.47</span>, <span class="op">-</span><span class="fl">0.03</span>, <span class="op">-</span><span class="fl">0.26</span>, <span class="op">-</span><span class="fl">1.03</span>, <span class="op">-</span><span class="fl">2.8</span>, <span class="op">-</span><span class="fl">3.01</span>, <span class="fl">6.75</span>, <span class="fl">1.68</span>, <span class="op">-</span><span class="fl">0.93</span>, <span class="op">-</span><span class="fl">0.88</span>, <span class="op">-</span><span class="fl">1.03</span>, <span class="fl">6.88</span>, <span class="op">-</span><span class="fl">0.1</span>, <span class="fl">7.32</span>, <span class="fl">7.59</span>, <span class="fl">3.09</span>, <span class="op">-</span><span class="fl">0.44</span>, <span class="fl">0.69</span>, <span class="op">-</span><span class="fl">0.27</span>, <span class="fl">3.45</span>, <span class="fl">0.46</span>, <span class="op">-</span><span class="fl">2.49</span>, <span class="fl">3.33</span>, <span class="fl">3.28</span>, <span class="op">-</span><span class="fl">1.48</span>, <span class="op">-</span><span class="fl">0.11</span>, <span class="fl">1.76</span>, <span class="fl">0.25</span>, <span class="fl">6.01</span>, <span class="op">-</span><span class="fl">6.53</span>, <span class="fl">0.62</span>, <span class="op">-</span><span class="fl">1.01</span>, <span class="fl">0.26</span>, <span class="fl">1.31</span>, <span class="fl">0.47</span>, <span class="op">-</span><span class="fl">6.7</span>, <span class="op">-</span><span class="fl">0.29</span>, <span class="op">-</span><span class="fl">6.09</span>, <span class="fl">2.03</span>, <span class="op">-</span><span class="fl">0.22</span>, <span class="op">-</span><span class="fl">1.24</span>, <span class="fl">1.46</span>, <span class="op">-</span><span class="fl">3.73</span>, <span class="op">-</span><span class="fl">0.87</span>, <span class="fl">5.27</span>, <span class="fl">6.59</span><span class="op">)</span></span></code></pre>
</div>
<p>Model the data as <span class="math inline">\(y \sim N(f(x),
\sigma^2)\)</span> and give <span class="math inline">\(f(x)\)</span> a
Gaussian process prior. Use the squared exponential covariance function
with hyperparameters <span class="math inline">\(\lambda = 1\)</span>
(length-scale), <span class="math inline">\(\alpha = 1\)</span>
(standard deviation), <span class="math inline">\(\sigma =
0.5\)</span>.</p>
<p>Plot the posterior for <span class="math inline">\(f\)</span> along
with the data, and compute the posterior probability for <span class="math inline">\(f(0) &gt; 0\)</span>.</p>
</div>
<div class="section level2">
<h2 id="gp-prediction-1">6.2. GP prediction<a class="anchor" aria-label="anchor" href="#gp-prediction-1"></a>
</h2>
<p>The file <code>data/nytemp.txt</code> contains daily maximum
temperatures (<span class="math inline">\(Temp\)</span>) in New York
from May to September 1973 [1]. The column <span class="math inline">\(x\)</span> gives the day number for the date (Jan
1st is day number 1 etc).</p>
<p>Do Gaussian process regression on the data and estimate the
temperature trend for the year 1973. Use a periodic covariance kernel
with <span class="math inline">\(\alpha = 100\)</span> and <span class="math inline">\(\lambda = 10\)</span>, and set a suitable value
for the period. Set <span class="math inline">\(\sigma\)</span>
(deviance from the trend) as an unknown parameter in Stan.</p>
<p>Plot the data with the posterior for temperature. Plot the marginal
posterior for temperature for the last day of the year and compare it
against the true value (which was 38F).</p>
<p>Hint:</p>
<p>See <a href="https://mc-stan.org/docs/functions-reference/gaussian-process-covariance-functions.html" class="external-link uri">https://mc-stan.org/docs/functions-reference/gaussian-process-covariance-functions.html</a>
for info on periodic kernel in Stan.</p>
<p>[1] (Chambers, J. M., Cleveland et al. (1983) Graphical Methods for
Data Analysis)</p>
</div>
<div class="section level2">
<h2 id="gp-prediction-2">6.3. GP prediction<a class="anchor" aria-label="anchor" href="#gp-prediction-2"></a>
</h2>
<p>The data file <code>data/stock.txt</code> contains the (scaled and
transformed) stock price of a company over 250 days.</p>
<p>Implement the following model and use it to predict the stock 150
days into the future.</p>
<p><span class="math display">\[
y \sim N(f, \sigma^2) \\
f = f_{trend} + f_{noise} \\
f_{trend} \sim GP(0, K_1(\alpha_1, \lambda_1)) \\
f_{noise} \sim GP(0, K_2(\alpha_2, \lambda_2)) \\
\sigma \sim \Gamma(2, 10)
\]</span></p>
<p>Set <span class="math inline">\(K_1\)</span> to squared exponential
covariance function and <span class="math inline">\(K_2\)</span> to
exponential covariance. The point of <span class="math inline">\(f_{trend}\)</span> is to capture the longer term
trend in the data, while <span class="math inline">\(f_{noise}\)</span>
targets shorter-term variations around the trend.</p>
<p>Set the hyperparameters <span class="math inline">\(\alpha_{1},
\alpha_{2}\)</span> and <span class="math inline">\(\lambda_{1},
\lambda_{2}\)</span> appropriately.</p>
<p>Is such a model appropriate for predicting stock prices into the
future?</p>
<p>Hint: Running the Stan program can take quite a long time, so do the
initial testing using only 1 chain and, for example, 500 iterations.</p>
</div>
</div>
<div class="section level1">
<h1 id="other-topics">7. Other topics<a class="anchor" aria-label="anchor" href="#other-topics"></a>
</h1>
<div class="section level2">
<h2 id="hierarchical-models-using-brms">7.1 Hierarchical models using <code>brms</code>
<a class="anchor" aria-label="anchor" href="#hierarchical-models-using-brms"></a>
</h2>
<ol style="list-style-type: lower-alpha"><li>
</li></ol>
<p>Use <code>brms</code> to fit the hierarchical Gamma-Poisson model
fitted in exercise 4.2. After fitting the model plot the histogram of
lambda and compare that the results are similar to the model fit in
4.2.</p>
<p>(Hint: You can check <a href="https://discourse.mc-stan.org/t/how-to-set-prior-for-hyper-parameter/15306/5" class="external-link">this</a>
forum post for how to implement prior for hyper-parameter when using
<code>brm</code>. You can also get a warning when fitting the model,
which you can ignore.)</p>
<ol start="2" style="list-style-type: lower-alpha"><li>
</li></ol>
<p>Fit the hierarchical Poisson regression model fitted in exercise 4.3
using <code>brms</code>. After fitting the models plot the city specific
estimates for alpha and beta.</p>
</div>
<div class="section level2">
<h2 id="zero-inflated-poisson-model">7.2 Zero-inflated poisson model<a class="anchor" aria-label="anchor" href="#zero-inflated-poisson-model"></a>
</h2>
<p>Sometimes count data has more zeros than is expected when using, for
example, Poisson or negative binomial model. This type of data can be
called zero-inflated. An example of this type of data is
<code>DoctorVisits</code> dataset from <code>AER</code> R package. The
data describes the amount of doctor visits based on Australian Health
Survey in 1977—1987.</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Install the package to get the data</span></span>
<span><span class="fu">install.packages</span><span class="op">(</span><span class="va">AER</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">ERROR<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="error" tabindex="0"><code>Error in eval(call, envir = parent.frame()): object 'AER' not found</code></pre>
</div>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Get data</span></span>
<span><span class="fu">data</span><span class="op">(</span><span class="st">"DoctorVisits"</span>, package <span class="op">=</span> <span class="st">"AER"</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">ERROR<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="error" tabindex="0"><code>Error in find.package(package, lib.loc, verbose = verbose): there is no package called 'AER'</code></pre>
</div>
<ol style="list-style-type: lower-alpha"><li>
</li></ol>
<p>Use <code>brms</code> to fit an zero-inflated poisson model to the
data while using gender, age, health and income as explanatory
variables. Use weakly informative prior for the population-level
coefficients. Comment the fit summary. Also plot the conditional
effects.</p>
<ol start="2" style="list-style-type: lower-alpha"><li>
</li></ol>
<p>Part of zero-inflated models is the zero-inflated probability. This
probability can also be predicted when fitting the model. Fit the same
model, but this time also predict zero-inflated probability using age
and health. Again comment the fit summary and especially how age and
health affect probability of zero visits. Compare the results to the
first model.</p>
<ol start="3" style="list-style-type: lower-alpha"><li>
</li></ol>
<p>To end fit a zero-inflated negative binomial model with the same
explanatory variables as in the second model. Compare results to the two
previous models. Use loo and comment which model is the best. Running
the model can take a while.</p>
<p>(Hint: Use <code>adapt_delta = 0.95</code>. Also if your computer has
4 or more cores you can use <code>cores = 4</code> to speed up the
fit.)</p>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div>
</div></section>
</div>
    </main>
</div>
<!-- END  : inst/pkgdown/templates/content-extra.html -->

      </div>
<!--/div.row-->
      		<footer class="row footer mx-md-3"><hr>
<div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/edit/main/README.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/" class="external-link">Source</a></p>
				<p><a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/blob/main/CITATION" class="external-link">Cite</a> | <a href="mailto:velait@utu.fi">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.17.1" class="external-link">sandpaper (0.17.1)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.9" class="external-link">pegboard (0.7.9)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.7" class="external-link">varnish (1.0.7)</a></p>
			</div>
		</footer>
</div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "LearningResource",
  "@id": "https://carpentries-incubator.github.io/statistical-probabilistic-programming-r/instructor/aio.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/LearningResource/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "software, data, lesson, The Carpentries",
  "name": "All in One View",
  "creativeWorkStatus": "active",
  "url": "https://carpentries-incubator.github.io/statistical-probabilistic-programming-r/instructor/aio.html",
  "identifier": "https://carpentries-incubator.github.io/statistical-probabilistic-programming-r/instructor/aio.html",
  "dateCreated": "2025-08-22",
  "dateModified": "2025-08-26",
  "datePublished": "2025-08-26"
}

  </script><script>
		feather.replace();
	</script>
</body>
</html><!-- END:   inst/pkgdown/templates/layout.html-->

