<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><title>Introduction to Probabilistic Programming in R: MCMC</title><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="stylesheet" type="text/css" href="../assets/styles.css"><script src="../assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="manifest" href="../site.webmanifest"><link rel="mask-icon" href="../safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" content="#ffffff"></head><body>
    <header id="top" class="navbar navbar-expand-md navbar-light bg-white top-nav incubator"><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-6">
      <div class="large-logo">
        <img alt="Carpentries Incubator" src="../assets/images/incubator-logo.svg"><abbr class="badge badge-light" title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught." style="background-color: #FF4955; border-radius: 5px">
          <a href="https://cdh.carpentries.org/the-lesson-life-cycle.html#early-development-pre-alpha-through-alpha" class="external-link alert-link" style="color: #000">
            <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
            Pre-Alpha
          </a>
          <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
        </abbr>
        
      </div>
    </div>
    <div class="selector-container">
      
      
      <div class="dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1"><li><button class="dropdown-item" type="button" onclick="window.location.href='../mcmc.html';">Learner View</button></li>
        </ul></div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl navbar-light bg-white bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Carpentries Incubator" src="../assets/images/incubator-logo-sm.svg"></div>
    <div class="lesson-title-md">
      Introduction to Probabilistic Programming in R
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="search button" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0"><li class="nav-item">
          <span class="lesson-title">
            Introduction to Probabilistic Programming in R
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/instructor-notes.html">Instructor Notes</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/images.html">Extract All Images</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown"><hr><li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul></li>
      </ul></div>
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled><input class="form-control me-2 searchbox" type="search" placeholder="Search" aria-label="Search"><button class="btn btn-outline-success tablet-search-button" type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="search button"></i>
        </button>
      </fieldset></form>
  </div><!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Introduction to Probabilistic Programming in R
</div>

<aside class="col-md-12 lesson-progress"><div style="width: 30%" class="percentage">
    30%
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: 30%" aria-valuenow="30" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="../mcmc.html">Learner View</a>
                      </div>
                    </div>
                  </div><!--/div.accordion-item-->
                </div><!--/div.accordion-flush-->
              </div><!--div.sidenav-view-selector -->
            </div><!--/div.col -->
      
            <hr></div><!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Schedule</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="setup.html">1. Setup</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="bayesian-statistics.html">2. Basics of Bayesian statistics</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="stan.html">3. Stan</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlushcurrent">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-headingcurrent">
      <button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapsecurrent" aria-expanded="true" aria-controls="flush-collapsecurrent">
        <span class="visually-hidden">Current Chapter</span>
        <span class="current-chapter">
        4. MCMC
        </span>
      </button>
    </div><!--/div.accordion-header-->
        
    <div id="flush-collapsecurrent" class="accordion-collapse collapse show" aria-labelledby="flush-headingcurrent" data-bs-parent="#accordionFlushcurrent">
      <div class="accordion-body">
        <ul><li><a href="#metropolis-hastings-algorithm">Metropolis-Hastings algorithm</a></li>
<li><a href="#example">Example</a></li>
<li><a href="#assessing-convergence">Assessing convergence</a></li>
<li><a href="#hamiltonian-monte-carlo">Hamiltonian Monte Carlo</a></li>
<li><a href="#reading">Reading</a></li>
        </ul></div><!--/div.accordion-body-->
    </div><!--/div.accordion-collapse-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="hierarchical-models.html">5. Hierarchical Models</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="model-critisism.html">6. Model checking</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="gaussian-processes.html">7. Gaussian processes</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush9">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading9">
        <a href="other-topics.html">8. Other topics</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush10">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading10">
        <a href="recommended-reading.html">9. Recommended reading</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush11">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading11">
        <a href="exercises.html">10. exercises</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width"><div class="accordion accordion-flush resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul><li>
                        <a href="../instructor/key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="../instructor/instructor-notes.html">Instructor Notes</a>
                      </li>
                      <li>
                        <a href="../instructor/images.html">Extract All Images</a>
                      </li>
                      <hr><li><a class="dropdown-item" href="reference.html">Reference</a></li>
                    </ul></div>
                </div>
              </div>
            </div>
            <hr class="half-width resources"><a href="../instructor/aio.html">See all in one page</a>
            

            <hr class="d-none d-sm-block d-md-none"><div class="d-grid gap-1">
            
            </div>
          </div><!-- /div.accordion -->
        </div><!-- /div.sidebar-inner -->
      </nav></div><!-- /div.sidebar -->
  </div><!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-instructor.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <nav class="lesson-content mx-md-4" aria-label="Previous and Next Chapter"><!-- content for small screens --><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="../instructor/stan.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="../instructor/hierarchical-models.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="../instructor/stan.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Stan
        </a>
        <a class="chapter-link float-end" href="../instructor/hierarchical-models.html" rel="next">
          Next: Hierarchical Models... 
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
      <hr></nav><main id="main-content" class="main-content"><div class="container lesson-content">
        <h1>MCMC</h1>
        <p>Last updated on 2024-01-16 |
        
        <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/edit/main/episodes/mcmc.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
        
        
        
        <p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 12 minutes</p>
        
        <div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>

        

<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul><li>What is MCMC?</li>
</ul></div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul><li><p>Idea behind MCMC</p></li>
<li>
<p>Learn how to</p>
<ul><li>assess convergence</li>
<li>implement MCMC</li>
</ul></li>
</ul></div>
</div>
</div>
</div>
</div>
<p>Computing the posterior analytically poses an insurmountable
challenge in the general case. Even if we were aware of the analytical
form, marginalizing it to recover posteriors for the individual model
parameters would still be difficult. In Episode 3, we saw that drawing
conclusions about the inference could be achieved relatively easily by
working on samples from the posterior distribution. However, obtaining
such samples from the posterior distribution is a non-trivial task,
unless the analytical posterior is known. In this episode, we will delve
into Markov chain Monte Carlo methods (MCMC) that are the most
extensively employed solution for generating these samples.</p>
<section id="metropolis-hastings-algorithm"><h2 class="section-heading">Metropolis-Hastings algorithm<a class="anchor" aria-label="anchor" href="#metropolis-hastings-algorithm"></a>
</h2>
<hr class="half-width"><p>MCMC methods draw samples from the posterior distribution by
constructing sequences (chains) of values in the parameter space that
ultimately converge to the posterior. While there are other variants of
MCMC, on this course we will mainly focus on the Metropolis-Hasting
algorithm outlined below</p>
<p>A chain starts at some initial value <span class="math inline">\(\theta^{0}\)</span>, which can be random or based
on some more informed criterion. The only precondition is that <span class="math inline">\(p(\theta^{0} | X) &gt; 0\)</span>. Then a
transition distribution <span class="math inline">\(T_i\)</span> is used
to generate a proposal for the subsequent value. An often-used solution
is the normal distribution centered at the current value, <span class="math inline">\(\theta^* \sim N(\theta^{i}, \sigma^2)\)</span>.
This is where the term “Markov chain” comes from, each element is
generated based on only the previous one.</p>
<p>Next, the generated proposal <span class="math inline">\(\theta^*\)</span> is either accepted or rejected.
If each proposal was accepted, the sequence would simply be a random
walk in the parameter space and would not approximate the posterior to
any degree. The rule that determines the acceptance should reflect this;
proposals towards higher posterior densities should be favored over
proposals toward low density areas. The solution is to compute the
ratio</p>
<p><span class="math display">\[r = \frac{p(\theta^* | X) / T_i(\theta^*
| \theta^{i})}{p(\theta^i | X) / T_i(\theta^{i} | \theta^{*})}.\]</span>
In situations where the transition density is symmetric, such as with
the normal distribution, <span class="math inline">\(r\)</span> reduces
simply to the ratio of the posterior values.</p>
<p>The next element in the chain is then chosen: with probability <span class="math inline">\(r\)</span> the chain moves to the proposal, <span class="math inline">\(\theta^{i+1} = \theta^*\)</span> and with
probability <span class="math inline">\(1-r\)</span> stays at the
current value, <span class="math inline">\(\theta^{i+1} =
\theta^{i}.\)</span></p>
<p>As the algorithm is ran long enough, convergence is guaranteed and
eventually the samples will start approximating the posterior
distribution.</p>
</section><section id="example"><h2 class="section-heading">Example<a class="anchor" aria-label="anchor" href="#example"></a>
</h2>
<hr class="half-width"><p>Let’s look at the normal model and implement the Metropolis-Hastings
algorithm to sample the posterior. First we’ll simulate some data</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">100</span></span>
<span><span class="va">mu_true</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">1.25</span></span>
<span><span class="va">sigma_true</span> <span class="op">&lt;-</span> <span class="fl">0.6</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu">rnorm</span><span class="op">(</span><span class="va">N</span>, <span class="va">mu_true</span>, <span class="va">sigma_true</span><span class="op">)</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fu">data.frame</span><span class="op">(</span><span class="va">X</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">X</span><span class="op">)</span>,</span>
<span>                 bins <span class="op">=</span> <span class="fl">20</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="va">p</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/mcmc-rendered-unnamed-chunk-1-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>Then, we’ll write some functions. Below, <code>pars</code> is of the
form <code>c(mu, sigma)</code>.</p>
<p>First the point-wise log likelihood. Remember that the likelihood is
the product of likelihoods for individual data points, which after a log
transformation turns into a sum.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">log_likelihood</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">X</span>, <span class="va">pars</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="va">log_lh</span> <span class="op">&lt;-</span> <span class="fu">dnorm</span><span class="op">(</span><span class="va">X</span>,</span>
<span>                  mean <span class="op">=</span> <span class="va">pars</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>,</span>
<span>                  sd <span class="op">=</span> <span class="va">pars</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>,</span>
<span>                  log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>    <span class="va">sum</span></span>
<span>  </span>
<span>  <span class="kw">return</span><span class="op">(</span><span class="va">log_lh</span><span class="op">)</span></span>
<span>  </span>
<span><span class="op">}</span></span></code></pre>
</div>
<p>Next, well define normal and Gamma priors as the priors. The log
posterior is the sum of log likelihood and log priors.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Priors: mu ~ normal, sigma ~ gamma  </span></span>
<span><span class="va">log_prior</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">pars</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">log_mu_prior</span> <span class="op">&lt;-</span> <span class="fu">dnorm</span><span class="op">(</span>x <span class="op">=</span> <span class="va">pars</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>,</span>
<span>                        mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                        log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="va">log_sigma_prior</span> <span class="op">&lt;-</span> <span class="fu">dgamma</span><span class="op">(</span>x <span class="op">=</span> <span class="va">pars</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>,</span>
<span>                            shape <span class="op">=</span> <span class="fl">2</span>, rate <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                            log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="kw">return</span><span class="op">(</span><span class="va">log_mu_prior</span> <span class="op">+</span> <span class="va">log_sigma_prior</span><span class="op">)</span></span>
<span>  </span>
<span><span class="op">}</span></span>
<span></span>
<span></span>
<span><span class="va">log_posterior</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">X</span>, <span class="va">pars</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="fu">log_likelihood</span><span class="op">(</span><span class="va">X</span>, <span class="va">pars</span><span class="op">)</span> <span class="op">+</span> <span class="fu">log_prior</span><span class="op">(</span><span class="va">pars</span><span class="op">)</span></span>
<span>  </span>
<span><span class="op">}</span></span></code></pre>
</div>
<p>The next function implements the transition density. We’ll use the
normal distribution for both parameters. However, as <span class="math inline">\(\sigma\)</span> cannot be negative, we’ll take the
absolute value to ensure positivity.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">generate_proposal</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">pars_old</span>, <span class="va">sd</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="co"># proposal </span></span>
<span>  <span class="va">pars_new</span> <span class="op">&lt;-</span> <span class="fu">rnorm</span><span class="op">(</span><span class="fl">2</span>, mean <span class="op">=</span> <span class="va">pars_old</span>, sd <span class="op">=</span> <span class="va">sd</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># make sure sigma proposal &gt; 0</span></span>
<span>  <span class="va">pars_new</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">abs</span><span class="op">(</span><span class="va">pars_new</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="kw">return</span><span class="op">(</span><span class="va">pars_new</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre>
</div>
<p>The next function computes the acceptance ratio. Since the normal
distribution is a symmetric proposal, it suffices to compute the ratio
of the posteriors.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Acceptance probability</span></span>
<span><span class="va">get_ratio</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">X</span>, <span class="va">pars_old</span>, <span class="va">pars_new</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="co"># Ratio of posteriors</span></span>
<span>  <span class="co"># No need to include ratio of proposal densities</span></span>
<span>  <span class="co"># because Gaussian density is symmetric</span></span>
<span>  <span class="va">r</span> <span class="op">&lt;-</span> <span class="fu">exp</span><span class="op">(</span><span class="fu">log_posterior</span><span class="op">(</span><span class="va">X</span>, <span class="va">pars_new</span><span class="op">)</span> <span class="op">-</span> <span class="fu">log_posterior</span><span class="op">(</span><span class="va">X</span>, <span class="va">pars_old</span><span class="op">)</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="kw">return</span><span class="op">(</span><span class="va">r</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre>
</div>
<p>Finally, here is the Metropolis-Hastings sampler for the normal
model.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">metropolis_sampler</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">X</span>, <span class="va">inits</span>, <span class="va">n_samples</span> <span class="op">=</span> <span class="fl">1000</span>, <span class="va">jump_sd</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="va">pars</span> <span class="op">&lt;-</span> <span class="fu">matrix</span><span class="op">(</span>nrow <span class="op">=</span> <span class="va">n_samples</span>, ncol <span class="op">=</span> <span class="fu">length</span><span class="op">(</span><span class="va">inits</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">pars</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span> <span class="op">&lt;-</span> <span class="va">inits</span></span>
<span>  </span>
<span>  <span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">2</span><span class="op">:</span><span class="va">n_samples</span><span class="op">)</span> <span class="op">{</span></span>
<span>    </span>
<span>    <span class="co"># Current parameters</span></span>
<span>    <span class="va">pars_old</span> <span class="op">&lt;-</span> <span class="va">pars</span><span class="op">[</span><span class="va">i</span><span class="op">-</span><span class="fl">1</span>, <span class="op">]</span></span>
<span>    </span>
<span>    <span class="co"># Proposal</span></span>
<span>    <span class="va">pars_new</span> <span class="op">&lt;-</span> <span class="fu">generate_proposal</span><span class="op">(</span><span class="va">pars_old</span>, <span class="va">jump_sd</span><span class="op">)</span></span>
<span>    </span>
<span>    <span class="co"># Ratio</span></span>
<span>    <span class="va">r</span> <span class="op">&lt;-</span> <span class="fu">get_ratio</span><span class="op">(</span><span class="va">X</span>, <span class="va">pars_old</span>, <span class="va">pars_new</span><span class="op">)</span></span>
<span>    </span>
<span>    <span class="co"># Does the sampler move?</span></span>
<span>    <span class="va">move</span> <span class="op">&lt;-</span> <span class="fu">runif</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1</span>, min <span class="op">=</span> <span class="fl">0</span>, max <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">&lt;=</span> <span class="va">r</span></span>
<span>    <span class="co"># OR: </span></span>
<span>    <span class="co"># move &lt;- sample(x = c(TRUE, FALSE), size = 1, prob = c(r, 1-r))</span></span>
<span>    </span>
<span>    <span class="kw">if</span><span class="op">(</span><span class="va">move</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="va">pars</span><span class="op">[</span><span class="va">i</span>, <span class="op">]</span> <span class="op">&lt;-</span> <span class="va">pars_new</span></span>
<span>    <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>      <span class="va">pars</span><span class="op">[</span><span class="va">i</span>, <span class="op">]</span> <span class="op">&lt;-</span> <span class="va">pars_old</span></span>
<span>    <span class="op">}</span></span>
<span>    </span>
<span>  <span class="op">}</span></span>
<span>  </span>
<span>  <span class="va">pars</span> <span class="op">&lt;-</span> <span class="fu">data.frame</span><span class="op">(</span>mu <span class="op">=</span> <span class="va">pars</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span>, sigma <span class="op">=</span> <span class="va">pars</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="kw">return</span><span class="op">(</span><span class="va">pars</span><span class="op">)</span> </span>
<span>  </span>
<span><span class="op">}</span></span></code></pre>
</div>
<p>Then, we run the sampler. We’ll use 4 chains with 5000 samples each.
The transition density standard deviation is set to 0.05.</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">n_samples</span> <span class="op">&lt;-</span> <span class="fl">5000</span></span>
<span><span class="va">n_chains</span> <span class="op">&lt;-</span> <span class="fl">4</span></span>
<span><span class="va">jump_sd</span> <span class="op">&lt;-</span> <span class="fl">0.05</span></span>
<span></span>
<span><span class="co"># Warmup 50%</span></span>
<span><span class="va">warmup</span> <span class="op">&lt;-</span> <span class="fl">0.5</span></span>
<span></span>
<span></span>
<span><span class="co"># Random initials for each chain</span></span>
<span><span class="va">inits</span> <span class="op">&lt;-</span> <span class="fu">apply</span><span class="op">(</span>X <span class="op">=</span> <span class="fu">matrix</span><span class="op">(</span><span class="fu">c</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">n_chains</span><span class="op">)</span><span class="op">)</span>,</span>
<span>               MARGIN <span class="op">=</span> <span class="fl">1</span>,</span>
<span>               FUN <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu">rnorm</span><span class="op">(</span><span class="fl">2</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="va">t</span> </span>
<span></span>
<span><span class="co"># Make sure sigma initial &gt;0</span></span>
<span><span class="va">inits</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">abs</span><span class="op">(</span><span class="va">inits</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Run the chains</span></span>
<span><span class="va">samples</span> <span class="op">&lt;-</span> <span class="fu">lapply</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu">nrow</span><span class="op">(</span><span class="va">inits</span><span class="op">)</span>, <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="va">my_df</span> <span class="op">&lt;-</span> <span class="fu">metropolis_sampler</span><span class="op">(</span>X <span class="op">=</span> <span class="va">X</span>,</span>
<span>                              inits <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="va">inits</span><span class="op">[</span><span class="va">i</span>, <span class="fl">1</span><span class="op">]</span>, <span class="va">inits</span><span class="op">[</span><span class="va">i</span>, <span class="fl">2</span><span class="op">]</span><span class="op">)</span>,</span>
<span>                              jump_sd <span class="op">=</span> <span class="va">jump_sd</span>,</span>
<span>                              n_samples <span class="op">=</span> <span class="va">n_samples</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>      <span class="fu">data.frame</span><span class="op">(</span><span class="op">)</span></span>
<span>  </span>
<span>  </span>
<span>  <span class="co"># Add column for chain and 50% warmup</span></span>
<span>  <span class="va">my_df</span> <span class="op">&lt;-</span> <span class="va">my_df</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu">mutate</span><span class="op">(</span>chain <span class="op">=</span> <span class="fu">as.factor</span><span class="op">(</span><span class="va">i</span><span class="op">)</span>, </span>
<span>           warmup <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="fu">rep</span><span class="op">(</span><span class="cn">TRUE</span>, <span class="fu">nrow</span><span class="op">(</span><span class="va">my_df</span><span class="op">)</span><span class="op">*</span><span class="va">warmup</span><span class="op">)</span>,</span>
<span>                      <span class="fu">rep</span><span class="op">(</span><span class="cn">FALSE</span>, <span class="fu">nrow</span><span class="op">(</span><span class="va">my_df</span><span class="op">)</span><span class="op">*</span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">warmup</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="op">}</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">do.call</span><span class="op">(</span><span class="va">rbind</span>, <span class="va">.</span><span class="op">)</span></span></code></pre>
</div>
<p>Plot results. Uncomment the line <code>fill = warmup</code> below so
see the effect of removing the initial 50% of the samples.</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">samples_w</span> <span class="op">&lt;-</span> <span class="va">samples</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">gather</span><span class="op">(</span>key <span class="op">=</span> <span class="st">"par"</span>, value <span class="op">=</span> <span class="st">"value"</span>, <span class="op">-</span><span class="fu">c</span><span class="op">(</span><span class="va">chain</span>, <span class="va">warmup</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Posterior histogram</span></span>
<span></span>
<span><span class="va">p_posterior</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>data <span class="op">=</span> <span class="va">samples_w</span>,</span>
<span>                 <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">value</span>,</span>
<span>                     <span class="co"># fill = warmup</span></span>
<span>                     <span class="op">)</span>,</span>
<span>                 bins <span class="op">=</span> <span class="fl">50</span>, alpha <span class="op">=</span> <span class="fl">0.75</span>, position <span class="op">=</span> <span class="st">"identity"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>data <span class="op">=</span> <span class="fu">data.frame</span><span class="op">(</span>par <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="st">"mu"</span>, <span class="st">"sigma"</span><span class="op">)</span>,</span>
<span>                               value <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="va">mu_true</span>, <span class="va">sigma_true</span><span class="op">)</span><span class="op">)</span>, </span>
<span>             <span class="fu">aes</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">value</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">facet_wrap</span><span class="op">(</span><span class="op">~</span><span class="va">par</span>, scales <span class="op">=</span> <span class="st">"free"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># p_posterior_chains &lt;- ggplot(samples_l) +</span></span>
<span><span class="co">#   geom_histogram(aes(x = value, fill = chain),</span></span>
<span><span class="co">#                  bins = 50, alpha = 0.75, </span></span>
<span><span class="co">#                  position = "identity") +</span></span>
<span><span class="co">#   geom_vline(data = data.frame(par = c("mu", "sigma"),</span></span>
<span><span class="co">#                                value = c(mu_true, sigma_true)), </span></span>
<span><span class="co">#              aes(xintercept = value)) + </span></span>
<span><span class="co">#   scale_fill_grafify()</span></span>
<span></span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="va">p_posterior</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/mcmc-rendered-unnamed-chunk-8-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure></section><section id="assessing-convergence"><h2 class="section-heading">Assessing convergence<a class="anchor" aria-label="anchor" href="#assessing-convergence"></a>
</h2>
<hr class="half-width"><p>Although converge is guaranteed in theory, it is not so in
practice.</p>
<p>Like we saw above, unless the chains’ initial values are in high
posterior density areas, the early chain samples will bias the target
distribution estimate. For this reason, it is customary to discard a
proportion of the chain as “warmup.” Often 50% is used and this is also
the default in Stan.</p>
<ul><li>Sample autocorrelation, effective sample size
<ul><li>ideally, the samples would be independent</li>
</ul></li>
<li>Mixing</li>
<li><span class="math inline">\(\hat{R}\)</span></li>
</ul><p>Let’s plot the generated trajectories and the true parameter value.
Here, the initial 50% of the chains are colored dim to illustrate the
fact that convergence to the posterior distribution requires long enough
chains.</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">p_traj</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_path</span><span class="op">(</span>data <span class="op">=</span> <span class="va">samples</span>,</span>
<span>            <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">mu</span>, y <span class="op">=</span> <span class="va">sigma</span>, color <span class="op">=</span> <span class="va">chain</span><span class="op">)</span>, alpha <span class="op">=</span> <span class="fl">0.25</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="co"># Post warmup samples</span></span>
<span>  <span class="fu">geom_path</span><span class="op">(</span>data <span class="op">=</span> <span class="va">samples</span> <span class="op">%&gt;%</span> <span class="fu">filter</span><span class="op">(</span><span class="va">warmup</span> <span class="op">==</span> <span class="cn">FALSE</span><span class="op">)</span>,</span>
<span>            <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">mu</span>, y <span class="op">=</span> <span class="va">sigma</span>, color <span class="op">=</span> <span class="va">chain</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">mu_true</span>, y <span class="op">=</span> <span class="va">sigma_true</span><span class="op">)</span>,</span>
<span>             size <span class="op">=</span> <span class="fl">4</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">scale_color_grafify</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Red point = true value"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="va">p_traj</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/mcmc-rendered-unnamed-chunk-9-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>Next, we’ll make the trace plots, which are comprised of the chains
of individual parameters. The warmup iterations are again colored
dimmer. Trace plots can give quick visual information about the chains.
When there are no converge issues, the trace plots should look like
“hairy caterpillars,” with sample of each chain located around the same
value. In this case everything look ok. A standard convergence metric is
the <span class="math inline">\(\hat{R}\)</span> which compares the
variances between chains and to the variance within each chain. We’ll
omit the definition here but, generally, value <span class="math inline">\(\hat{R} \geq 1.1\)</span> are seen as a sign of
convergence issues. However, with modern samplers such as Stan,
thresholds closer to 1 are recommended (<a href="https://mc-stan.org/rstan/reference/Rhat.html" class="external-link uri">https://mc-stan.org/rstan/reference/Rhat.html</a>).</p>
<p>Clearly convergence is reached fairly quickly after initialization,
in some dozen iterations. Moreover, the chain autocorrelation low. This
is desirable because it implies that the drawn samples are independent.
Another popular convergence metric is the effective sample size. It
quantifies the number of independent samples produced by the
sampler.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Long --&gt; wide format</span></span>
<span><span class="va">samples_w</span> <span class="op">&lt;-</span> <span class="va">samples</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>sample <span class="op">=</span> <span class="fu">rep</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">n_samples</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">gather</span><span class="op">(</span>key <span class="op">=</span> <span class="st">"parameter"</span>, value <span class="op">=</span> <span class="st">"value"</span>, <span class="op">-</span><span class="fu">c</span><span class="op">(</span><span class="va">chain</span>, <span class="va">warmup</span>, <span class="va">sample</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Trace plot</span></span>
<span><span class="va">p_trace</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>data <span class="op">=</span> <span class="va">samples_w</span>,</span>
<span>            <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">sample</span>, y <span class="op">=</span> <span class="va">value</span>, color <span class="op">=</span> <span class="va">chain</span><span class="op">)</span>, alpha <span class="op">=</span> <span class="fl">0.25</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>data <span class="op">=</span> <span class="va">samples_w</span> <span class="op">%&gt;%</span> <span class="fu">filter</span><span class="op">(</span><span class="va">warmup</span> <span class="op">==</span> <span class="cn">FALSE</span><span class="op">)</span>,</span>
<span>            <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">sample</span>, y <span class="op">=</span> <span class="va">value</span>, color <span class="op">=</span> <span class="va">chain</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">facet_wrap</span><span class="op">(</span><span class="va">chain</span> <span class="op">~</span> <span class="va">parameter</span>,</span>
<span>             scales <span class="op">=</span> <span class="st">"free"</span>,</span>
<span>             ncol <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">scale_color_grafify</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="va">p_trace</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/mcmc-rendered-unnamed-chunk-10-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>Let’s compute the number of rejected proposals to get some idea about
the efficiency of the algorithm. The less samples are rejected, the more
efficient the sampler performs.</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Proportion of post-warmup samples where the proposal was rejected</span></span>
<span><span class="fu">sum</span><span class="op">(</span><span class="fu">table</span><span class="op">(</span><span class="va">samples</span> <span class="op">%&gt;%</span></span>
<span>            <span class="fu">filter</span><span class="op">(</span><span class="va">warmup</span> <span class="op">==</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>            <span class="fu">pull</span><span class="op">(</span><span class="va">mu</span><span class="op">)</span><span class="op">)</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">/</span><span class="op">(</span><span class="va">n_chains</span><span class="op">*</span><span class="va">n_samples</span><span class="op">*</span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">warmup</span><span class="op">)</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[1] 0.3943</code></pre>
</div>
<div id="discussion1" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#discussion1"></a>
</h3>
<div class="callout-content">
<p>Try different proposal distributions (e.g. 0.005, 0.5) standard
deviations in the MCMC example above. How does this affect the inference
and convergence? Why?</p>
</div>
</div>
</div>
</section><section id="hamiltonian-monte-carlo"><h2 class="section-heading">Hamiltonian Monte Carlo<a class="anchor" aria-label="anchor" href="#hamiltonian-monte-carlo"></a>
</h2>
<hr class="half-width"><p>Hamiltonian Monte Carlo (HMC) is a variant of the Metropolis-Hastings
algorithm implemented in Stan. The defining feature is the elaborate
scheme it uses to generate proposals. Briefly, the idea is to simulate
the dynamics of a particle moving in a potential landscape defined by
the posterior. At each iteration, the particle is given a random
momentum vector and then its dynamics are simulated forward for some
time. The end of the trajectory is then taken as the proposal value.</p>
<p>Compared to the random walk Metropolis-Hastings we implemented in
this episode, HMC is very efficient. The main advantages of HMC is its
ability to explore high-dimensional spaces more effectively, making it
especially useful in complex models with many parameters</p>
<p>A type of convergence criterion exclusive to HMC are divergent
transitions. In region of the parameter space where the posterior has
high curvature, the simulated particle dynamics can produce spurious
transitions which do not represent the posterior accurately. Such
transitions are called divergent and signal that the particular area of
parameter space is not explored accurately. Stan provides information
about divergent transitions.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul><li><p>MCMC is ….</p></li>
<li>
<p>Convergence should be monitored</p>
<ul><li>mixing: <span class="math inline">\(\hat{R}\)</span>
</li>
<li>divergent transitions</li>
</ul></li>
</ul></div>
</div>
</div>
</section><section id="reading"><h2 class="section-heading">Reading<a class="anchor" aria-label="anchor" href="#reading"></a>
</h2>
<hr class="half-width"><ul><li><p>See interactive visualization of different MCMC algorithms: <a href="https://chi-feng.github.io/mcmc-demo/app.html" class="external-link uri">https://chi-feng.github.io/mcmc-demo/app.html</a></p></li>
<li><p>Statistical Rethinking</p></li>
<li><p>BDA3</p></li>
<li><p>Bayes Rules!</p></li>
</ul><!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 --></section></div> <!-- / div.lesson-content -->
    </main><!-- / main#main-content.main-content --><nav class="bottom-pagination mx-md-4" aria-label="Previous and Next Chapter"><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="../instructor/stan.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="../instructor/hierarchical-models.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="../instructor/stan.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Stan
        </a>
        <a class="chapter-link float-end" href="../instructor/hierarchical-models.html" rel="next">
          Next: Hierarchical Models... 
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
    </nav></div> <!-- / div.primary-content.col-xs-12 -->
<!-- END:   inst/pkgdown/templates/content-instructor.html-->

      </div><!--/div.row-->
      		<footer class="row footer mx-md-3"><hr><div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>
        
        <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/edit/main/episodes/mcmc.Rmd" class="external-link">Edit on GitHub</a>
        
	
        | <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/" class="external-link">Source</a></p>
				<p><a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/blob/main/CITATION" class="external-link">Cite</a> | <a href="mailto:velait@utu.fi">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">
        
        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>
        
        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.2" class="external-link">sandpaper (0.16.2)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.3" class="external-link">pegboard (0.7.3)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.1" class="external-link">varnish (1.0.1)</a></p>
			</div>
		</footer></div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "TrainingMaterial",
  "@id": "https://carpentries-incubator.github.io/statistical-probabilistic-programming-r/instructor/mcmc.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "software, data, lesson, The Carpentries",
  "name": "MCMC",
  "creativeWorkStatus": "active",
  "url": "https://carpentries-incubator.github.io/statistical-probabilistic-programming-r/instructor/mcmc.html",
  "identifier": "https://carpentries-incubator.github.io/statistical-probabilistic-programming-r/instructor/mcmc.html",
  "dateCreated": "2024-01-16",
  "dateModified": "2024-01-16",
  "datePublished": "2024-01-16"
}

  </script><script>
		feather.replace();
	</script><!-- Matomo
    2022-11-07: we have gotten a notification that we have an overage for our
    tracking and I'm pretty sure this has to do with Workbench usage.
    Considering that I am not _currently_ using this tracking because I do not
    yet know how to access the data, I am turning this off for now.
  <script>
    var _paq = window._paq = window._paq || [];
    /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
    _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
    _paq.push(["setDomains", ["*.preview.carpentries.org","*.datacarpentry.github.io","*.datacarpentry.org","*.librarycarpentry.github.io","*.librarycarpentry.org","*.swcarpentry.github.io", "*.carpentries.github.io"]]);
    _paq.push(["setDoNotTrack", true]);
    _paq.push(["disableCookies"]);
    _paq.push(['trackPageView']);
    _paq.push(['enableLinkTracking']);
    (function() {
          var u="https://carpentries.matomo.cloud/";
          _paq.push(['setTrackerUrl', u+'matomo.php']);
          _paq.push(['setSiteId', '1']);
          var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
          g.async=true; g.src='https://cdn.matomo.cloud/carpentries.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
        })();
  </script>
  End Matomo Code --></body></html><!-- END:   inst/pkgdown/templates/layout.html-->

