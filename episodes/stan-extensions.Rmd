---
title: 'Stan extensions'
teaching: 10
exercises: 2
---


```{r, include=FALSE}
library(magrittr)
library(tidyverse)
library(grafify)
library(cowplot)
library(brms)
library(bayesplot)
library(splines2)
theme_set(theme_bw(15))


okabi_colors <- c("#E69F00", "#56B4E9", "#009E73")

prior_color <- "#009E73"
likelihood_color <- "#E69F00"
posterior_color <- "#56B4E9"

bayesplot::color_scheme_set("brightblue")
```


:::::::::::::::::::::::::::::::::::::: questions

- Which packages take advantage of Stan and how to use them?

::::::::::::::::::::::::::::::::::::::::::::::::

::::::::::::::::::::::::::::::::::::: objectives

- Learn to use Stan with additional R packages

::::::::::::::::::::::::::::::::::::::::::::::::


In this chapter, we will introduce packages that take advantage of Stan. The covered packages are  `loo`, which enables approximate Bayesian cross-validation,  `bayesplot`, which contains plotting tools, and `brms`, which allows calling Stan using common R syntax, without having to write the Stan code.


## `loo` 

The `loo` package allows computing approximate leave-one-out cross-validation (loo-cv) for models fitted with Stan. The approximation is based on something called Pareto smoothed importance sampling (PSIS) [1]. The package can also be used for computing WAIC and model weights for average predictive distributions.

### Example 1

We will demonstrate `loo` package usage on the model comparison example studied in Episode 5. We will fit the normal and Cauchy models on the same synthetic data, then use the tools provided in `loo` to compute and compare the approximate loo-cv scores for these two models. 

To be able to utilize the package functions, we need to add a log-likelihood computation in the Stan code, in the generated quantities block. The object containing the log-likelihood needs to be named `log_lik` so the 'loo' functions can find it. Below, we demonstrate this with the two models we are comparing.

```{stan output.var="normal_model_loo"}
// Normal model
data {
  int<lower=0> N;
  vector[N] X;
}
parameters {
  real<lower=0> sigma;
  real mu;
}
model {
  X ~ normal(mu, sigma);
  
  mu ~ normal(0, 1);
  sigma ~ gamma(2, 1);
}

generated quantities {
  vector[N] X_rep;
  
  for(i in 1:N) {
    X_rep[i] = normal_rng(mu, sigma);
  }
  
  // Calculating log-likelihood for loo
  vector[N] log_lik;
  
  for (i in 1:N) {
  log_lik[i] = normal_lpdf(X[i] | mu, sigma);
  }
}
```


```{stan output.var="cauchy_model_loo"}
// Cauchy model
data {
  int<lower=0> N;
  vector[N] X;
}
parameters {
  // Scale
  real<lower=0> sigma;
  // location
  real mu;
}
model {
  // location = mu and scale = sigma
  X ~ cauchy(mu, sigma);
  
  mu ~ normal(0, 1);
  sigma ~ gamma(2, 1);
}
generated quantities {
  vector[N] X_rep;
  for(i in 1:N) {
    X_rep[i] = cauchy_rng(mu, sigma);
  }
  
  // Calculating log-likelihood for loo
  vector[N] log_lik;
  
  for (i in 1:N) {
  log_lik[i] = cauchy_lpdf(X[i] | mu, sigma);
  }
}

```

Now we can fit the models in the usual way.

```{r, echo=FALSE}
# Data used
df5 <- data.frame(X = c(-2.27, 1.941, 0.502, -0.378, -0.226, -0.786, -0.209, -0.637, 0.814, 0.566, -1.901, -2.047, -0.689, -3.509, 0.133, -4.353, 1.067, 0.722, 0.861, 0.523, 0.681, 2.982, 0.429, -0.539, -0.512, -1.09, -8.044, -0.387, -0.007, -11.126, 1.036, 1.734, -0.203, 1.036, 0.582, -2.922, -0.543, -6.12, -0.649, 4.547, -0.867, 1.942, 7.148, -0.044, -0.681, -3.461, -0.142, 0.678, 0.644, -0.039, 0.354, 1.783, 0.369, 0.175, 0.98, -0.097, -4.408, 0.442, 0.158, 0.255, 0.084, 0.775, 2.786, 0.008, -0.664, 43.481, 1.943, 0.334, -0.118, 3.901, 1.736, -0.665, 2.695, 0.002, -1.904, -2.194, -4.015, 0.329, 1.14, -3.816, -14.788, 0.047, 6.205, 1.119, -0.003, 3.618, 1.666, -10.845))

N <- 88
```

```{r}
# Fit normal model
normal_fit <- rstan::sampling(normal_model_loo,
                       list(N = N, X = df5$X), 
                       refresh = 0, seed = 2024)
# Fit cauchy model
cauchy_fit <- rstan::sampling(cauchy_model_loo,
                       list(N = N, X = df5$X), 
                       refresh = 0, seed = 2024)

```

We can now compute PSIS-LOO for both of the models with `loo::loo` function. After the calling the function, information about the fit can be viewed by printing the `loo` objects.

```{r}
# PSIS-LOO computation for normal model
normal_loo <- loo::loo(normal_fit)
print(normal_loo)

# PSIS-LOO computation for cauchy model
cauchy_loo <- loo::loo(cauchy_fit)
print(cauchy_loo)
```

Running `print` returns $\widehat{\text{elpd}}_{\text{loo}}$ (expected log pointwise predictive density), $\hat{p}_{loo}$ (estimated number of parameters) and $\text{looic}$ (LOO information criterion) values and their standard errors. It also returns a table with the Pareto $k$ diagnostic values, which are used to asses the reliability of the estimates. Values below 1 are required for reliable PSIS estimates.

Model comparison can be done by using the `loo::loo_compare` function on the `loo` objects. The comparison is based on the models' elpd values. 

```{r}
# Comparing models based on loo
loo::loo_compare(normal_loo, cauchy_loo)
```

The comparison shows that the elpd difference is larger than the standard error, indicating that the cauchy model is expected to have better predictive performance than the normal model. This is in line with what we saw in chapter 5: the Cauchy distribution is a superior model for the data. 


::::::::::::::::::::::::::::::::::::::::: challenge

`loo` can also be used to compute WAIC for Bayesian models. Calculate WAIC for the two models and then compare them.

::::::::::::::::::::::::::::::: solution

First we need to extract the log-likelihood values from the fitted model object.

```{r}
# Extracting loglik
normal_loglik <- loo::extract_log_lik(normal_fit)
cauchy_loglik <- loo::extract_log_lik(cauchy_fit)

# Computing WAIC for the models
normal_waic <- loo::waic(normal_loglik)
print(normal_waic)
cauchy_waic <- loo::waic(cauchy_loglik)
print(cauchy_waic)
```

Computing WAIC for the model return values for $\widehat{\text{eldp}}_{\text{WAIC}}$, $\hat{p}_{\text{WAIC}}$ and $\widehat{\text{WAIC}}$. Models can be compared based on WAIC using the same function as with PSIS-LOO.

```{r}
# Comparing models based on WAIC
loo::loo_compare(normal_waic, cauchy_waic)
```

::::::::::::::::::::::::::::::::::::::::

:::::::::::::::::::::::::::::::::::::::::::::::::::


## `bayesplot`

Next, we will look at the the `bayesplot` R package. The package provides a library of plotting functions for fitted Stan models. The created plots are `ggplot` objects, meaning that the plots can be customized with the functions from `ggplot2` package. The package enables plotting posterior draws, visual MCMC diagnostics and graphical posterior and prior predictive checking. The functions of the package also work with model fit with the popular packages `brms` and `rstanarm`.

### Example 1 continued

We will demonstrate using `bayesplot` with the Cauchy model used in the first example. First, we need to extract the posterior draws. Then, we will plot uncertainty intervals for $\mu$ and $\sigma$.

```{r}
# Extracting draws
cauchy_draws <- as.array(cauchy_fit)

# Plotting uncertainty intervals
bayesplot::mcmc_intervals(cauchy_draws, pars = c("mu", "sigma"))
```

Alternatively, we can plot the (marginal) posterior sample histograms or densities with credible intervals as shaded areas as follows:

```{r, message = FALSE}
# Plotting estimated density curves
bayesplot::mcmc_areas(cauchy_draws, pars = c("mu", "sigma"),
                      prob = 0.95,
                      point_est = "mean")

# Plotting histogram
bayesplot::mcmc_hist(cauchy_draws, pars = c("mu", "sigma"))
```

`bayesplot` also provides functions for assessing MCMC convergence and visualizing fit diagnostics. For example, we can generate trace plots for the chains:

```{r}
# Plotting trace plot
bayesplot::mcmc_trace(cauchy_draws, pars = c("mu", "sigma"),
                      facet_args = list(ncol = 1))
```



::::::::::::::::::::::::::::::::::::::::: challenge

Perform a graphical posterior predictive checks with `bayesplot`. Using the Cauchy model fit generated above, plot the density of $X_{rep}$ samples overlaid with the density of $X$. Alternatively, you can plot the corresponding histograms.

::::::::::::::::::::::::::::::: solution


```{r}
# Extracting replicates and getting a subset
set.seed(2024)
X_rep <- rstan::extract(cauchy_fit, "X_rep")[[1]] %>%
  data.frame() %>%
    mutate(sample = 1:nrow(.))

N_rep <- 9

X_rep_sub <- X_rep %>% filter(sample %in%
                                sample(X_rep$sample,
                                       N_rep,
                                       replace = FALSE))
X_rep_sub <- X_rep_sub[, -89] %>%
  as.matrix()
```

```{r, message = FALSE, warning = FALSE}
# Plot density
# Limit x range for better illustration
bayesplot::ppc_dens_overlay(y = df5$X, yrep = X_rep_sub) + xlim(-25, 50)
```

```{r, message = FALSE, warning = FALSE}
# Plot histograms
bayesplot::ppc_hist(y = df5$X, yrep = X_rep_sub) + xlim(-25,50)
```


::::::::::::::::::::::::::::::::::::::::

:::::::::::::::::::::::::::::::::::::::::::::::::::


## `brms` R package

We will now introduce the `brms` R package. The package allows fitting probabilistic generalized (non-)linear models with Stan. A large range of distributions and link functions are supported, in addition to multilevel structure. Moreover, several built-in functions are available for priors. 

Models are specified using familiar R formula syntax, input into an R function which compiles and calls the Stan model in the backend.

The package also provides tools for evaluating the fit and MCMC convergence. These tools, in turn, use functions from the `loo` and `bayesplot` packages, that is, many of the same tools we covered earlier in this Episode. 

Next, we will demonstrate usage of the package with two different examples.



### Example 2: Survival modeling

In this example, we will demonstrate fitting a Cox proportional hazard model with `brms`. However, first, we will briefly describe and model and idea in survival modeling. 

The Cox model is a standard approach used in survival modeling, in which the outcome of interest is the time to some event. A common application is medical studies where patients are followed in time until an event (e.g. death) or until censoring. A subject is censored if the event doesn't occur during the follow-up. 

An important ingredient in survival modeling is the hazard function, representing the instantaneous risk for an event at time $t$, defined as  $\lambda(t)=\text{lim}_{h \to 0+} \frac{1}{h}P(t \le T<t+h|T\ge t)$. In the Cox model, the hazard function is of the form $\lambda(t_i,Z_i,\theta)=\lambda_0(t_i)\text{exp}(\beta^\prime Z_i)$.

The baseline hazard function $\lambda_0(t_i)$ represents the hazard when the covariates are set to their baselines, and is the same for each subject $i$. Commonly, the functional form the baseline hazard is not specified. The second part of the hazard function contains subject-specific covariates, $\text{exp}(\beta^\prime Z_i)$. 

The exponentials of the effects $\beta$ are called hazard ratios, which measure the hazard in one group against the hazard in another group.

When fitting the Cox model, `brms` uses M-splines for the baseline hazard. Splines are functions built from piecewise-defined polynomials. In other words, the baseline hazard is a combination of several different polynomial functions. M-splines are non-negative spline functions, which is important for reasons we omit. However, hopefully, the reader can appreciate the simplicity of the upcoming `brms` function call.



Before fitting the model, we will take a look at the `lung` dataset from the `survival` R package, which we will be analyzing below. The dataset consists of survival times of patients with advanced lung cancer including some clinical covariates. 

```{r}
# Get data
lung <- survival::lung

# Take a peek
head(lung)
```


The variable `status` denotes if an event (death) was observed or if the subject was censored. We will use three covariates: `age`, `sex` and `ph.karno`. The variable `ph.karno` describes how well a patient can perform daily activities rated by a physician. We will split the variable into two categories "high" and "low." 

Cox model can be fit with `brms::brm()` function by specifying `family = brmsfamily("cox")`. Censored data points are indicated with the `cens(1 - status)` argument. We will use a standard $\text{Normal}(0, 10)$ prior for the population-level effects, with the argument `prior(normal(0,10), class = b)`. The option `class = b` sets the prior for all population-level effects.
 
```{r}
# Let's change status coding from 2/1 to 1/0
lung$status <- lung$status - 1

# Remove observations with NA ph.karno
lung <- lung[!is.na(lung$ph.karno),]

# Creating new variable for ph.karno status
lung$ph.karno_status <- cut(lung$ph.karno,
                            breaks = c(0, 70, 100),
                            labels = c("low", "high"))

# Fitting the model
fit_cox <- brms::brm(time | cens(1 - status) ~ sex + age + ph.karno_status,
             data = lung, family = brmsfamily("cox"), seed = 2024,
             silent = 2, refresh = 0, cores = 4,
             prior = prior(normal(0,10), class = b))
# Summary of the fit
summary(fit_cox)
```

The summary output of the `brms` fit prints coefficient estimates, and also returns Rhat, Bulk_ESS and Tail_ESS values, which can be used to assess the convergence of the model. 

It is important to notice that the coefficients are the log hazard ratios, which means we still need to exponentiate them. The `bayesplot::mcmc_intervals()` function allows transforming the parameters before plotting with `transform = "exp"` argument.

```{r}
# Get hazard values
sum_cox <- summary(fit_cox)
exp(sum_cox$fixed[,1:4])

# Credible intervals
bayesplot::mcmc_intervals(fit_cox,
                          pars = c("b_sex", "b_age", "b_ph.karno_statushigh"),
                          transform = "exp")
```

Based on the estimates, it seems that age has only a minor effect on the hazard. Female sex and being "high" in `ph.karno` imply smaller hazards, meaning that these factors are protective. 

After fitting the model, we can print information about the priors used with the function `brms::get_prior`.

```{r}
# Get priors for the cox model
brms::get_prior(fit_cox)
```

The population-level effects have the normal prior we specified. In `brms`, the default prior for the intercept is Student's t-distribution with three degrees of freedom. The Stan program `brms` ran under the hood can be printed with the `brms::stancode` function.

```{r}
# Print the Stan code
brms::stancode(fit_cox)
```


### Example 3: Hierarchical binomial model

We will now demonstrate one of the key focuses of `brms`, fitting hierarchical models. The syntax for specifying hierarchical models is similar as in the `lme4` package, which is used to fit frequentist multilevel models in R. 

For this example, we will be using is the `VerbAgg` data from `lme4` package. The data consist of item responses to a questionnaire on verbal aggression. 

```{r}
# Get data
VerbAgg <- lme4::VerbAgg

head(VerbAgg)
```

We will estimate population-level effects for Anger, Gender, btype and situ, and includea group-level intercept for id. The variable of interest is the binary r2, which contains the response to an question in the questionnaire. We will use $\text{Normal}(0, 10)$ as the prior for all the population-level effects. For the standard deviation of group-level effect we will set a (half-)$\text{Cauchy}(0, 5)$ prior. By default, `brms` uses half-Student's t-distribution with three degrees of freedom for standard deviation parameters. The group-level intercept for variable id is specified with the argument `(1|id)`. Let's now fit the model.

```{r}
# Change coding for r2
VerbAgg <- VerbAgg %>%
  mutate(r2 = ifelse(r2 == "N", 0, 1))
# Fit model
fit_hier <- brms::brm(r2 ~ Anger + Gender + btype + situ + (1|id),
                      family = bernoulli, 
                      data = VerbAgg,
                      seed = 2024, cores = 4, silent = 2, refresh = 0,
                      prior = prior(normal(0, 10), class = b) + 
                        prior(cauchy(0,5), class = sd))
# Summary
summary(fit_hier)
```

The conditional effects of the predictors can easily be plotted with the function `brms::conditional_effects`.

```{r}
# Conditional effects
plots <- plot(conditional_effects(fit_hier), plot = FALSE)
cowplot::plot_grid(plots[[1]], plots[[2]], plots[[3]], plots[[4]])

```

The function can also plot variable interactions. Let's plot the conditional effect for interaction between Anger and btype.

```{r}
# Plot conditional effect for interaction of Anger and btype
plot(conditional_effects(fit_hier, effects = "Anger:btype"))
```



Let us now do a slight alteration in model and add another group-level intercept for the item variable. The priors are same as in the first model. The `update` function can be used to modify the formula without writing it anew in its entirety.

```{r}
# Update model
fit_hier2 <- update(fit_hier, formula. = ~ . + (1|item), newdata = VerbAgg, seed = 2024,
                    cores = 4, silent = 2, refresh = 0)
# Summary
summary(fit_hier2)
```

Another useful aspect of `update` is that it allows resampling from the model without having to recompile the model, for example, using different number of iterations. However, changes to the model itself require recompilation.

To end this section, let's compare the two models by using `brms::loo()`. This works in the same way as the `loo::loo_compare`.

```{r}
# Compare models
brms::loo(fit_hier, fit_hier2)
```

Based on the output, the second model provides a superior fit compared to the first model.


::::::::::::::::::::::::::: challenge

Experiment with different priors for the model. How much does the chosen prior affect the results? Is there a big difference between a flat and the weakly informative prior used above?

:::::::::::::::::::::::::::::::::::::


## Other packages built on Stan

In addition to the ones covered here, there are several other packages that take advantage of Stan. Here we will briefly introduce some of them.  [CmdStanR](https://mc-stan.org/cmdstanr/index.html) is a lightweight command-line-based interface for Stan and provides and alternative for rstan. [rstanarm](https://mc-stan.org/rstanarm/) emulates the model fitting R functions using Stan. The package can do lot of the same things as `brms`, but they do have differences, for example `rstanarm` models come pre-compiled while `brms` compiles the models when called. 

[shinystan](https://mc-stan.org/shinystan/) uses Shiny and provides user with interactive, customizable visual and numerical summaries of model parameters and convergence diagnostics. [projpred](https://mc-stan.org/projpred/) performs projection predictive variable selection for various models. The package works with models from `brms` and `rstanarm`. [posterior](https://mc-stan.org/posterior/) provides tools for manipulating posterior draws, and contains methods for common operations, such as,  subsetting and binding, and producing posterior summaries, and diagnostics. 

::::::::::::::::::::::::::::::::::::: keypoints 

- There are several R packages that provide more user-friendly ways of using Stan.
- `brms` package can be used to fit a vast array of different Bayesian models.
- `bayesplot` package is a library for various plotting tools. 
- Approximate leave-one-out cross-validation can be performed with the `loo` package. 

::::::::::::::::::::::::::::::::::::::::::::::::



## Reading

- [brms website](https://paul-buerkner.github.io/brms/index.html)

- [bayesplot website](http://mc-stan.org/bayesplot/)

- [loo website](https://mc-stan.org/loo/)

## References

- [1] A. Vehtari *et al.*, Pareto Smoothed Importance Sampling, *Journal of Machine Learning Research* 25 (2024) 1-58.
